{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Neuroimager's Guide to the CHBH","text":"<p>Welcome to the Neuroimager's Guide!</p> <p>These pages contain practical information on data collection and analysis at the CHBH. We also extend the BEAR Technical Documentation pages to provide tutorials on neuroimaging quality control and data analyses using the University of Birmingham's Supercomputer - BlueBEAR.</p> <p>The open information here is generated by CHBH users for CHBH users for the benefit of our whole research community.</p> <p>We are always open for new contributions. This is a fantastic way to build your skills in documentation and <code>git</code> to learn about contributing to the scientific community. Take a look at our Making a Contribution pages for more information and the bottom of this page for the list of contributors so far!</p> <p>CHBH Sharepoint Pages</p> <p>This website is intended for current staff and students at the Centre for Human Brain Health and University of Birmingham. It may or may not be useful for anyone else.</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"#click-a-modality-to-get-started","title":"Click a modality to get started","text":"<ul> <li>MRI </li> <li>MEG </li> <li>EEG add image? </li> <li>EEG-fMRI add image? </li> <li>Sleep add image? </li> <li>fNIRS add image? </li> <li>Behaviour add image? </li> <li>Brain Stimulation add image? </li> </ul>"},{"location":"#contributors","title":"Contributors","text":"<p>Many thanks to our contributors!</p> <sub>ajquinn</sub>\ud83d\udea7 \ud83d\udd8b <sub>James Carpenter</sub>\ud83d\udea7 \ud83d\udd8b <sub>Brandon Ingram</sub>\ud83d\udd8b <sub>Arkady Konovalov</sub>\ud83d\udd8b <sub>Ben Griffiths</sub>\ud83d\udd8b <sub>Tara</sub>\ud83d\udd8b <sub>Dagmar S Fraser</sub>\ud83d\udd8b <sub>Jianzhang Ni</sub>\ud83d\udd8b <sub>Katharina</sub>\ud83d\udd8b <sub>Tommy Roberts</sub>\ud83d\udd8b <sub>Aamir Sohail</sub>\ud83d\udea7 \ud83d\udd8b <sub>Selma Lugtmeijer</sub>\ud83d\udd8b <sub>TomRhysMarshall</sub>\ud83d\udd8b <sub>Nicholas Paul Holmes</sub>\ud83d\udd8b <sub>Martin Wilson</sub>\ud83d\udd8b <sub>froemero</sub>\ud83d\udd8b <sub>toddvogel1628</sub>\ud83d\udd8b <sub>MEGSupportCHBH</sub>\ud83d\udd8b \ud83d\udea7 <sub>Simon Marchant</sub>\ud83d\udd8b <sub>kiranphalke50</sub>\ud83d\udd8b"},{"location":"#contributing","title":"Contributing","text":"<p>This page is a work-in-progress and contributions are very welcome! Please email Andrew or make some changes directly on the CHBH-on-BEAR GitHub page. See the 'Making a contribution' page for more information on how to do so.</p>"},{"location":"faqs/","title":"Frequently Asked Questions","text":"<p>Is something incorrect, out-of-date or missing from this page? Open an issue on github and let us know.</p>"},{"location":"faqs/#where-can-i-ask-for-help","title":"Where can I ask for help?","text":"<p>You can ask for informal help via the CHBH Code, Computing and Open Science teams page. More formal support is availabl by raising a support ticket with IT.</p>"},{"location":"faqs/#general","title":"General","text":"<p>What is a 'core'? is it the same as a 'CPU'?</p> <p>Core and CPU refer to a Central Processing Unit. The terms are sometimes used interchangeably.</p> <p>What does it mean if I use '4 cores'?</p> <p>Each core can run a single computation at a time. If we have 4 cores, we can run 4 different things can happen at once. And 50 cores means 50 jobs could be run in parallel.</p> <p> Is castles the same as rds space?</p> <p>CaStLeS (Compute and Storage for Life Sciences) resources (both compute and storage) are a constituent part of BEAR Cloud, BlueBEAR and the wider BEAR infrastructure. They are reserved exclusively for the use of research groups carrying out research in the life sciences.</p> <p>In CHBH, 'Castles' has often referred to Virtual Machine environments used for analyses. These are been phased out in favour of the BEAR GUI.</p> <p> What about code sharing? Not everybody has a Bluebear. Will people be able to run my code if I\u2019ve written it for use on this platform?</p> <ul> <li>Think in terms of \u2018develop\u2019 vs \u2018rationalise\u2019. The second part is where parallelising becomes a bi advantage. It\u2019s also the place you think about code sharing.</li> <li>There are clever ways to make things very shareable agnostic to infrastructure. E.g., putting everything into a docker container and running \u2018container jobs\u2019. This has the disadvantage that you lose bear\u2019s optimisation (all modules have been optimised so may run a lot faster). But you gain control. Tradeoff</li> </ul>"},{"location":"faqs/#bear-portal","title":"BEAR Portal","text":"<p>What is included in the 'Number of hours' when starting a service on BEAR portal?</p> <p>The \u2018number of hours\u2019 means that the GUI is required for N hours, not that the whole analysis needs to last N hours.  The 8 hour limit is for interactive jobs or apps started from the BEAR portal. The time limit on the main cluster is 10 days.</p> <p>What does \u2018working directory\u2019 mean when starting VS Code?</p> <p>This changes root dir that VScode opens in, though it can only operate within your RDS home space, not a group space.</p> <p>If you want to edit files in a group space using VS Code, you'll need to create a 'Symbolic Link' that provides a path to the group from within your home space. For example, to link a project to a home space you can run</p> <pre><code>ln -s /rds/groups/q/quinna-example-project /rds/homes/q/quinna/\n</code></pre> <p>There will now be a link directory in <code>/rds/homes/q/quinna/quinna-example-project</code> that you can use to see the files in the group space. Note that this is a 'link' not a copy.</p> <p>Do I NEED to run a VScode interactive session - couldn\u2019t I use my own local code editor?</p> <p>If you\u2019ve mounted your RDS drive, you could also use a local text editor, any one that you like. But, if you\u2019re running things locally on BEAR, an advantage is that you don\u2019t need to copy files back and forth which adds a step and can be cumbersome.</p> <p>Does VScode track changes to code?</p> <p>VScode doesn\u2019t track changes itself but VScode should be able to show you which files have been modified if you are reading files within an existing git repository. Git should be used to handle version tracking.</p>"},{"location":"faqs/#matlab","title":"Matlab","text":"<p>What situations would it make sense to use parfor in matlab?</p> <p>The most common neuroimaging use-case for <code>parfor</code> is looping over participants for first-level analyses. For example, when you want to run an identical set of steps on every file in a datasets.</p> <p>Other examples might include computing something from every voxel/channel/frequency in a single dataset, or running non-parametric permutatation stats.</p> <p>What if you asked for 50 CPUs and DIDN\u2019T use a parfor? Would it still be faster?</p> <p>Not necessarily. It depends on how the person wrote the code, occasionally a toolbox might know how to parallelise a process internally but this is unlikely by default. It is possible to ask for 50 cores and then accidentally run an analysis on only one of them.w</p> <p>Can I write a startup.m script to do things like adding paths to tools I use all the time, so MATLAB will automatically execute this when it starts up?</p> <p>Yes. A matlab <code>startup.m</code> script in your local home directory will run as normal when opening matlab.</p> <p>For people who are already using matlab/rdesktop on their own computer, what are the key steps to get the best optimisation as you\u2019ve described when they switch to the cluster?</p> <p>Don\u2019t optimise too early. Look at your data first - lots of visualisation etc which is more interactive. But when you\u2019ve got your pipeline hardened, that\u2019s when you want to do all this stuff. Or when you\u2019ve got a pipeline but want to change something and re-run.</p>"},{"location":"getting_started/","title":"Getting started on BEAR","text":"<p>This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main BEAR Technical Documentation pages.</p> <p>Here we provide a set of links, tips and tricks for getting started.</p>"},{"location":"getting_started/#step-0-linux","title":"Step 0: Linux","text":"<p>BEAR provide a Introduction to Linux guide. Many computing services on BEAR rely on Linux. There are in-person workshops and an online Canvas courses available on this page.</p>"},{"location":"getting_started/#step-1-bluebear","title":"Step 1: BlueBEAR","text":"<p>BEAR also provide a Introduction to BlueBEAR course. There are in person workshops and an online Canvas course.</p>"},{"location":"getting_started/#step-2-rds-projects","title":"Step 2: RDS Projects","text":"<p>You'll need to be a member of a BEAR project and have a BEAR linux account to use BlueBEAR. Your PI and lab can help with this. A detailed guide for accessing BEAR is provided on the technical docs.</p>"},{"location":"getting_started/#step-3-bear-portal","title":"Step 3: BEAR Portal","text":"<p>BEAR Portal provides web-based access to a range of BEAR services, such as JupyterLab, RStudio, and various other GUI applications. BEAR Portal is only available on campus or using the University Remote Access Service.</p>"},{"location":"getting_started/#step-4-launching-interactive-sessions","title":"Step 4: Launching interactive sessions","text":"<p>From the BEAR Portal there are three options for launching an interactive analysis session.</p> <ul> <li> <p>Some software packages have GUI Apps installed on BlueBEAR that can be launched from the BEAR Portal - the main example for neuroimaging analysis is MATLAB.</p> </li> <li> <p>JupyterLab and RStudio are installed as standalone apps that can be launched from the BEAR Portal (note that only packages installed on BEAR Apps are available to load in JupyterLab).</p> </li> <li> <p>A complete Linux Desktop can be launched as the BlueBEAR GUI. BlueBEAR GUI is effectively a blank-slate Linux desktop, into which you can load the modules for various applications, specify environment variables etc. by using the built-in Terminal client, and then ultimately launch the interface for the application that you require.</p> </li> </ul>"},{"location":"getting_started/#step-5-running-cluster-jobs-with-slurm","title":"Step 5: Running cluster jobs with Slurm","text":"<p>There are two ways to submit a cluster job - the BlueBEAR terminal and the job submission page on BEAR Portal</p> <p>BlueBEAR Terminal Once you have prepared a submission script, you can go to that location in the BEAR Portal file browser and click 'Open in terminal' in the top. This will open a terminal session from which you can submit, monitor and (optionally) cancel your job using <code>sbatch</code>, <code>squeue</code> and <code>scontrol</code>.</p> <p>Note</p> <p>These terminal sessions are ONLY intended for submitting and monitoring cluster jobs - not for active analyses. This should be carried out on the BEAR GUI or similar.</p> <p>BlueBEAR Job Composer this is a GUI page which helps you to write a new job to submit to BlueBEAR using the job composer.</p>"},{"location":"making_a_contribution/","title":"Making a contribution","text":"<p>This page will teach you how to add contributions to the chbh-on-bear GitHub page. This page outlines the whole process, from installing Git to requesting your contribution to be added. We assume no knowledge of Git or GitHub.</p>"},{"location":"making_a_contribution/#installing-git","title":"Installing Git","text":""},{"location":"making_a_contribution/#linux","title":"Linux","text":"<p>You can install Git through your package manager in the terminal, this will depend on your particular distro.</p> <p>For Debian : </p> <pre><code>$ sudo apt install git-all\n</code></pre> <p>For Fedora :</p> <pre><code>$ sudo dnf install git-all\n</code></pre> <p>For other distros see other distro installs.</p>"},{"location":"making_a_contribution/#windows","title":"Windows","text":"<p>You can install git from a windows installer or by using a package manager similar to linux.</p> <p>Using Winget :</p> <pre><code>&gt; winget install -e --id Git.Git\n</code></pre>"},{"location":"making_a_contribution/#making-a-github-account","title":"Making a Github account","text":"<p>You will also need to have a GitHub account to be able to make a change request. Make an account on GitHub</p> <p>After making an account configure your git to use that account within your terminal.</p> <pre><code>$ git config --global user.email \"Add GitHub Email address here within quotes\"\n$ git config --global user.name \"Add GitHub Username here within quotes\"\n</code></pre> <p>You may also need to generate a personal access token :</p> <ul> <li>On GitHub click your profile picture</li> <li>Settings</li> <li>Developer Settings</li> <li>Personal Access Tokens </li> <li>Tokens (Classic)</li> <li>Generate New Token</li> <li>Repo</li> <li>Generate New Token</li> <li>Place this token somewhere safe this will be used for your password</li> </ul>"},{"location":"making_a_contribution/#working-with-git-locally","title":"Working with Git Locally","text":""},{"location":"making_a_contribution/#creating-a-branch","title":"Creating a Branch","text":"<p>A branch is a version of the project that is different from the main, this is made so that changes do not effect the main project.</p> <p>Check what branch you are on :</p> <pre><code>$ git branch -l\n</code></pre> <p>Create your own branch :</p> <pre><code>$ git checkout -b tommy_changes\n</code></pre> <p>This will create a new branch called \"tommy_changes\" and switch to it. You can check what branch you are in again to make sure you have switched. </p>"},{"location":"making_a_contribution/#making-changes","title":"Making changes","text":"<p>Once you are on your own branch you can start making changes. To make changes add or edit the markdown files in the \"Docs\" folder, this can be done in your usual text editor. If you are unfamiliar with markdown check out this guide If you have created a new markdown file then this can be added to the website in the \"mkdocs.yml\" file.</p> <p>Adding the page to mkdocs.yml : </p> <pre><code>nav:\n  - Python: software/python.md\n</code></pre>"},{"location":"making_a_contribution/#adding-your-changes","title":"Adding your changes","text":"<p>To check the status of you changes use : </p> <pre><code>$ git status\n</code></pre> <p>Use this whenever you're unsure as what is happening with your file changes.</p> <p>If you've created a new file add it to git using it's filename.</p> <p>Example file add :</p> <pre><code>$ git add docs/software/python.md\n</code></pre> <p>To see the differences you've made you can use git in your terminal.</p> <pre><code>$ git diff\n</code></pre> <p>Once you've made all the changes you would like to make, you can then save all these changes to your git branch. As good practice these changes should be similar in nature such as \"Correcting spelling errors\". </p> <p>Saving your changes to your branch :</p> <p><pre><code>$ git commit -m \"Correcting spelling errors\"\n</code></pre> This will save all your changes with the messsage \"Correcting spelling error\". This will be visable publically later and be used to explain your changes to others. </p>"},{"location":"making_a_contribution/#working-with-github","title":"Working with GitHub","text":""},{"location":"making_a_contribution/#pushing-those-changes-to-public-branch","title":"Pushing those changes to public branch","text":"<p>To put our changes on GitHub for the project so everyone can see. We must first make a public branch similar to how we created our local branch before. You will be prompted to enter your username for GitHub, use the username we set up before. It will then ask for a password, do not use your GitHub password, use your git token we generated before (Note when you type or copy this token in, it will not be shown in the terminal but it is registering inputs. This can be odd for users unfamiliar.). </p> <p>Creating GitHub branch : </p> <pre><code>$ git push --set-upstream origin tommy_changes\nUsername for 'https://github.com': TommyTeapot\nPassword for 'https://github.com': {Your token here}\n</code></pre> <p>To then push those changes to this new branch use : </p> <pre><code>$ git push origin tommy_changes\nUsername for 'https://github.com': TommyTeapot\nPassword for 'https://github.com': {Your token here}\n</code></pre> <p>This will then push these changes to the public branch that is viewable for everyone. If you wish to push another commit you can skip the creating a branch section.</p>"},{"location":"making_a_contribution/#making-a-request-for-your-contribution","title":"Making a request for your contribution","text":"<p>After doing all these previous steps the final thing you need to do is create a pull request. This lets the admins know that you want something merged into the main branch that will then be put automatically onto the chbh-on-bear page. </p> <ul> <li>In your browser go onto the chbh-on-bear GitHub page</li> <li>Then on branches select the branch that you have created and made your commits to</li> <li>Click \"Compare and pull request\"</li> <li>Type the title and description of your pull request</li> <li>Check will be run automatically on your pull request and then will be reviewed by the admin team</li> </ul> <p>If review is sucessesful your changes will be merged into the main branch. Otherwise there is a section to have a conversation about those changes and add more commits. Feel free to make any changes you feel are valuable and thank you for contributing!</p>"},{"location":"making_a_contribution/#changes-to-the-main-branch","title":"Changes to the main branch","text":"<p>When working on this project and making multiple commits it's possible the main branch will be updated. It's important to work on a version that is close to the live version to avoid conflicts. </p> <p>Move onto main branch : </p> <pre><code>$ git checkout main\n</code></pre> <p>Check you are on the main branch : </p> <pre><code>$ git branch\n* main\n</code></pre> <p>Get updated main branch :</p> <pre><code>$ git fetch origin \n</code></pre> <p>Pull the update into local main : </p> <pre><code>$ git pull origin main\n</code></pre> <p>Move back to your branch : </p> <pre><code>$ git checkout tommy_changes\nSwitched to branch tommy_changes\n</code></pre> <p>Check you are on your branch :</p> <pre><code>$ git branch\n* tommy_changes\n</code></pre> <p>Merge updated main into your branch : </p> <pre><code>$ git merge main\n</code></pre> <p>Update the public GitHub branch :</p> <pre><code>$ git push origin tommy_changes\n</code></pre> <p>This will update you local main and personal branch to be up to date with the current live version and then push that to the public version of the branch. Editing is done exactly the same as before, happy contributing! </p>"},{"location":"behaviour/","title":"Behavioural Testing at CHBH","text":"<p>Guides and documentation for behavioural data collection at the CHBH.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> <ul> <li>Cubicles</li> <li>Common Experimental Platform PCs</li> <li>Troubleshooting</li> </ul> </li> <li> <p>Eye Tracking</p> <p>Tracking eyes and pupilometry</p> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"behaviour/technical/cep/","title":"Common Experimental Platform PCs","text":"<p>Currently the Brain Stim Lab, the fMRI, the Mock, the MEG, fNIRS, the OPM and some Cubicles have identical stimulus presentation / response recovery PCs built specifically for research grade timing, durability and redundancy.</p> <p>We intend to install such CEP (common experimental platform) Stimulus machines in all suitable modalities. This will encourage paradigm mobility between the modalities (write once, run anywhere), and allow enhanced response from CHBH IT personnel.</p>"},{"location":"behaviour/technical/cep/#the-cep-pc","title":"The CEP PC","text":"<p>Note</p> <p>Information on log-ins, network names and administration of CEP PCs is covered on the CHBH sharepoint pages which require UoB SSO log in.</p>"},{"location":"behaviour/technical/cep/#hardware","title":"Hardware","text":"<p>High end Intel CPUs and 16GB of RAM on ASUS PRIME Z370-A II (or it's predecessor Z270-A) motherboards. Graphics are provided by AMD WX (4100 or 7100) series of workstation graphics cards, as specifically recommended by the author of the PsychoPhysics Toolbox (PTB) under Neurodebian.</p> <p>AMD WX 4100 &amp; WX7100 graphics cards. The WX7100 cards will be in the MEG (in transition from NVIDIA), MOCK and fMRI. 4100s in the cubicles and other modalities. (2023 will see new PCs equipped with the newer W7500 cards)</p> <p>Onboard audio is the recommended solution for the PTB, replacing the previous ASIO recommendation (which has been fully retired in recent version of PTB).</p> <p>AOC 24\" monitor 1920x1080@120Hz (to match the standard operation of the VPIxx projector in the MEG and fMRI chambers). Check that desktop refresh rate is set to 120Hz and that AMD FreeSync is disabled - otherwise the PTB will fail the SimpleMovieDemo test. Some PCs will now be equipped with 360Hz monitors in the EEG lab.</p> <p>Single monitors are indicated for precise timing control in the PTB. In Labs where multiple monitors are indicated, experimenters should use a hardware splitter and not a second output port on the AMD WX card (especially under Windows 10). The VPIXX Projector provides it's own pass through that preserves timing control.</p>"},{"location":"behaviour/technical/cep/#software","title":"Software","text":"<p>Generally Windows 10; MATLAB 2018a and 2019b, with the most recent PTB. PsychoPy 3.0.3. National Instruments DAQmx. LABJACK U3 package. Every machine should have an identical OS installation. We will be updating the MATLAB versions in the beginning of 2024.</p> <p>To provide a consistent experience. MATLAB will clean it's path of any non basic paths on restart. Please add suitable code to the beginning of your experiment, such as addpath(genpath(\u2018yourfolder)); . As this is a multi-user machine this allows us to avoid namespace clashes for inbuilt and bespoke scripts.</p> <p>All CEPs are capable of running Neurodebian 18 LTS; MATLAB 2018a, with the most recent PTB. This is the preferred platform for precise timing.</p> <p>See this article, from the author of PsychoPy, for a discussion of timing reliability betwixt PsychoPy/PTB and Windows/Linux.</p> <p>Some Labs may request that their CEP not be constantly connected to the Network.</p>"},{"location":"behaviour/technical/cep/#paradigm-location-windows","title":"Paradigm Location (Windows)","text":"<p>The C: boot drive is not for the storage of responses or paradigms. The C: boot drive is not backed up. The C: boot drive can and will be re-imaged at any time. A remote drive R: Remote Paradigms is provided to offer a shared repository of paradigms and your data. This will allow access from any other CEP PC. This is backed up. - How to Map the Remote Paradigms Drive. A second drive L: LOCAL is provided for paradigms to be hosted locally if your paradigm is impacted running from a network resource. This is not backed up.</p>"},{"location":"behaviour/technical/cubicles/","title":"Behavioural testing cubicles","text":""},{"location":"brainstim/","title":"Brain Stimulation at CHBH","text":"<p>Guidelines and documentation for all Brain Stimulation methods at CHBH</p> <ul> <li> <p>Lab overview</p> <p>Information about the CHBH brain stimulation lab</p> <ul> <li>Lab overview</li> </ul> </li> <li> <p>Focused Ultrasound Stimulation (FUS)</p> <p>Everything FUS-related, including pre-sonication planning</p> <ul> <li>Equipment Overview</li> <li>Planning with k-Plan</li> <li>Transducer Calibration</li> </ul> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"brainstim/tms/","title":"Transcranial magnetic stimulation (TMS)","text":"<p>TMS can be used to measure brain activity levels (e.g., using EMG for studies of the motor system), to interfere with brain activity (e.g., in perceptual or cognitive studies), or to induce changes in the brain (e.g., in clinical interventions). A TMS study at minimum needs a stimulator and a coil. TMS can be used in conjunction with other stimulation and recording modalities such as EMG, eye-tracking, MRI or EEG.</p>"},{"location":"brainstim/tms/#guidance","title":"Guidance","text":"<p>The following international consensus statements and guidance are required reading for all new TMS researchers.</p> <p>Rossini et al. 2015: Non-invasive electrical and magnetic stimulation of the brain, spinal cord, roots and peripheral nerves: basic principles and procedures for routine clinical and research application.</p> <p>Rossi et al. 2009: Safety and recommendations for TMS use in healthy subjects and patient populations, with updates on training, ethical and regulatory issues: expert guidelines</p>"},{"location":"brainstim/tms/#hardware","title":"Hardware","text":""},{"location":"brainstim/tms/#stimulator","title":"Stimulator","text":"<p>Magstim Rapid [model number]</p> <p></p> <p>The Rapid delivers biphasic pulses at up to [max] Hz. The intensity of stimulation will detemine how long each train of stimulation can be applied for.</p>"},{"location":"brainstim/tms/#coils","title":"Coils","text":"<ul> <li>[diameter] mm figure-of-eight [model number]</li> <li>[diameter] mm figure-of-eight [model number]</li> </ul>"},{"location":"brainstim/tms/#interface-devices","title":"Interface devices","text":"<p>[D-type x pins] digital input-output port.</p> <p>![image_of_back_of_TMS_here]</p>"},{"location":"brainstim/tms/#electromyography","title":"Electromyography","text":"<ul> <li>[do we have this?] 1401?</li> </ul>"},{"location":"brainstim/tms/#neuronavigation","title":"Neuronavigation","text":"<p>Some studies (e.g., on the motor system) may not use neuronavigation to locate the stimulation target, because they can use body movement or EMG instead. For targeting other brain areas, neuronavigation may be important. For further details, see the main neuronavigation page.</p>"},{"location":"brainstim/tms/#software","title":"Software","text":"<p>TMS studies can be run in stand-alone mode, using only the software interface provided with the stimulator. Alternatively, the TMS can be controlled by an external device using 5V TTL pulses or a digital interface.</p>"},{"location":"brainstim/tms/#tmsmultilab","title":"TMSMultiLab","text":"<p>Set up by members of the University of Birmingham, TMSMultiLab is an international community of researchers using TMS that shares guidance, resources, code &amp; data for TMS research. New members are always welcome. Contact Nick Holmes for more details.</p>"},{"location":"brainstim/FUS/calib/","title":"Equipment Calibration","text":"<p>PLACEHOLDER</p> <p>Include SOP for transducer calibration in water bath etc.</p>"},{"location":"brainstim/FUS/equip/","title":"FUS Equipment","text":"<p>The following equipement is part of the 'standard' FUS setup at CHBH:</p> <ul> <li> <p>NeuroFUS PRO Transducer Power Output (TPO). Upgraded to TPO-105, including the following features:</p> <ul> <li>Up to 400W electrical power</li> <li>Up to 100W per channel</li> </ul> </li> <li> <p>NeuroFUS Transducers (4):</p> <ul> <li>CTX-500-4CH 500kHz, 4 element</li> <li>CTX-250-4CH 250kHz, 4 element</li> <li>CTX-500-2CH 500kHz, 2 element</li> <li>DPX-500-4CH 'Deep Transducer', 500kHz, 4 element</li> </ul> </li> <li> <p>Transducer Verification Kit</p> <ul> <li>Hydrophone</li> <li>Test container with transducer and hydrophone holder</li> <li>Multimeter</li> </ul> </li> <li> <p>k-Plan Software and software licenses</p> </li> </ul> <p>We additionally have the following equipment for deploying FUS in the MRI scanner (not currently in active use)</p> <ul> <li>NeuroFUS MRI-compatible Transducer and Cable upgrade</li> <li>BrainSight MRI Camera Stand</li> <li>BrainSight MRI-compatible trackers (for volunteer and transducers)</li> </ul>"},{"location":"brainstim/FUS/kplan/","title":"Pre-Sonication Planning with k-Plan","text":"<p>This page will eventually include a walkthrough for using k-Plan to perform pre-sonication planning.</p>"},{"location":"eeg/","title":"EEG at CHBH","text":"<p>Guides and documentation for EEG analysis and data collection.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> <ul> <li>The EEG Devices</li> </ul> </li> <li> <p>Data Acquisition</p> <p>Equipment and setup for data collection</p> <p>Preparing code for EEG </p> </li> <li> <p>Stimulus Delivery</p> <p>Software and methods for stimulus presentation</p> </li> <li> <p>Quality Control</p> <p>Analysis and data quality procedures</p> <ul> <li>FieldTrip</li> </ul> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"eeg/acquisition/how_to_acquire/","title":"EEG Data Acquisition Checklist","text":"<p>Click on the checklists to mark your progress through data collection.</p>"},{"location":"eeg/acquisition/how_to_acquire/#check-hardware","title":"Check Hardware","text":"<ul> <li> <p> make sure you're sending triggers</p> in your experimentin a sample scipt <ul> <li>run your experiment </li> </ul> <ul> <li>locate x script on the stimulus computer</li> <li>make sure everything is turned on</li> </ul> </li> <li> <p> make sure batteries are charged</p> </li> <li> <p> ...</p> </li> </ul>"},{"location":"eeg/acquisition/how_to_acquire/#prepare-eeg-room","title":"Prepare EEG room","text":""},{"location":"eeg/acquisition/how_to_acquire/#prepare-participant","title":"Prepare Participant","text":""},{"location":"eeg/acquisition/how_to_acquire/#prepare-electrodes","title":"Prepare electrodes","text":"<ul> <li> select correctly sized cap</li> <li> insert electrodes into cap</li> <li> insert gel</li> <li> check signal</li> </ul>"},{"location":"eeg/acquisition/how_to_acquire/#start-recording","title":"Start recording","text":""},{"location":"eeg/acquisition/how_to_acquire/#stop-recording","title":"Stop recording","text":""},{"location":"eeg/acquisition/how_to_acquire/#tidying-up","title":"Tidying up","text":""},{"location":"eeg/acquisition/preparing_code_for_EEG/","title":"Setting up your code to collect good EEG data","text":""},{"location":"eeg/acquisition/preparing_code_for_EEG/#sending-triggers","title":"sending triggers","text":"<p>For EEG timing is of the essence! Even if you do not care about exact stimulus timing, you really should care about logging the time relevant events happen as accurately as possible!</p> <p>Documentation and code for how to send triggers with labjack</p> Example Code MatlabExample Code Python <p>Here's some example code for how to define and send triggers in Matlab.  For this to work, make sure you have downloaded the code for labjack to your task code folder and added the path (see example).</p> <p>Note</p> <p>Matlab example contributed by Romy Froemer.</p> <pre><code>    %% setting EEG via console prompt at the start of the task\n    novalidinput = 1;\n    while  novalidinput==1\n        expParams.isEEGsession = (input('Do EEG? y or n: ','s'));\n\n        if isstrprop(p.isET, 'upper')\n            expParams.isEEGsession = lower(expParams.isEEGsession);\n        end\n\n        if strcmp(expParams.isEEGsession, 'y')\n            expParams.isEEGsession = 1;\n            novalidinput = 0;\n        elseif strcmp(expParams.isEEGsession, 'n')\n            expParams.isEEGsession=0;\n            novalidinput = 0;\n        end\n    end\n\n    %% setting up the EEG\n    if expParams.isEEGsession\n        addpath('taskCode/EEG_code/'); % in this example, the labjack code lives in a folder called EEG_code within a folder called taskCode\n\n        if expParams.isEEGsession\n\n            try\n                L = lab_init_sa;\n                expParams.EEGpars.ext.L = L;\n                disp('EEG SUCCESSFULLY CONFUFURED!');\n                % here also define event codes\n                % 1x = stimulus onset, 2x = response onset; Confidence = trig +20\n                % x = phase: FAM = 1, RATE = 2, CHOICE = 0\n\n                % FAM triggers\n                expParams.EEGpars.trigs.FamStimCode = 11; % a task relevant stimulus comes on - Choice\n                expParams.EEGpars.trigs.FamRespCode = 21; % a response is given\n\n                % RATE Triggers\n                expParams.EEGpars.trigs.RateStimCode = 12;\n                expParams.EEGpars.trigs.RateRespCode = 22; % -  RATE\n                expParams.EEGpars.trigs.ConfPromptCode = 32;\n                expParams.EEGpars.trigs.ConfRespCode = 42;\n\n                % CHOICE Triggers\n                expParams.EEGpars.trigs.trialCode = 1;      % a trial begins (first item)\n                expParams.EEGpars.trigs.stimCode = 10;      % a task relevant stimulus comes on - Choice (all items after first)\n                expParams.EEGpars.trigs.respCode = 20;      % a response is given\n                expParams.EEGpars.trigs.fbCode = 30;        % show chosen\n                expParams.EEGpars.trigs.erCode = 40;        % error response code\n                expParams.EEGpars.trigs.NOrespCode = 99;    % trial ended without a response\n\n\n                expParams.EEGpars.trigs.runStartCode = 50;\n                expParams.EEGpars.trigs.runEndCode = 60;\n            catch\n                disp('FAILED EEG CONFIGURATION!  :-(');\n            end\n\n\n            try\n                % Turn off all pins in the parallel port\n                lab_put_code_sa(expParams.EEGpars.ext.L,0); \n                disp('EEG TRIGGER SUCCESSFUL!');\n            catch\n                disp('FAILED EEG TRIGGER!  :-(');\n            end\n\n\n        end\n    end\n\n    %% Sending an actual trigger (example)\n\n\n        % here's where stimuli are actually shown\n        Screen(p.wPtr, 'Flip',0,1);  % don't clear!\n\n        if expParams.isEEGsession &amp;&amp; ~expParams.CHOICE.isPracticeNow\n            lab_put_code_sa(expParams.EEGpars.ext.L,expParams.EEGpars.trigs.trialCode);\n        end\n</code></pre> <p>Here's some example code for how to send triggers in python.  All following Python code snippets are from Python code elements run by Opensesame.</p> <p>1)  Import the labjackU3 module at the beginning of the experiment: <pre><code>    import labjackU3\n</code></pre></p> <p>2)  Insert a Python code element in the trial sequence at exactly the moment you want to sent the trigger and sent the trigger you want from that code element. In this example the trigger \u201c99\u201d is sent everytime the Python code element is executed within the trial sequence:     <pre><code>    labjackU3.trigger(99) \n</code></pre> The triggers can be either hard-coded as in the example above or soft-coded and defined somewhere else, as in the following example. Here the trigger with information about the memory array is defined somewhere else in the experiment (e.g. the run file) in a variable named \u201ctrigger_ma_info\u201d:     <pre><code>    labjackU3.trigger(trigger_ma_info)\n</code></pre> Example of a trial sequence in opensesame, to illustrate the placement of the python code snippets.</p> <p></p> <p>Caveat: LabJack has a sleep time implemented this will influence the timing of your task, as the python code sending the trigger is paused after sending it, this could become relevant for experiments that need highly precise timing. The pause duration of LabJack can be changed with a line of code that is inserted after importing the LabJack module. In this example the pause time is reduced to 2.5ms.     <pre><code>    labjackU3.DURATION = 0.025\n</code></pre> When triggers are sent closely after the LabJack pause might not be sufficient to prevent trigger overlap, so you can either increase the labjackU3.DURATION or you use the opensesesame module \u201ctime\u201d to pause the experiment. To do that you need to import \u201ctime\u201d at the beginning of the experiment and set it to sleep after sending a trigger. In this example, time is paused for 5ms.     <pre><code>    import time\n\n     time.sleep(0.05) \n</code></pre></p>"},{"location":"eeg/acquisition/preparing_code_for_EEG/#stimulus-timing","title":"stimulus timing","text":""},{"location":"eeg/analysis/fieldtrip/","title":"Fieldtrip on Slurm","text":"<p>Note</p> <p>Example contributed by Ben Griffiths.</p> <p>This is an example script running a fieldtrip analysis on EEG data acqurired during a visual flicker task.</p> <p>The data is read in, filtered, epoched, ICA'd, re-referenced, then plotted. The core function can be executed on the MATLAB GUI App during an interactive session, or submitted to BlueBEAR using the <code>bash</code> script below.</p>"},{"location":"eeg/analysis/fieldtrip/#core-processing-script","title":"Core processing script","text":"<p>The following code can be saved as <code>basic_preprocessing.m</code>.</p> <pre><code>%% Basic Preprocessing\n% A script to demonstrate how one can (superficially) preprocessing EEG\n% data using Fieldtrip, Matlab and BlueBEAR.\n%\n% Benjamin J. Griffiths (b.griffiths.1 [at] bham.ac.uk)\n% 28th March 2023\n\n%% Prepare Workspace\n% define root directory where data is stored\nroot_dir = '/rds/projects/g/griffibz-example-project/msc-eeg-23/';\n\n% add fieldtrip to path\naddpath('/rds/projects/g/griffibz-example-project/fieldtrip/')\nft_defaults\n\n% define participant number\nsubj = 1;\n\n%% Filter Raw Data\n% load data\ncfg         = [];\ncfg.dataset = sprintf('%s/bids/sub-%02.0f/eeg/sub-%02.0f_task-eeg-flicker_eeg.eeg', root_dir, subj, subj); % dynamically determine dataset name\ndata        = ft_preprocessing(cfg);\n\n% remove external and trigger channels\ncfg         = [];\ncfg.channel = {'all', '-EX*', '-Status'}; % select all channels except any external (-EX*) or trigger (-Status) channel\ndata        = ft_selectdata(cfg, data);\n\n% filter data\ncfg             = [];\n%cfg.hpfilter    = 'yes';   % apply high-pass filter\n%cfg.hpfreq      = 0.8;     % use high-pass to suppress frequencies &lt; 0.8Hz\ncfg.lpfilter    = 'yes';   % apply low-pass filter\ncfg.lpfreq      = 120;     % use low-pass to suppress frequencies &gt; 120Hz\ncfg.bsfilter    = 'yes';   % apply band-pass filter\ncfg.bsfreq      = [49 51]; % use band-pass to suppress frequencies netween 49Hz and 51Hz\ndata            = ft_preprocessing(cfg, data);\n\n%% Epoch Data\n% load in BIDS event file\nevents = readtable(sprintf('%s/bids/sub-%02.0f/eeg/sub-%02.0f_task-eeg-flicker_events.tsv', root_dir, subj, subj),'Filetype','text'); % dynamically determine dataset name\n\n% define Fieldtrip-style event structure\ntrl_start = -2; % start trial 2 seconds before trigger\ntrl_end = 4; % end trial 4 seconds after trigger\ntrl_def(:,1) = events.sample + (trl_start * data.fsample); % define samples to start trial\ntrl_def(:,2) = events.sample + (trl_end * data.fsample); % define samples to end trial\ntrl_def(:,3) = trl_start * data.fsample; % define when time = 0 occurs relative to start of trial\n\n% epoch data\ncfg = [];\ncfg.trl = trl_def;\ndata = ft_redefinetrial(cfg, data);\n\n% load in trialinfo\nload(sprintf('%s/bids/sourcedata/sub-%02.0f_trialinfo.mat', root_dir, subj))\ndata.trialinfo = trialinfo; % add trialinfo to data structure\n\n% tidy workspace\nclear events trl_start trl_end trl_def trialinfo\n\n%% Run ICA\n% restrict to retrieval trials\ncfg         = [];\ncfg.trials  = find(cellfun(@(x) strcmpi(x.trl_type, 'retrieval'), data.trialinfo));\ndata        = ft_selectdata(cfg, data);\n\n% reduce sample rate\ncfg = [];\ncfg.resamplefs = 256; % drop sample rate from 1024Hz to 256Hz\ndata = ft_resampledata(cfg, data);\n\n% run ica\nrng(subj) % set random seed to ensure reproducible outputs every time the function is run\nica = ft_componentanalysis([], data); % \"cfg\" need not be defined if using default settings\n\n% visualise first 20 components (commented to stop execution when running via Slurm)\n%ft_topoplotIC(struct('component',1:20,'layout','biosemi128.lay'), ica)\n\n% remove components\ncfg             = [];\ncfg.component   = [1 3]; % 1 = eyeblink, 3 = saccade\ndata            = ft_rejectcomponent(cfg, ica);\n\n%% Re-reference Data\n% re-reference to the average of all channels\ncfg = [];\ncfg.reref = 'yes';\ncfg.refchannel = 'all';\ndata = ft_preprocessing(cfg, data);\n\n%% Plot Results\n% get timelocked average of data\ncfg = [];\ncfg.channel = 'A*'; % restrict to posterior quadrant of channels\ntml = ft_timelockanalysis(cfg, data);\n\n% baseline correct timelocked average\ncfg = [];\ncfg.baseline = [-0.25 -0.05]; % set baseline as -250ms to -50ms\ntml = ft_timelockbaseline(cfg, tml);\n\n% plot ERP\nh = figure;\nsubplot(2,1,1); hold on\nplot(tml.time, mean(tml.avg))\nxlim([-0.5 2.5])\nxline(0,'k--')\nyline(0,'k-')\nxlabel('Time (s)')\nylabel('Amplitude (uV)')\ntitle('Visual Evoked Potential')\n\n% cycle through trials\npow = cell(8, 1); % create empty cells for eight conditions\nfor trl = 1 : numel(data.trial)\n    condition = data.trialinfo{trl}.ret_freq; % determine flicker condition\n    channels_A = cellfun(@(x) strncmpi(x, 'A', 1), data.label); % identify posterior channels\n    signal = data.trial{trl}(channels_A, :); % extract signal over posterior channels\n    pow{condition}(end+1,:) = mean(abs(fft(signal')')); % compute FFT\nend\n\n% determine frequencies of FFT\nfreqs = linspace(0, data.fsample, size(pow{1},2));\n\n% plot FFT for each condition\nsubplot(2,1,2); hold on\nfor condition = 1 : numel(pow)\n    plot(freqs,mean(pow{condition}));\nend\nxlim([6, 42])\nylim([0, 700])\ntitle('Power Spectrum')\nxlabel('Frequency (Hz)')\nylabel('Power (arb. units)')\nlegend({'60Hz','40Hz','30Hz','24Hz','20Hz','17.1Hz','15Hz','Baseline'})\n\n% save figure in root directory\nsaveas(h, sprintf('%s/basic_preproc_output.jpg', root_dir))\n</code></pre>"},{"location":"eeg/analysis/fieldtrip/#cluster-submit-script","title":"Cluster submit script","text":"<p>The following can be saved as a shell script and submitted to the cluster using <code>sbatch</code>.</p> <pre><code>#!/bin/bash\n\n#SBATCH --ntasks 10\n#SBATCH --nodes 1\n#SBATCH --time 1:0:0\n#SBATCH --qos bbdefault\n#SBATCH --mail-type ALL\n\nset -e\n\nmodule purge; module load bluebear\nmodule load MATLAB/2021b\n\nmatlab -nodisplay -r \"basic_preprocessing; exit;\"\n</code></pre>"},{"location":"eeg/hardware/eeg/","title":"EEG at CHBH","text":"<p>EEG (electroencephalogram) is a non-invasive technique where electrodes are placed on a person's scalp to record electrical activity in the brain.</p> <ul> <li> <p>It does this by recording changes in potential difference. </p> </li> <li> <p>EEG can capture hundreds of data points per second and therefore is a great tool for researching the chronology of mental processes. </p> </li> <li> <p>EEG is completely safe and pain free for participants.</p> </li> </ul> <p>The CHBH has 3 BioSemi's Active Two housed in 2 labs. These are housed in the Gisbert Kapp EEG facility and the boothed EEG lab in 52 Pritchatt's Rd. Currently the latter affords simultaneous eye-tracking and prospectively, all EEG labs will. In addition to these stand-alone systems, we have an MR compatible Brain Vision system and a built-in MEG compatible system.</p> <p>We also have Polhemus Fastrak with Brainstorm to digitise EEG electrode positions and head shapes. </p>"},{"location":"eeg-fmri/","title":"EEG-fMRI at CHBH","text":"<p>Guides and documentation for simultaneous EEG-fMRI analysis and data collection.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> </li> <li> <p>Data Acquisition</p> <p>Equipment and setup for data collection</p> </li> <li> <p>Stimulus Delivery</p> <p>Software and methods for stimulus presentation</p> </li> <li> <p>Quality Control</p> <p>Analysis and data quality procedures</p> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"eye-tracking/","title":"Eye-tracking at CHBH","text":"<p>Guides and documentation for Eye-tracking analysis and data collection.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> <ul> <li>The Eye-traking Devices</li> </ul> </li> <li> <p>Data Acquisition</p> <p>Equipment and setup for data collection</p> <p>Preparing code for Eye-tracking </p> </li> <li> <p>Stimulus Delivery</p> <p>Software and methods for stimulus presentation</p> </li> <li> <p>Quality Control</p> <p>Analysis and data quality procedures</p> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"eye-tracking/acquisition/how_to_acquire/","title":"EEG Data Acquisition Checklist","text":"<p>Click on the checklists to mark your progress through data collection.</p>"},{"location":"eye-tracking/acquisition/how_to_acquire/#check-hardware","title":"Check Hardware","text":"<ul> <li> <p> make sure you're sending triggers</p> in your experimentin a sample scipt <ul> <li>run your experiment </li> </ul> <ul> <li>locate x script on the stimulus computer</li> <li>make sure everything is turned on</li> </ul> </li> <li> <p> make sure batteries are charged</p> </li> <li> <p> ...</p> </li> </ul>"},{"location":"eye-tracking/acquisition/how_to_acquire/#prepare-eeg-room","title":"Prepare EEG room","text":""},{"location":"eye-tracking/acquisition/how_to_acquire/#prepare-participant","title":"Prepare Participant","text":""},{"location":"eye-tracking/acquisition/how_to_acquire/#prepare-electrodes","title":"Prepare electrodes","text":"<ul> <li> select correctly sized cap</li> <li> insert electrodes into cap</li> <li> insert gel</li> <li> check signal</li> </ul>"},{"location":"eye-tracking/acquisition/how_to_acquire/#start-recording","title":"Start recording","text":""},{"location":"eye-tracking/acquisition/how_to_acquire/#stop-recording","title":"Stop recording","text":""},{"location":"eye-tracking/acquisition/how_to_acquire/#tidying-up","title":"Tidying up","text":""},{"location":"eye-tracking/acquisition/preparing_code_for_ET/","title":"Setting up your code to collect good ET data","text":""},{"location":"eye-tracking/acquisition/preparing_code_for_ET/#calling-eye-tracker-and-sending-messages","title":"calling eye-tracker and sending messages","text":"<p>For eye-tracking timing is of the essence! Even if you do not care about exact stimulus timing, you really should care about logging the time relevant events happen as accurately as possible!</p> Example Code MatlabExample Code Python <p>Here's some example code for how to define and send messages in Matlab. </p> <p>Note</p> <p>Matlab example contributed by Romy Froemer.</p> <pre><code>    %% setting ET via console prompt at the start of the task\n    novalidinput =1;\n    while novalidinput == 1\n    p.SessionInfo.isET = (input('Do eye-tracking? y or n: ','s'));\n\n    if isstrprop(p.SessionInfo.isET,'upper')\n       p.SessionInfo.isET = lower(p.SessionInfo.isET); \n    end\n\n    if strcmp(p.SessionInfo.isET, 'y')\n        p.SessionInfo.isET = 1;\n        novalidinput =0;\n    elseif strcmp(p.SessionInfo.isET, 'n')\n        p.SessionInfo.isET=0;\n        novalidinput =0;\n    end\n    end\n\n    %% initializing file and eye-tracker\n    % set file name\n    p.TaskParams.ET.edfFile =  strcat('MPRD',p.SubID); % define filename for edf file\n    %here, initialize a structure corresponding to the parameters of the\n    %display where stimuli are being created, for use in calculating the\n    %DVA of eye position location. The argument to pass is the screen\n    %number that corresponds to where the already opened window pointer is. (see function below)\n    p = initializeEyetrackingParams(p.screenParams.screenNum,p);\n\n    %% example for sending messages:\n    if (p.SessionInfo.isET &amp;&amp; ~p.SessionInfo.isPractice)\n        Eyelink('Message', 'DotsOn');\n    end\n\n    %% cali instructions %%%%\n        showETInstruction(p, p.SessionInfo.Instructions.CaliInstruction, 'to start the calibration. While doing so, please look at the + above.')\n        p = EyelinkSetup(1,p);\n        save(fullfile(p.SessionInfo.filePath,['MPRDM_v', p.Version, '_',p.SubID,'_',p.SessionInfo.date,'.mat']),'p');\n        Eyelink('IsConnected');\n        if p.TaskParams.ET.recordContinuous ==1\n            Eyelink('Command', 'set_idle_mode');\n            WaitSecs(0.05);\n            Eyelink('StartRecording');\n            % record a few samples before we actually start displaying\n            % otherwise you may lose a few msec of data\n            WaitSecs(0.1);\n        end\n\n    %% shut down eyeLink\n    if p.SessionInfo.isET\n       % End of Experiment;\n       %% when adding EEG add start trigger here\n       %% add end message:\n       Eyelink('Message', 'ExpEnd');\n       % close the file firsts\n       % close graphics window, close data file and shut down tracker\n       Eyelink('Command', 'set_idle_mode');\n       WaitSecs(0.5);\n       Eyelink('CloseFile');\n       EyelinkSetup(0,p) % receiving (any) files and shutting down eyelink\n    end\n\n    %% function to start/stop eye-tracking which saves and pulls file\n    function [p] = EyelinkSetup(startOrStop, p)\n\n    %Local function to set up defaults for each Eyelink and start recording.\n    %Designed to be called before starting each block. Requires previous call\n    %to EyelinkInitDefaults to work appropriately\n\n    %startOrStop is a binary variable, where 1 = 'start up the Eyelink and\n    %initialize', and 0 = 'turn off Eyelink'\n\n    if startOrStop==1 %starting up the Eyelink\n\n        p.TaskParams.ET.el=EyelinkInitDefaults(p.screenParams.wPtr); %initialize the Eyelink default settings\n\n        % Initialize Eyelink connection (real or dummy). The flag '1' requests\n        % use of callback function and eye camera image display:\n        if ~EyelinkInit([], 1)\n            fprintf('Eyelink Init aborted.\\n');\n            cleanup;\n           return;\n        end\n\n        if p.TaskParams.ET.save_edf\n            i = Eyelink('Openfile', p.TaskParams.ET.edfFile);\n            if i~=0\n                fprintf('Cannot create EDF file ''%s'' ', p.TaskParams.ET.edfFile);\n                Eyelink( 'Shutdown');\n                Screen('CloseAll');\n                return;\n            end\n            Eyelink('command', 'add_file_preamble_text ''Recorded by EyelinkToolbox MPRDM experiment''');\n        end\n\n        if ~isfield(p.TaskParams.ET,'eye_used')\n            p.TaskParams.ET.eye_used=0;\n        end\n\n\n        % Send any additional setup commands to the tracker\n        Eyelink('Command','calibration_type = HV5'); % calibration type changed 12/01/2023 from HV9 due to issues with corners\n        Eyelink('Command','recording_parse_type = GAZE');\n\n        if p.TaskParams.ET.save_edf\n            % set EDF file contents using the file_sample_data and\n            % file-event_filter commands\n            % set link data thtough link_sample_data and link_event_filter\n            Eyelink('command', 'file_event_filter = LEFT,RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,BUTTON,INPUT');\n            Eyelink('command', 'link_event_filter = LEFT,RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,BUTTON,INPUT');\n        else\n            Eyelink('Command','link_event_filter = LEFT,RIGHT,FIXATION,SACCADE,BLINK');\n        end\n\n        %perform calls to the Eyelink host to get the correct queued eye data\n        Eyelink('command','link_sample_data = LEFT,RIGHT,GAZE,AREA,GAZERES,HREF,PUPIL,STATUS,INPUT,HMARKER');\n\n        % HH Settings\n        Eyelink('command', 'file_sample_data  = LEFT,RIGHT,GAZE,HREF,AREA,GAZERES,STATUS,INPUT');\n        %   Eyelink('command', 'link_sample_data  = LEFT,RIGHT,GAZE,GAZERES,AREA,STATUS,INPUT');\n\n        Eyelink('command','inputword_is_window = ON');\n\n        Eyelink('Command','sample_rate = 1000');\n\n        % changed 01/2022: we read in the coordinates from display params (like HH)\n        Eyelink('command','screen_pixel_coords = %ld %ld %ld %ld', 0, 0, p.TaskParams.ET.dp.w_width-1, p.TaskParams.ET.dp.w_height-1);\n        Eyelink('message', 'DISPLAY_COORDS %ld %ld %ld %ld', 0, 0, p.TaskParams.ET.dp.w_width-1, p.TaskParams.ET.dp.w_height-1);\n\n        %Eyelink('Command','screen_pixel_coords = 0 0 1024 768');\n        %Eyelink('Command','screen_pixel_coords = 0 0 1151 863'); %need to fix the resolution input thing here\n        Eyelink('Command','draw_line = x1, y1, x2, y2, 0');\n        Eyelink('Command','file_event_data = GAZE,VELOCITY');\n        Eyelink('Command','link_event_data = GAZE,VELOCITY');\n        Eyelink('Command','saccade_velocity_threshold = 200');\n        Eyelink('Command','saccade_motion_threshold = 0.15');\n\n        % what is that and what does it do?\n        %result = Eyelink('StartSetup',1);\n        result = EyelinkDoTrackerSetup(p.TaskParams.ET.el); % do calibration\n\n        %Eyelink('StartRecording');\n\n        disp('Eyelink up and running!');\n\n    elseif startOrStop==0 %done with Eyelink for now, shut it down\n\n        if p.TaskParams.ET.save_edf\n            try\n                fprintf('Receiving data file ''%s''\\n', p.TaskParams.ET.edfFile );\n                status=Eyelink('ReceiveFile');\n                if status &gt; 0\n                    fprintf('ReceiveFile status %d\\n', status);\n                end\n                if 2==exist([p.TaskParams.ET.edfFile, '.edf'], 'file')\n                    fprintf('Data file ''%s'' can be found in ''%s''\\n', p.TaskParams.ET.edfFile, pwd);\n                    movefile([p.TaskParams.ET.edfFile, '.edf'], 'data/ET_Results')\n                end\n            catch\n                fprintf('Problem receiving data file ''%s''\\n', p.TaskParams.ET.edfFile );\n            end\n        end\n        %reset sampling rate for other experimenter's use and shutdown the Eyelink\n        if p.TaskParams.ET.resetParams\n            Eyelink('Command','sample_rate = 250');\n            Eyelink('Command','calibration_type = HV9');\n        end\n        disp('....now clearing eyelink! :)');\n        Eyelink('Shutdown');\n        p.TaskParams.ET.el=-1;\n\n    end\n</code></pre>"},{"location":"eye-tracking/hardware/eye-tracking/","title":"Eye-tracking at CHBH","text":"<p>Eye tracking  is a non-invasive technique that allow the recording of eye-movements and pupillary responses.</p> <ul> <li> <p>It does this by tracking changes in in th esize and relative location of the pupil and pupillary reflexes. </p> </li> <li> <p>Eye-tracking can capture hundreds of data points per second and therefore is a great tool for researching the chronology of mental processes. </p> </li> <li> <p>Eye-tracking is completely safe and pain free for participants.</p> </li> </ul> <p>The CHBH has multiple EyeLink 1000 Plus eye-trackers housed in multiple labs. Eye-movements can be recorded alone or together with other imaging methods, including EEG and MRI.</p>"},{"location":"fnirs/","title":"fNIRS at CHBH","text":"<p>Guides and documentation for functional Near-Infrared Spectroscopy analysis and data collection.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> </li> <li> <p>Data Acquisition</p> <p>Equipment and setup for data collection</p> </li> <li> <p>Stimulus Delivery</p> <p>Software and methods for stimulus presentation</p> </li> <li> <p>Quality Control</p> <p>Analysis and data quality procedures</p> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"meg/","title":"MEG at CHBH","text":"<p>Guides and documentation for MEG analysis and data collection at the CHBH.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> <ul> <li>The MEG</li> <li>MEG Safety<ul> <li>MEG Contraindications</li> </ul> </li> <li>How to Open the MSR<ul> <li>MSR Dimensions</li> </ul> </li> <li>Helium Recycling System (the IHR)</li> <li>LabJack</li> <li>SIGGI II Impedance Meter</li> <li>EyeLink 1000 Plus Operations Guide<ul> <li>Copying EyeLink EDF Files</li> <li>EyeLink Demo Code</li> </ul> </li> <li>Charging EyeLink batteries</li> <li>EyeLink Settings</li> <li>EyeLink Analog Output</li> <li>VPixx X-Rite i1Display Pro</li> </ul> </li> <li> <p>Data Acquisition</p> <p>Equipment and setup for data collection</p> <ul> <li>MEG Acquisition Checklist<ul> <li>Noisy Channels</li> <li>Fixing Noisy Channels<ul> <li>Nosiy Data</li> </ul> </li> <li>Perform a \"RAP\"</li> <li>Restart Acquisition</li> <li>Metal items Checklist</li> <li>Atypical MEG Signals</li> </ul> </li> <li>Moving the Gantry</li> <li>Correct Positioning &amp; Usage of EEG Caps</li> <li>EEG &amp; MEG</li> <li>Copying MEG data</li> <li>MEG Consumables</li> <li>Tidying Up<ul> <li>Cleaning EEG caps</li> </ul> </li> <li>Audio Delay Testing</li> <li>MISC Channels</li> </ul> </li> <li> <p>Lab Safety/Useful Documents</p> <p>Procedures to follow in case of an emergency</p> <ul> <li> <p>Safety Procedures</p> </li> <li> <p>Metal Detection</p> </li> <li> <p>Documentation</p> </li> </ul> </li> <li> <p>Stimulus Delivery/Response Collection</p> <p>Software/Hardware and methods for stimulus presentation and data collection</p> <ul> <li> <p>Stimulus Hardware Layout</p> </li> <li> <p>VPixx PROPixx Projector</p> </li> <li> <p>VPixx SOUNDPixx stereo audio system</p> </li> <li> <p>Eyetracking - SR Eyelink 1000 tracker</p> </li> <li> <p>Button Box - fMRI Button Pad (2-Hand) System (NATA Technologies)</p> </li> </ul> </li> <li> <p>Quality Control</p> <p>Analysis and data quality procedures</p> <ul> <li>MNE-Python</li> </ul> </li> <li> <p>Troubleshooting</p> <p>Issues encountered, when occured (if required), usual solutions</p> <ul> <li>MEG Power Shutdown/Restart</li> </ul> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"meg/acquisition/atypical_meg_signals/","title":"Atypical MEG signals","text":"<p>\"Artifacts\" are unwanted noise in the acquired data that may or may not interfere/mask the signal expected to be seen.  Any artifact found will need to be removed from acquired data before any analysis is performed, and obviously they are needed to be identified first. Artifacts can be caused by the environment or by the participant, and common examples are:</p>"},{"location":"meg/acquisition/atypical_meg_signals/#pysiological","title":"Pysiological","text":"<ul> <li>Eye blinks (EOG) - Electrooculogram.</li> <li>Heart beats (ECG) - Electrocardiogram.</li> <li>Muscle artifacts (EMG) - Electromyogram.</li> <li>Head movements (will include neck EMG artifacts).</li> <li>Dental artifacts (large amalgam fillings, orthodontic applances).</li> </ul>"},{"location":"meg/acquisition/atypical_meg_signals/#environmental-system","title":"Environmental / System","text":"<ul> <li>Power line noise (Mains 50Hz).</li> <li>Squid Jumps.</li> </ul>"},{"location":"meg/acquisition/atypical_meg_signals/#example-fif-data","title":"Example FIF data","text":"<ul> <li>Good Data. An example of good, clean, data. Temporal set of sensors. Eyes open looking at a central cross on the projector screen. Even if the ECG hadn't been recorded, the heartbeat can still be detected in the acquired data. </li> </ul> <ul> <li>Squid Jumps \"Squid jumps\" on channel MEG1043. Resetting the channel/warming the sensor had no effect, and its tuning curve was within normal parameters. Resetting the SSC card only caused a temporary respite for a few days. At the time, the channel was marked as \"bad\", and it was repaired during the PM Service Visit.</li> </ul> <ul> <li>Eye blinks. Eye blinks from two sets of sensors, Frontal (left image) and Temporal (right image). The Participant was asked to blink their eyes every two seconds, producing approximately five blinks in each ten-second window. It is recommended to record EOG channels in acquired data, to help remove blink artifacts.</li> </ul> <ul> <li>Eyes side-to-side. The Participant was asked to move their eyes between two markers on either side of the projector screen, about once every second. There are about eight movements collected in the eight-second window. There may also be some head movement/neck EMG artifact incorporated in the example image. </li> </ul> <ul> <li>Head Movement. The Participant was asked to make a shaking their head \"No!\" type movement, with each \"shake\" taking about two seconds to complete. There are about five movements in the eight-second window, so they were moving slightly faster than asked. There is probably some neck EMG involved, as well as some EOG as they kept their eyes fixated on the central cross as they shook their head. </li> </ul> <p> <ul> <li>Shrug Shoulders. The Participant was asked to \"shrug\" their shoulders, about once a second. Temporal (left image) and Occipital (right image). The majority of the artifact is probably muscle EMG; the Participant kept their head surprisingly still during the task. </li> </ul> <p> </p> <p> <ul> <li>Clench Teeth. The Participant was asked to clench their teeth and then relax. Frontal (left), Parietal (center) and Occipital (right). Majority of the artifact is jaw muscle EMG.</li> </ul> <p>With many thanks to Davd L. Winter.</p>"},{"location":"meg/acquisition/audio_delay_testing/","title":"Audio Delay Testing","text":"<p>Tie-Clip microphones are available to help measure the audio delay from a sound being triggered to hitting the participant's ear or ears.</p> <p>Two are identical and were purchased (October 2022), and the third is the original one provided during MEG training (February/March 2018).</p> <p>Specifications</p> Original 2 x New Transducer Principle Condenser Condenser Frequency Response 20 - 16000 Hz 50 - 18000 Hz Pickup Pattern Omnidirectional Omnidirectional Sensitivity -64dB +/- 3dB -62dB Impedance 1 k\u03a9 1 k\u03a9 Battery Power 1.5V DC, \"AAA\" 1.5V DC, LR-44 Button Output Connector 6.35mm / \u00bc\" mono Plug 6.35mm / \u00bc\" mono Plug Microphone Connection/lead length 3.5mm mono Plug, 4M 3.5mm mono Plug, 4M <ul> <li>Connect Stim PC or the PROPixx Controller (DATAPixx) audio output, to whichever sound system is being tested - MEG Audio Connections</li> <li>Decide which microphone/s to use and insert the relevant battery. Remove battery after use (plastic forceps available to help remove LR-44 battery from new microphone/s). </li> </ul> <p>Info</p> <ul> <li>If using two microphones, best to not mix the Original and New microphones - to avoid possible inconsistencies - see Specifications above.</li> <li>New microphone/s require/s microswitch on microphone case to be switched ON.</li> </ul> <ul> <li>Uncoil the microphone cable/s and lay it/them out neatly/safely on Control Room floor, to avoid tripping use the provided Cable Protection Cover Mat. Insert the 3.5mm mono Plug/s into the microphone case/s.</li> <li>Insert the \u00bc\" mono Plugs attached to the microphone case/s to the relevant \u00bc\" socket-to-socket adapter/s. The socket adapter/s should already be attached to the correct \u00bc\" Plug-to-BNC cable/s already connected to the MISC input box.<ul> <li>Check MISC Channels for the correct BNC connection/s to use on the MISC Input Box.<ul> <li>Microphone Input - Left Response - MISC #8</li> <li>Microphone Input - Right Response - MISC #9</li> </ul> </li> </ul> </li> <li>Carefully push the microphone/s (minus the Tie Clips) halfway into the provided small piece/s of silicone tubing.</li> <li>Roll up the relevant eartip/s and push into the opposite end/s of the tubing.<ul> <li>NATUS:<ul> <li>Attach the Natus cabling to the gantry side panel as usual. Lay out the Transducers on the gantry chair, on the floor, or on a chair outside the MSR. Attach the microphone/s + eartip/s to the Left or Right, or both, Transducer/s as required.</li> </ul> </li> <li>SOUNDPixx: <ul> <li>Unravel the clear SOUNDPixx tubing from the MSR shelving. Attach the black Participant tubing correctly. Attach the microphone/s + eartip/s to the Left or Right, or both, red-coiled connector/s as required.</li> </ul> </li> </ul> </li> </ul> <p>If only listening from one audio channel, to avoid possible spurious noise being picked up attach the relevant \"squashed\"/blocked eartip to whichever audio channel not recording from.</p> <p>Don't close the MSR door, or don't close it fully, to avoid cutting cable!</p> <ul> <li>In Acquisition Settings, select the relevant MISC Channels as well as the trigger channels associated with the audio test stimulus.</li> </ul> <p>To reduce the resulting file size, turn off the MEG channels.Increase the \"Sample freq (Hz)\" to 3000 or 4000 to increase file resolution (more points) to make subsequent cursor line start point selection easier/more defined.</p> <ul> <li> <p>Press \"GO\", \"Record\", and start audio test stimulus.</p> </li> <li> <p>Recording the triggers, the audio output/s (used for reference, and should be almost instantaneous but delays may be due to how the test sound is being generated in PTB), and the microphone output/s - should now show the audio delay between the sound-onset trigger and the microphone response.</p> </li> <li>Save the resultant .FIF file and read into Graph to find the delay/s.</li> </ul> <p> To check the delay using \"Graph\" </p> <ol> <li>Start Graph.<ul> <li><code>Applications -&gt; Neuromag -&gt; Graph.</code></li> <li>Dismiss the \"Welcome\" splash screen, click \"OK\".</li> </ul> </li> <li><code>File -&gt; Load settings</code>.<ul> <li>Example settings files/.fif files, to try, are shown in blue.</li> </ul> </li> <li>In the Directories window, double-click on the settings required e.g.<ul> <li>/home/meguser/lisp/setup/examples.</li> </ul> </li> <li>In the Files window, select basic.setup.</li> <li>Click \"OK\".</li> <li><code>File -&gt; Open Diskfile</code>.</li> <li>In the Directories window, double-click /neuro/data/sinuhe.</li> <li>In the next Directories window (left-click on the RH window edge and drag to open the window wider if necessary), scroll down and double-click on the Project e.g.<ul> <li>/neuro/data/sinuhe/demo.</li> </ul> </li> <li>In the next Directories window (left-click on the RH window edge and drag to open the window wider if necessary), scroll down and double-click on the relevant sub-directory e.g.<ul> <li>/neuro/data/sinuhe/demo/221013.</li> </ul> </li> <li>In the Select disk file to open window, chose the .fif file to view e.g.<ul> <li>Hyojin_audio_test_code_new_Stim.fif.</li> </ul> </li> <li>Click \"OK\".</li> <li>Graph will respond with \"No data available\" - if the MEG Channels were turned off during data collection to reduce file size.</li> <li><code>Displays -&gt; Control Panel</code>.</li> <li>Double-click the widget labelled \"Stim\" to add in the MISC and STI channels used during the Acquisition.</li> <li>In the \"Common to widgets\", \"names\" window, type in each channel name, in CAPITAL letters, one channel per line, pressing the Return key after each entry e.g. MISC 6MISC 7MISC 8STI 2 <li>Click \"Apply\", \u201cOK\u201d</li> <li>Right-click on the \"Stim\" widget, and drag/draw a line to the \"display\" widget. Release the mouse button.</li> <li>The four channels should now appear.</li> <li>In the \"Start &amp; length\" window, type a reasonable value in the \"length\" (lower) box, e.g. 10</li> <li>Left-click on each channel in turn (channel turns \"white\"). Click on Autoscale for both \"Scale\" and \"Offset\".</li> <li>Adjust the bottom slider to choose the best section to measure.</li> <li>Right-click on a position near e.g. the STI trigger and drag right to open a section to view (selected section turns \"white\").</li> <li><code>Displays -&gt; zoom in</code></li> <li>Repeat as necessary from Step 22.</li> <li>Once happy with the zoomed view...</li> <li>\"Shift + right-click\" on a channel at a relevant starting point e.g. the start of the STI trigger. A vertical white line is displayed, along with a cursor box showing the Port number and which channel selected e.g. one from ... Port: 0 MISC006Port: 1 MISC007Port: 2 MISC008Port: 3 STI002  and the \"X\" and \"Y\" axis values at the point selected e.g. X: 13.688 (Time scale in Seconds to 3 decimal places).</li> <li>Make a note of this \"X\" time value.</li> <li>Release the \"Shift\" key and whilst still right-clicking, drag the mouse to the right to the start of the desired time-delayed channel e.g. the microphone response. Move the line to the start of the response and note the time e.g. X: 13.711.</li> <li>The time difference is the delay (in msec) from trigger onset to microphone response e.g. in this example, 23msec. </li> <li>Repeat as necessary from Step 21 to take more readings from different triggers/different sections of the file, to ensure a reliable/repeatable value is collected for the delay.</li> <li>\u201cExit\u201d, \u201cExit\u201d, \u201cYes\u201d when finished.</li>"},{"location":"meg/acquisition/charging_eyelink_batteries/","title":"Charging EyeLink batteries","text":""},{"location":"meg/acquisition/charging_eyelink_batteries/#original","title":"Original","text":"<p>Press TEST button to check the battery power level. If charging required ...</p> <ul> <li>Plug in correct battery charge lead (#1 for #1 etc).</li> <li>GREEN Power LED will light, also ORANGE Charge LED.</li> <li>Charge LED will go out when battery is fully charged / \"Complete\".</li> </ul> <p>Note</p> <p>Make sure the battery is switched OFF when charging. Unplug the battery once fully charged. Do not leave attached to the charger. Do not leave a battery on charge overnight.     - Add a piece of Micropore tape to the battery front, to indicate the battery needs charging next day. <ul> <li>Use a fully-charged battery for an acquisition session (if possible).</li> <li>Swap to a new battery between acquisitions. </li> <li>Put first battery on charge.</li> </ul> <p>\"A battery with 2-3 hours left should be fine for a short experiment. Do not risk using it for a 2-hour experiment.\" (SR Research).</p> <p> </p> EyeLink Battery fully charged EyeLink Battery cable connections / ON-OFF Switch / TEST button EyeLink Battery Charger <p></p>"},{"location":"meg/acquisition/charging_eyelink_batteries/#new","title":"New","text":"<p>LRBB User Manual</p> <p>To check the current battery level, move the Battery POWER Switch to the ON position, and press the Battery level TEST button.</p> <p></p> <ul> <li>There are five LEDs in the Battery Level Indicator window on top of the battery (3 GREEN, 1 ORANGE, and 1 red). </li> <li>Each LED represents approximately 20% of the battery charge.</li> <li>The Indicator is disabled during charging and when the POWER switch is OFF to prevent accidental discharge.</li> </ul> <p></p> LED State (With Power Switch ON and Battery Level button pressed) Charge State Action to take All LEDs are lit (3 GREEN plusRED and ORANGE) Fully charged Ready for extended useor storage 1 GREEN LED (plus RED and ORANGE) Less than 50% charged Please charge Only ORANGE and RED LEDs Battery Level low, limited time remaining Please charge beforestarting further use RED LED only Critically low, may losepower in a few minutes Please charge assoon as possible No LEDs lit Battery completelydischarged Please chargeimmediately! <p> Battery #4 showing a full charge.</p> <p> To Charge</p> <ul> <li>Plug in the labelled charger cable (e.g. #4) into the appropriate battery.</li> <li>Switch on the labelled (e.g. #4) Mains plug. The LEDs on the charger will display its status. </li> </ul> LED Status RED Charging is in progress YELLOW The battery is fully charged and is now in trickle charging modeThe Mains plug can be switched off, and the charger lead disconnected from the battery GREEN Trickle charging is complete <p>Typical charging time is ~4 hours (from the Battery Level showing a RED-only LED).</p> <p>Note</p> <p>Make sure the battery is switched OFF when charging. Unplug the battery once fully charged. Do not leave attached to the charger. Do not leave a battery on charge overnight.     - Add a piece of Micropore tape to the battery front, to indicate the battery needs charging next day. <ul> <li>Use a fully-charged battery for an acquisition session (if possible).</li> <li>Swap to a new battery between acquisitions. </li> <li>Put first battery on charge.</li> </ul> <p>\"A battery with 2-3 hours left should be fine for a short experiment. Do not risk using it for a 2-hour experiment.\" (SR Research).</p> <p> Battery #4 Charger showing a GREEN LED (indicating trickle charging is complete).</p>"},{"location":"meg/acquisition/cleaning_eeg_caps/","title":"Cleaning EEG caps / Makeup &amp; EEG gel removal","text":"<p><p>Please  do not use the toilet sinks for any of the following purposes.</p>"},{"location":"meg/acquisition/cleaning_eeg_caps/#cleaning-eeg-caps","title":"Cleaning EEG caps","text":"<p>Use the ground floor shower  (just outside the MEG corridor) sink,  or the first floor shower sink for cleaning the EEG caps.</p> <p>Clean the caps immediately after each use, ideally before the electrolyte gel/paste starts drying. </p> <p>The dried gel reduces the signal tranductance of an electrode and is a common reason for bad impedance/bad signal strength.</p> <ul> <li>Fill sink with lukewarm water.</li> <li>Submerge only the cap. DO NOT allow the connector boxes/end connectors to get wet. Let the cap sit in the water for a few minutes.</li> <li>In case of more persistent/greasy stains, use mild detergents, pure soap, or baby shampoo, and clean the caps in lukewarm soapy water.<ul> <li>Rinse thoroughly with water after cleaning.</li> <li>DO NOT use dish detergents - will alter the electrode surface.</li> </ul> </li> <li>Clean the gel from the electrodes using a cotton swab or soft toothbrush. <ul> <li>Alternatively, run each electrode, in turn, under running lukewarm water. The water pressure will force most of the gel from the electrodes.</li> </ul> </li> <li>Rinse the cap thoroughly, BUT CAREFULLY!! See Handling and Maintenance information section below.</li> <li>Blot dry using a towel, or green paper towel.</li> <li>Place green paper towel on the correctly-sized polystyrene head (which can found in a box on top of the cupboards in Side Room), and carefully fit the cap over it to dry.<ul> <li>Make sure the connector boxes/end connectors are kept away from any chance of water drippage.</li> </ul> </li> <li>When the cap is dry, replace it in its box, and put box back in the right-hand white cabinet in the Control Room.</li> <li>Return the polystyrene head to its box on the cupboard.</li> </ul> <p>Note</p> <p>A small hairdryer may also be used to quickly dry a cap. However, use only the warm setting. The high or hot settings on some hair dryers are too hot and will weaken the elastic material - severely shortening the cap life.</p> <ul> <li>A disinfectant for the EEG caps - Perfektan TB (found on shelf in right-hand white cabinet in Control Room) is available if required.<ul> <li>Follow the instructions with/on the bottle.<ul> <li>Use the minimum concentration and soak for the the minimum time required. Make sure that the cap is fully immersed in the disinfectant.</li> <li>Do not leave the cap in the disinfecting solution longer than necessary.</li> <li>Do not let the connector boxes/end connectors get wet.</li> </ul> </li> <li>Rinse the cap in clean water thoroughly afterwards.</li> <li>Leave cap to dry as above.</li> </ul> </li> </ul> <p>Any disinfection is more stressful to the materials than simple cleaning. However, caps and electrodes will not be ruined by disinfection. Rather, disinfection will accelerate premature aging of the cap.Dry air by itself is a very good disinfectant. Most viruses and bacteria will not survive in a dry environment at room temperature for more than a few minutes.</p> <p>Info</p> <p>Handling and Maintenance</p> <ul> <li>The lifespan of our EEG caps, and our reusable electrodes/HPI coils, depends on handling.</li> <li>The most critical spot of an EEG cap electrode is where the elastic cable goes into the solid electrode housing and into the plug - please DO NOT overstretch/overbend this section.</li> <li>EEG caps are, and will stay, non-magnetic if handled correctly. However, they do contain soft metals which will become magnetic if exposed to a magnetic field.<ul> <li>NEVER take the caps near an MR-scanner.</li> <li>Avoid placing the cap near an incandescent light bulb, or a Mains power wall socket.</li> <li>Do not allow caps to get dusty - ordinary household dust can be ferromagnetic.</li> </ul> </li> <li>If the electrodes in the cap do become (slightly) magnetised, in the majority of cases they can be made MEG-compatible again by simply rewashing/cleaning the cap.</li> </ul>"},{"location":"meg/acquisition/cleaning_eeg_caps/#makeup-and-electrode-gel-removal","title":"Makeup and Electrode Gel removal","text":"<p>Escort Participant to one of the shower rooms to wash off any electrode gel, or for makeup removal prior to Acquiring.Remember to take swipe card!</p> <ul> <li>Towel and hair dryer are in the Changing Room wardrobe.</li> <li>Makeup removal cotton pads, Micellar water are available.</li> <li>Leave the used towel on the drying rack in the Changing Room for MEG Support to deal with.</li> </ul>"},{"location":"meg/acquisition/copying_edf_files/","title":"Copying EyeLink EDF files","text":"<p>Ideally leave for MEG Support to do , but ...</p> <p>If there is a need to copy off EyeLink EDF files from /elcl/exe -  e.g. because the EyeLink partition is almost full (TRACK may/will not start if the partition is full!)</p> <ul> <li>Make sure the Stim PC is On and Logged in.</li> <li>Turn On the EyeLink PC, and exit to FileManager.</li> <li>On the STIM PC, open the Bing incognito browser shortcut from the Taskbar.</li> <li>Then either...<ul> <li>Click on the \"EyeLink Host PC FileManager\" shortcut, in the Bookmarks toolbar. Or...</li> <li>In the Address Bar, type \"100.1.1.1\" (without the quotes). A connection should now be made to the SR Research EyeLink FileManager, and the following page should be displayed in the Stim PC Browser window...</li> </ul> </li> </ul> <p> The link is not a secure link, so make sure the address is headed by \"http://\" and not \"https://\"</p> <p> Stim PC linked to EyeLink Host PC FileManager.</p> <ul> <li>Click on the \"+\" button, by the \"/elcl\" folder icon to open up the sub-folders.</li> <li>Click on the \"exe\" folder icon to show the folder contents in the right-hand window.</li> <li>Click on the \"Change view\" icon and select \"Details\" from the dropdown menu.</li> <li>Click on \"Type\" to list all the EDF files together.</li> <li>Select relevant EDF files (using shift-leftclick or ctrl-leftclick) in the right-hand window, and right-click the selected files to view the options. </li> <li>Select \"Download (no. selected) items\".</li> <li>Select \"OK\" to download the files as a compressed file to the Stim PC Downloads folder.<ul> <li>Filename: \"exe (no. of items).zip\"</li> </ul> </li> <li>Once transfer is complete, check the Downloads folder to confirm ZIP file is there and can be opened.</li> <li>Copy the zip file to RDS partition, or University OneDrive (depending on what share has been mapped on the Stim PC).</li> <li>Return to the open browser window, right-clicking to now, carefully, select \"Delete (no. selected) items\", to make space on the EyeLink partition enabling the recording of EDF files again.</li> </ul>"},{"location":"meg/acquisition/copying_meg_data/","title":"Copying MEG data","text":"<p>Operators must have access to a BlueBEAR RDS Project and their own BlueBEAR Linux Account prior to transferring data from the MEG Acquisition computer (\"Sinuhe\").</p> <p></p> <p> Data is stored here - in the BEAR Cave! </p>"},{"location":"meg/acquisition/copying_meg_data/#requesting-rds-activating-a-linux-account","title":"Requesting RDS / Activating a Linux Account","text":"<p>RDS can be requested through the IT Service Desk </p> <ul> <li>After Log in, select the option \"Research\", then \"Request a new BEAR Project\".</li> </ul> <p>RDS can only be requested by a member of Staff/PI/Supervisor.The Project MUST have BlueBEAR compute services added (\"BlueBEAR Linux HPC\").</p> <p>A BlueBEAR Linux Account is needed to be able to copy off Acquired data from the Console. To request a BlueBEAR Linux Account, after Log in ...</p> <ul> <li>Select the option \"Research\", then select \"My BEAR Accounts\" and then \"Activate your BEAR Linux Account (you must be on a suitable project)\".</li> </ul> <p>Association is first required with a Project, before data can be copied off the Console.Addition of MEG Operator email address to the Project needs to be requested - by the MEG Operator or PI.</p>"},{"location":"meg/acquisition/copying_meg_data/#transferring-acquired-data-to-rds","title":"Transferring Acquired data to RDS","text":"<p>Use the scp command from a terminal window on the MEG console. To open ...</p> <ul> <li>Click the Application Launcher button (bottom left) and select <code>Terminal</code>.</li> <li>Right-click anywhere on the Desktop and select <code>Konsole</code> from the window that pops up.</li> </ul> <p>Change to relevant Project directory in neuro-data ...</p> <ul> <li><code>cd /data/neuro-data/project-name</code> or more likely</li> <li><code>cd /data/neuro-data/project-name/subject-name</code></li> </ul> <p>subject-name will be the anonymised code generated by the Participant Logging Computer (PLC) or possibly no-name if just Acquiring data for Project Development.</p> <p>If a subject-name is not provided when setting up megacq, a sub-directory called no_name is generated instead in the project-name directory.</p> <ul> <li> <p>When files are saved in the subject-name directory, a sub-directory with the format YYMMDD is created.</p> </li> <li> <p>This YYMMDD sub-directory will contain the saved MEG acquisition.FIF data file.</p> </li> <li> <p>If another Acquisition is started, any subsequently saved data will be in the same YYMMDD directory.</p> </li> </ul> <p>Run the scp command to copy over the data ...</p> <ul> <li><code>scp -rp data username@bluebear.bham.ac.uk:/rds/projects/year/project-name</code> or </li> <li><code>scp -rp data username@bluebear.bham.ac.uk:/rds/projects/letter/project-name</code><ul> <li>Replace <code>data</code> with the folder to be copied, or use the asterisk character, *, for the complete contents of neuro-data <code>project-name</code> or <code>project-name/subject-name</code>.</li> <li>Replace <code>username</code> with Operator's username.</li> <li>Replace <code>project-name</code> with Operator's RDS path.</li> </ul> </li> </ul> <p>For example ...</p> <ul> <li><code>cd /data/neuro-data/empty_room</code> or</li> <li><code>cd /data/neuro-data/empty_room/no_name</code> then</li> <li><code>scp -rp 191225 smithj25@bluebear.bham.ac.uk:/rds/projects/2018/jenseno-meg-qualitycontrol/smithj25/meg-data/</code>  or perhaps</li> <li><code>scp -rp * smithj25@bluebear.bham.ac.uk:/rds/projects/j/jenseno-meg-raw-data/data/neuro-data/empty-room/</code></li> </ul> <p>Check data has copied correctly ...</p> <ul> <li><code>ssh smithj25@bluebear.bham.ac.uk</code> then</li> <li><code>cd /rds/projects/2018/jenseno-meg-qualitycontrol/smithj25/meg-data/</code> or</li> <li><code>cd /rds/projects/j/jenseno-meg-raw-data/data/neuro-data/empty-room/</code></li> <li>Run the command <code>ls -l</code> to list the data to allow checking.</li> </ul> <p>NOTE: Please don't save data to anywhere other than the data/neuro-data/project-name directory on the MEG console.</p>"},{"location":"meg/acquisition/copying_meg_data/#bluebear-data-backup","title":"BlueBEAR Data Backup","text":"<p>For Duty of Care obligations, the following information is backed-up, overnight, to a RDS Project space on BlueBEAR.</p> <ul> <li>Daily acquired MEG data</li> <li>Project &amp; Subject databases, including the ctc and sss folders</li> <li>The DACQ Tuning directory</li> </ul> <p>A backup script runs as a CRON job, generating backup-log and backup-error txt messages emailed as necessary.</p> <p>MEG Operators need to ensure Acquired data is always kept in the correct folder on the Console ... /data/neuro-data/project-name</p> <p>If data doesn't get copied overnight, due to errors with BlueBEAR, the next time the script runs, and BlueBEAR is available, any missing files are backed up.</p> <p>Acquired data is then routinely removed from the DACQ data partition, on more-or-less a monthly basis, to allow continued MEG Acquisition.</p> <p>No quota system is in place, or automatic file deletion deamon running, but MEG Operators will still need to copy off their data to their own RDS space in a timely manner.</p>"},{"location":"meg/acquisition/eeg_meg/","title":"Using EEG with MEG","text":"<p>We have a 64 Channel EEG system, use EASYCAPs specifically designed for our TRIUX system, purchased from Brain Products UK, and have 6 caps available in 4 different sizes.  The caps use the 10/20 system of electrode placement.</p> <ul> <li>1 x 54cm, 2 x 56cm, 2 x 58cm, 1 x 60cm</li> </ul> <p>64Ch BrainCap-MEG for Triux - Electrode Layout/Channel Assignment</p> <p>64Ch BrainCap-MEG for Triux - Table of Coordinates</p>"},{"location":"meg/acquisition/eeg_meg/#digitisation","title":"Digitisation","text":"<p>To digitise the 64 electrodes, follow the Instructions for Digitisation copied from MEGIN's EEG Cap User's Manual The EASYCAP layout closely follows the MEGIN caps, but there are some differences in electrode usage (EASYCAPs have T9 &amp; T10, but no PO5 &amp; PO6) , and when certain electrodes are digitised, and be wary of the extra EOG electrodes built into the EASYCAPs  - See the 64 BrainCap-MEG electrode layout above.</p> <p>NOTE:  One additional important difference between the two systems: the channel numbering (channel index mapping) is not the same.For example, channel Fpz ... - Is registered as EEG020 for the MEGIN caps, whereas it is ...- EEG002 for the EASYCAP.(The data is recorded as EEG001, EEG002, etc., rather than as Fp1, Fp2, and so on).</p>"},{"location":"meg/acquisition/eeg_meg/#if-using-easycaps","title":"If using EASYCAPs ...","text":"<p>The eeg_digit_maps file in <code>/neuro/dacq/setup</code> has been edited to create a new layout to help digitise the EASYCAPs.</p> <ul> <li>Select all EEG channels in <code>megacq</code> (click the <code>EEG on</code> button). </li> <li>After Coordinate frame alignment and HPI Coils digitisation, select <code>EEG EasyCap 64</code> from the dropdown sub-menu, then click on <code>EEG ecectrodes</code> to start digitising each electrode. <ul> <li>The REF electrode is always the first one to digitise (\"0\").</li> </ul> </li> </ul> <p>The new digitisation order (taken from eeg_digit_maps) is as follows ...</p> <pre><code># A map for 64-channel EASYCAP (05/02/2026 - JLW &amp; CZ)\nEEG EasyCap 64:0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:19:20:21:22:18:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:41:42:43:44:45:46:47:48:49:53:54:55:56:57:58:59:60:61:64:38:39:40:62:50:51:52:63\n</code></pre>"},{"location":"meg/acquisition/eeg_meg/#if-using-megin-caps","title":"If using MEGIN Caps ...","text":"<p>To help in digitisation, three pages have been copied from MEGIN's EEG Cap User's manual above ...</p> <ul> <li> <p>Electrode Locations and Channel Numbers</p> </li> <li> <p>Electrode layout (original) - Figure A.2</p> </li> <li> <p>Electrode layout (new numbering) - Many thanks to Malgorzata \"Gosia\" Wislowska.</p> </li> </ul> <p>She says ...</p> <p>\"I exchanged numbers of green electrodes so that they go from 1-32 instead of 33-64. This new numbering is compatible with electrode numbering on SIGGI device. So one can save a little bit of grey matter energy and skip subtracting number 32 when checking the impedances. We should however not get rid of the old layout, which in turn is compatible with electrode numbering in the acquisition software (numbers going from 1 to 64).\"</p>"},{"location":"meg/acquisition/eeg_meg/#procedure","title":"Procedure","text":"<p>Not many MEG Operators have undertaken EEG &amp; MEG, but those that have used the following procedure/digitisation order: Many thanks to Oscar Ferrante &amp; Tara Ghafari @2020</p> <ul> <li>Attach BIO electrodes.</li> <li>Attach EEG cap.</li> <li>Attach HPI coils on EEG cap (EASYCAPs were purchased with built-in HPI coil holders).</li> <li>Gel EEG cap (Correct Positioning &amp; Usage of EEG Caps)</li> <li>Digitise fiducial points.</li> <li>Digitise HPI coils.</li> <li>Digitise the 64 electrodes. <ul> <li>Use the SIGGI-II multimeter to measure electrode impedance  - Correct Positioning &amp; Usage of EEG Caps#check-impedances</li> </ul> </li> <li>Digitise the head shape. Take care not to damage the coils/break any electrode wiring!</li> </ul> <p>They used the MEGIN caps \"We attached the HPI coils to the MEGIN cap because that way we could easily reach them during digitisation. If they are placed on the head (as in normal usage), this needs to be done so that the Polhemus pointer can reach them under the EEG cap with a perpendicular orientation - it needs to be very well thought out.\"</p> <p>When queried if it was possible to digitise the head shape before the 64 electrodes ... \"I\u2019m not sure it\u2019s possible to digitise the head shape before doing it for the EEG electrodes in the MEGIN software. If so, it\u2019s worth a try. But the HPI coils would then need to be attached to the head, adding the problems mentioned above. Doing the head shape digitisation once the cap is in place is not perfect as it introduces some noise, which can make the coregistration less accurate. It\u2019s a trade-off. In our analysis (i.e., visual response in posterior and prefrontal areas), this extra noise did not have a strong impact, but I guess it depends on the specific experimental question.\"</p> <p>NOTE: Autumn 2025: Coen &amp; Helena found that using the BIO GND electrode (which they're using for EMG recording), rather than the EASYCAP GND electrode, produced better signal quality overall when plugged into the gantry side panel.The side panel REF connection was made using the EASYCAP REF electrode (no BIO REF electrode was attached to the participant).</p>"},{"location":"meg/acquisition/eyelink_analog_output/","title":"EyeLink Analog Output","text":"<p>In order to ensure the EyeLink \"X\", \"Y\" and \"P\" (pupil) are recorded on MEG channels MISC#1, MISC#2 and MISC#3... </p> <p></p> <ul> <li>Make sure MISC#1, MISC#2, and MISC#3 are selected in MEG Acquisition.</li> <li>Select a value for Analog Output e.g. Raw, in EyeLink Set Options (bottom left of screen).</li> <li>Make sure the EyeLink is set to RECORD in order to see the Output.</li> </ul> <p> If using any of the Binocular settings, make sure the LEFT eye is ALWAYS selected - DAC3, DAC4, and DAC5 are not being recorded (no cable connection from EyeLink Host A/D card output to MEG MISC channels).</p> <p> EyeLink Analog Outputs.</p>"},{"location":"meg/acquisition/eyelink_demo/","title":"EyeLink Demo Code","text":"<p>Demo code for EyeLink setup, calibration, validation, drift checking and trigger sent during data acquiring. Edited by Dr. Yali Pan.</p>"},{"location":"meg/acquisition/eyelink_demo/#matlab-code","title":"MATLAB Code","text":"<pre><code>function Eyelink_Demo\n%%%% Demo for eyelink setup, calibration, validation, drift checking and trigger sent during data acquiring\n%%%%% edited by Yali Pan (Y.Pan.1@bham.ac.uk) \n\n%%%=====Open screen, the same screen for eyelink\nscreens = Screen('Screens'); % Get the screen numbers\ncfg.screenNumber = max(screens); %select screen\ncfg.ScrBgc = [0.5 0.5 0.5];\ncfg.TextColor = [1 1 1];\n%%%open PTB window\n[window] = PsychImaging('OpenWindow', cfg.screenNumber, cfg.ScrBgc);\ncfg.window = window;\n%%%  Get the size of the on screen window and set resolution\nsc_info = Screen('Resolution', cfg.screenNumber);\nresx = sc_info.width;\nresy = sc_info.height;\ncfg.resx = resx;\ncfg.resy = resy;\n\n%%%=====Parameters for eyelink\ncfg.el.Eyeused = 'LEFT_EYE';      %eye used\ncfg.el.edffile = 'sub1.edf'; %EDF filename\n%%% check file\n%add eyelink script folder (should be in main experiment folder)\naddpath([exp_dir filesep 'Eyelink']);\n%make directory if it doesn't already exist (local computer)\ncfg.el.eyedir = [exp_dir filesep 'Eyelink' filesep ];\nif ~exist(cfg.el.eyedir, 'dir')\n    mkdir(cfg.el.eyedir);\nend\n%check whether files already exist for this subject/session\nif exist([exp_dir filesep 'Eyelink' filesep 'Data' filesep  cfg.el.edffile '.edf'],'file')&gt;0\n    cont = input('Warning! Eyelink file will be overwritten, do you want to continue? (y/n) ','s');\n    if cont == 'n'\n        error('Session aborted')\n    end\nend\ncfg.el_rect = [0 0 resx resy]; %% needed for the el_Set_Params function\n\n%%%=====Eyelink setup, calibration and validation\ncfg = el_calib_valid(cfg,0);\n\n%%%%===== Trigger: Experiment start message to eyelink\nEyelink('Message', 'sub1: Exp_start');\n\n%%%%===== Trigger: Experiment triggers to eyelink\nsendTrigger(cfg,1); %%% here the trigger is '1'\n\n%%%=====Redo calibration and validation\ncfg = el_calib_valid(cfg,1);\n\n%%%=====Run EyelinkDoDriftCorrection\n%%% enable eye drift checking !!!\nEyelink('Command', 'driftcorrect_cr_disable = NO');\nel_calib_valid(cfg,2);\nWaitSecs(0.1)\n\n%%%======Stop eyelink &amp; transfer file\nEyelink('Message', 'end of block');\nel_Stop(cfg);\n\nend\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nfunction cfg = el_calib_valid(cfg,mode)\nif mode == 0 %% run the eye-tracker setup for the first time\n    %%% run el_Start\n    cfg = el_Start_SameWindow(cfg);\n    cfg.el.defaults.ScrBgc = cfg.ScrBgc;\n    cfg.el.defaults.TextColor = cfg.TextColor;\nelseif mode == 1 %% run the eye-tracker setup for the non-first time\n    %%% re-calibration and re-validation and re-drift correction\n    EyelinkDoTrackerSetup(cfg.el.defaults);\nelseif mode == 2\n    EyelinkDoDriftCorrection_pan(cfg.el.defaults);\n    Eyelink('StartRecording');\n    % record a few samples before we actually start displaying\n    WaitSecs(0.1);\n    % mark zero-plot time in data file\n    disp('Sending message')\n    Eyelink('Message', 'SYNCTIME');\nend\n%%% set screen to experiment background color\nScreen('FillRect', cfg.window, cfg.ScrBgc)\nScreen('Flip', cfg.window);\nend\n\nfunction cfg = el_Start_SameWindow(cfg)\n% Used in FG experiment\n% Using the main screen for calibration, calibrate and start recording\n\n% STEP 1\n% Provide Eyelink with details about the graphics environment\n% and perform some initializations. The information is returned\n% in a structure that also contains useful defaults\n% and control codes (e.g. tracker state bit and Eyelink key values).\n% Psychtoolbox defaults function\ncfg.el.defaults = EyelinkInitDefaults(cfg.window);\n\n% Disable key output to Matlab window:\nListenChar(2);\n\n% STEP 2\n% Initialization of the connection with the Eyelink Gazetracker.\n% exit program if this fails.\nif ~EyelinkInit\n    fprintf('Eyelink Init aborted.\\n');\n    cleanup;  % cleanup function\n    return;\nelse\n    disp('Eyelink initizalized')\nend\n\n% open file to record data to\ndisp('Opening EDF file');\nstatus = Eyelink('Openfile', cfg.el.edffile);\n\nif ~status\n    disp('EDF file opened on Eyelink computer')\nelse\n    error(['Could not open EDF file on Eyelink computer, error: ' int2str(status)])\nend\n\n% set custom parameters\ndisp('Setting parameters')\ncfg = el_Set_Params(cfg);\n\n% STEP 3\n% start recording eye position\ndisp('Start recording')\n%sca\nEyelink('StartRecording');\n% record a few samples before we actually start displaying\nWaitSecs(0.1);\n% mark zero-plot time in data file\ndisp('Sending message')\nEyelink('Message', 'SYNCTIME');\nListenChar(0);\nend\n\nfunction [cfg] = el_Set_Params(cfg)\n%el_Set_Params \n%Custom parameter file for eyelink\nel=cfg.el.defaults;\nel.eye_used                = cfg.el.Eyeused;\nel.calibrationtargetsize   = 1;\nel.calibrationtargetwidth  = 0.5;\nel.targetbeep              = 0;\nel.feedbackbeep            = 0;\nel.displayCalResults       = 1;\nel.eyeimagesize            = 50;  % percentage of screen\nel.backgroundcolour        = cfg.ScrBgc;\n\ndisp('Updating Parameters')\nEyelinkUpdateDefaults(el);\n\ncfg.el.defaults=el;\n% make sure we're still connected.\nif Eyelink('IsConnected')~=1\n    warning('eyelink is not connected! restart the tracker');\n    cleanup;\n    return;\nend\n% make sure that we get gaze data from the Eyelink\nEyelink('Command', 'link_sample_data = LEFT,RIGHT,GAZE,GAZERES,AREA,STATUS,INPUT'); \n\n% This Command is crucial to map the gaze positions from the tracker to\n% screen pixel positions to determine fixation\nEyelink('Command','screen_pixel_coords = %ld %ld %ld %ld',  cfg.el_rect(1)-cfg.el_rect(1), cfg.el_rect(2)-cfg.el_rect(2), cfg.el_rect(3)-cfg.el_rect(1), cfg.el_rect(4)-cfg.el_rect(2));\nEyelink('message','DISPLAY_COORDS %ld %ld %ld %ld',         cfg.el_rect(1)-cfg.el_rect(1), cfg.el_rect(2)-cfg.el_rect(2), cfg.el_rect(3)-cfg.el_rect(1), cfg.el_rect(4)-cfg.el_rect(2));\n\n% Use Psychophysical setting\nEyelink('Command', 'recording_parse_type = GAZE');\nEyelink('Command', 'saccade_motion_threshold = 0.0');\nEyelink('Command', 'saccade_pursuit_fixup = 60');\nEyelink('Command', 'fixation_update_interval = 0');\n%%% normal visual experiments\nEyelink('Command', 'saccade_velocity_threshold = 22');\nEyelink('Command', 'saccade_acceleration_threshold = 3800');\n% % %%% YPan: changed accoording to the user mannual to be better for reading study\n% % Eyelink('Command', 'saccade_velocity_threshold = 30');\n% % Eyelink('Command', 'saccade_acceleration_threshold = 8000');\n\n% Other tracker configurations\n%% these might crash:\nEyelink('Command', 'heuristic_filter = 0');\nEyelink('Command', 'pupil_size_diameter = YES');\n\n%use 9 point calibration (Default)\nEyelink('Command', 'calibration_type = HV9'); %%HV5,HV3\n\nEyelink('Command', 'generate_default_targets = YES');\nEyelink('Command', 'enable_automatic_calibration = YES');\nEyelink('Command', 'automatic_calibration_pacing = 1000');\nEyelink('Command', 'binocular_enabled = NO');\nEyelink('Command', 'use_ellipse_fitter = NO');\nEyelink('Command', 'sample_rate = 1000');\n%Eyelink('Command', 'elcl_tt_power = %d', 2); % illumination, 1 = 100%, 2 = 75%, 3 = 50%\n\nswitch cfg.el.Eyeused\n    case 'RIGHT_EYE'\n        Eyelink('Command', 'file_event_filter = RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,INPUT');\n        Eyelink('Command', 'link_event_filter = RIGHT,FIXATION,FIXUPDATE,SACCADE,BLINK,MESSAGE,INPUT');\n    case  'LEFT_EYE'\n        Eyelink('Command', 'file_event_filter = LEFT,FIXATION,SACCADE,BLINK,MESSAGE,INPUT');\n        Eyelink('Command', 'link_event_filter = LEFT,FIXATION,FIXUPDATE,SACCADE,BLINK,MESSAGE,INPUT');\nend\nEyelink('Command', 'file_sample_data  = GAZE,GAZERES,HREF,PUPIL,AREA,STATUS,INPUT');\n\n% Cleanup routine:\nfunction cleanup\n% Shutdown Eyelink:\n    Eyelink('Shutdown');\n    el.online = 0;\nend\nend\n\n%function to send eyelink triggers\nfunction [cfg] = sendTrigger(cfg,trig)\n%send trigger to eyelink\nif cfg.el.eyelink\n    Eyelink('Message', ['Trigger_' int2str(trig)]);\nend\nend\n\nfunction el_Stop(cfg)\nel=cfg.el;\n% finish up: stop recording eye-movements,\n% close graphics window, close data file and shut down tracker\nEyelink('StopRecording');\nEyelink('CloseFile');\n% download data file\nfprintf('Receiving data file ''%s''\\n', cfg.el.edffile);\n%status=Eyelink('ReceiveFile');\nstatus=Eyelink('ReceiveFile',cfg.el.edffile,cfg.el.eyedir,1); %transfer file to experiment directory\nif status &gt; 0\n    fprintf('ReceiveFile status %d\\n', status);\nend\nif 2==exist(cfg.el.edffile, 'file')\n    fprintf('Data file ''%s'' can be found in ''%s''\\n', cfg.el.edffile, cfg.el.eyedir );\nend\ncleanup;\nend\n\n% Cleanup routine:\nfunction cleanup\n% Shutdown Eyelink:\nEyelink('Shutdown');\n% Restore keyboard output to Matlab:\nListenChar(0);\nend\n</code></pre>"},{"location":"meg/acquisition/eyelink_operations_guide/","title":"EyeLink Operations Guide","text":"<p>Quick Start Guide Install/Training (slides) User Manual v1.0.22</p>"},{"location":"meg/acquisition/eyelink_operations_guide/#initial-setup","title":"Initial Setup","text":"<p>Switch on the 6-way bar plug (next to EyeLink Host PC), to provide power to the Host PC, PC monitor &amp; EyeLink camera.</p> <p>EyeLink batteries </p> <ul> <li>Press the TEST button to check the power level (batteries #1 and #2), or power on and press the TEST button (batteries #3 and #4).</li> <li>Use a fully charged battery if possible.</li> </ul> <p>A battery with 2-3 hours should be fine for a short experiment. Do not risk using it for a 2-hour experiment.</p> <p>Take a battery into the MSR and place in front left hand corner (as seen from gantry chair). Arrange the power cable around the inside wall of the MSR to avoid any loops.</p> <p>Remove the lens cap from the FO camera head, and place the FO camera head/IR Illuminator on the small table in front of the gantry chair (usually once Participant is in place). Attach power cable to battery and FO camera head/IR Illuminator. Switch on the battery.</p> <p>NOTE: Ensure a good cable connection is made (the black rubber strain reliefs aren't pushed up over the silver two-pin connectors).NOTE: If the camera head/IR Illuminator isn't powered-on first, the Host PC will complain slightly (ticking sound) when EyeLink starts up.</p> <p>To prevent small threshold drifts, the EyeLink camera head/Host PC etc should be powered up/switched on for at least 5 minutes before recording.</p> <p>If using Monocular, make sure the FO camera head is HORIZONTAL, and the knurled silver adjustment knobs are centered to the projector screen.</p> <ul> <li>Once Participant is in place, tilt the camera head/illuminator as necessary to bring the eye into view, making sure to keep everything as level as possible.</li> </ul> <p>For Binocular use, the position of the camera head will require changing.</p> <ul> <li> <p>Note the value on the BAR SCALE (as indicated by the RED line in the image) before undoing the knob, and make sure the camera mount is back at that value on the bar after adjusting the camera head and before tightening the knob.</p> </li> <li> <p>Undo the BLACK KNURLED KNOB (as indicated by the BLUE circle in the image) to allow the camera head to be pulled slightly away from the bar, exposing the BRASS FIXING PINS (as indicated by the GREEN circle in the image).</p> </li> <li> <p>Adjust the camera head on an angle, aligning the pins to the secondary/BINOCULAR position, and then push the camera head back into place, tightening the black knurled knob - FRONT VIEW of Binocular usage position.</p> </li> <li> <p>Ensure the camera mount hasn't slid closer or further away from the IR illuminator when adjusting (as indicated by the RED line in the images mentioned above).</p> </li> <li> <p>If required, raise the small table using the black plastic TABLE RISERS, 3 heights available, so that the top of the IR Illuminator is as close as possible to the lower edge of the projector screen.</p> </li> </ul> <p>EyeLink Clip Position Adjustment </p> <p></p> <ul> <li>Camera Head and Illuminator Separation:  Adjust the camera and Illuminator clip positions on the mounting bar so that the inner edges align with the eye-to-camera distance measured in cm.</li> <li>When using the small table, the separation should be already adjusted. Only if moving closer or further away will an adjustment need to be made.</li> </ul> <p> Position projector screen so the max visual angle subtends no more than: 32<sup>o</sup> horizontally, 25<sup>o</sup> vertically. The eye-to-projector distance should be at least 1.75 times the display width to ensure that it falls within the trackable range. <p>EyeLink Configuration </p> <ul> <li> <p>Switch on the EyeLink Host PC &amp; monitor. Select the default EyeLink partition from the Windows Boot Manager interface.</p> </li> <li> <p>Select the appropriate EyeLink Configuration from the Set Options screen, e.g. monocular, binocular.</p> <ul> <li>From Set Options, select LONG RANGE MOUNT in the Configuration window (may already be highlighted)</li> <li>Then select Select Config... and choose either MONOCULAR or BINOC/MONOC and click on Accept.<ul> <li>The following screens should be displayed, depending on the chosen option - MONOCULAR IMAGE or BINOCULAR IMAGE.<ul> <li>Make sure the sample rate is selected back to 1K for Binocular usage (as indicated by the RED arrow in the BINOCULAR IMAGE).  The sample rate defaults to 500Hz when selecting Binocular.</li> <li>The view of the head will need adjusting when using Binocular, as the angle of the camera head has changed. Select the top right-hand blue square (as indicated by the BLUE arrow in the BINOCULAR IMAGE) as many times as necessary to display the correct view.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Info</p> <p>Lens Guide Three lenses are available for use as required: 35mm, 50mm and 75mm, with the 35mm lens being used as the default, currently, for both monocular and binocular usage. The 35mm lens only has a focusing ring, whereas the 50mm and 75mm lenses have both focus and apature adjustment. The aperture ring is the smaller of the two, and probably doesn\u2019t need adjusting (currently fixed at 1.8 f-stop on the 75mm lens). Smaller numbers (e.g., f/2.8) mean a wider opening for more light/blurry background, while larger numbers (e.g., f/11) mean a smaller opening for less light/sharper background).</p> <p>Lens Guide for Different Viewing Distances</p> Lens Apature Size Long Range Mount (Monocular/Binocular) 35mm 60-70cm 50mm 70-100cm 75mm 100-150cm <p>If necessary, have the Participant remove any mascara, and replace glasses with provided MEG-safe glasses. Soft contact lenses can be worn during an eye-tracking experiment, but hard contact lenses may interfere with the corneal reflection (CR) and thus need to be switched for MEG-safe lenses using the provided GoPro/Loc-Line assembly.</p> <p>Info</p> <p>Mascara. Eye lashes with mascara will show very dark on the eye image, which can have a negative effect on pupil detection. Mascara shouldn\u2019t be used in the MEG in any case, due to the possibility of metal particles in the makeup. Soft contact lenses usually work quite well. The edge of lens can be seen from the eye image as pale ring, but it doesn\u2019t usually have an effect on the eye tracking. Lenses can also create an extra reflection point, which is very similar to a corneal reflection (1st Purkinje image), but is normally only visible at certain angles. Hard lenses don\u2019t usually work with the EyeLink. They tend to be less stable than soft lenses and can slide partly off the centre of the eye. This will produce an eye image, where the pupil is partially cut off. MEG-glasses.  The EyeLink will work with our MEG-safe glasses, but it needs to be adjusted very carefully. The lenses may reflect IR light, which can disturb the eye tracking. Also the success rate for good tracking is lower with the glasses than without.</p>"},{"location":"meg/acquisition/eyelink_operations_guide/#focusing","title":"Focusing","text":"<p>Align the camera </p> <ul> <li> <p>Once the Participant is positioned in the gantry chair, point/tilt the camera at the eye to be tracked so that the eye appears in the centre of the global view. (TOP IMAGE WINDOW on the Camera Setup screen), undoing/tightening the silver knurled knobs, remembering to keep the camera/IR illuminiator as level as possible.  If necessary, move the whole Desktop Mount left/right slightly so that the patch of IR light is aligned with the field of view of the camera head.</p> </li> <li> <p>If tracking the left eye, the illuminator is usually on the right side, but the position may be irrelevant for binocular eye tracking.</p> </li> <li>Focus the camera image if the eye looks blurred (by turning the lens focus ring).  The 35mm lens only has a focusing ring, whereas the 50mm and 75mm lenses have both focus and apature adjustment. The aperture ring is the smaller of the two, and probably doesn\u2019t need adjusting (currently fixed at 1.8 f-stop on the 75mm lens).</li> </ul> <p>Smaller numbers (e.g., f/2.8) mean a wider opening for more light/blurry background, while larger numbers (e.g., f/11) mean a smaller opening for less light/sharper background).</p> <p>Note</p> <p>When using Psychtoolbox (PTB), the image of the eye can be thrown onto the projector screen to make focusing easier. The left/right arrows on the Stim PC toggle between wide angle view and eye focused view.</p> <ul> <li>To throw the image, start TRACK (using either the installed standalone program (when testing) or as part of stimulus code - see the Calibration section for more detailed usage and link to the In-House provided code).  The Offline Screen should appear.</li> <li>Press <code>ENTER</code> to start camera setup, the Camera Setup screen should appear, and then press <code>ENTER</code> again to display the camera image of the Eye A good guide is to check if the eyelashes are in focus; when they are sharp the image is usually good enough.</li> </ul> <p>Info</p> <p>Ideally when recording from one eye, the eye movements should be measured from the Participant\u2019s dominant eye \u2013 but this is the optimal solution and not necessarily essential to obtaining good eye tracking. If you want to use the dominant eye, examples to find the dominant eye are shown below:</p> <ul> <li>Extend your arms out in front of you and create a triangular opening between your thumbs and forefingers by placing your hands together at a 45-degree angle.   With both eyes open, centre this triangular opening on a distant object - such as a wall clock or door knob.   Close your left eye.   If the object stays centred, your right eye (the one that's open) is your dominant eye.If the object is no longer framed by your hands, your left eye is your dominant eye.</li> <li>Extend one arm out, holding the thumb (or index finger) of that hand in an upright position.   Keeping both eyes open and focused on a distant object, superimpose your thumb/index finger on that object. Don't worry if it looks like your thumb/finger partially disappears - that\u2019s normal.   Alternately close one eye at a time.   The eye that keeps your thumb/finger directly in front of the object while the other eye is closed is your dominant eye.</li> </ul> <ul> <li> <p>Roughly focus on the eye using the wide angle view on the projector screen.</p> </li> <li> <p>Set the search limits on the Eyelink Host PC by selecting the pupil image in the global view and then select Auto Threshold.</p> </li> <li> <p>Switch to eye-view (arrow key) and focus using the corneal reflection. The focus is best when the corneal reflection is smallest (sharp).</p> </li> <li> <p>Select/click Auto Threshold again, and check whether the pupil value (identified by the blue shading)  is between 75-115 and the corneal reflection is less than 240 (identified by a turquoise circle with crosshair). If needed, manually adjust. If sub-optimal, then the ILLUMINATOR FOCUS may need adjusting.</p> </li> </ul> <p>A good check is to ask your Participant to look along the edges/four corners of the display and ensure that the pupil and corneal reflection do not get lost.</p> <p>Focusing the Illuminator </p> <p></p> <ul> <li>If the  the Illuminator needs focusing, loosen the two knurled knobs on the underside of the Illuminator and then adjust the cover so that its edge aligns with the marking that approximates the eye-to-camera distance and then tighten the knobs. </li> </ul> <p>Info</p> <p>Pupil threshold: Fill the dark pupil with blue colour. If there isn\u2019t enough colour inside the pupil, adjust the pupil threshold level up. If there is too much blue colour around the pupil, change the threshold level down. Pupil value should be between 75 and 115. If the pupil threshold is too high or too low, try increasing or decreasing the eye-camera distance.  Corneal reflections: You want a small CR as possible, showing the pupil is in focus. If there is a white halo around the turquoise reflections, adjust the CR threshold level down. Also adjust the focus of the camera. Corneal reflections should not exceed 240. If the corneal thresholds are too high, try increasing the eye-to-camera distance. CR smearing is typically seen when the Participant looks top-left or top-right of the display, indicating the viewing angle is too large for the setup. Try raising the Desktop mount and/or increasing the viewing distance. Correct detection: When both the pupil and CR are detected correctly, you will see the GREEN boxes, under the eye or eyes being tracked, showing <code>PUPIL OK</code> and <code>CR OK</code> in white text e.g.  PUPIL OK </p> <p>Info</p> <p>Default settings for the display resolution of the EyeLink 1000 are set to 1920 x 1080 in the PHYSICAL.INI file that specifies the settings (screen_pixel_coords = 0.0, 0.0, 1920.0, 1080.0). It\u2019s important that it is matched with the actual display resolution you use, as the calibrated gaze data is in pixels. If you use a different display resolution, you can change the settings, but don\u2019t do this in the PHYSICAL.INI file.  Rather, copy the command line to the FINAL.INI file and change the setting there (this will override the settings in the PHYSICAL.INI file). All setup files (.ini files) are stored in the C:\\ELCL\\EXE directory. Remember to reset it to the default setting after you finished your experiment!  The best way to set the display resolution is to have your script send a command to the Host PC to update this parameter based on the resolution you are using. For example ... Eyelink('Command', 'screen_pixel_coords = 0 0 1920 1080');</p> <ul> <li>Check which eye is being tracked in the EyeLink Host Computer! (the last known settings are used, which may be different to your own settings).</li> </ul>"},{"location":"meg/acquisition/eyelink_operations_guide/#calibration","title":"Calibration","text":"<p>Info</p> <p>When writing your own applications, try to match the background colour of the screen during calibration and validation to that of the test displays. Changes in pupil size caused by large brightness differences can degrade the system accuracy. A velocity threshold of 22 <sup>o</sup>/S allows detection of saccades as small as 0.3<sup>o</sup>, ideal for smooth pursuit and psychophysical research. A conservative threshold of 30<sup>o</sup>/S is better for reading and cognitive research, shortening saccades and lengthening fixation durations. The larger threshold also reduces the number of microsaccades detected, decreasing the number of short fixations (less than 100 msec in duration) in the data. Use of eye-movement acceleration is important for detection of small saccades, especially in smooth pursuit.Acceleration data has much more noise than velocity data, and thresholds of 4000<sup>o</sup>/S<sup>2</sup> for small saccade detection and 8000<sup>o</sup>/S<sup>2</sup> for reading and cognitive research are recommended. Check your sample rate: Lowering the sample rate to less than 2K can help with the stability of the eye tracker. Our Default is 1000Hz for both monocular and binocular.</p> <p>Info</p> <p>Two useful links to Eyelink PTB code (on Github) can be found below ... EyelinkDoTrackerSetup.m Psychtoolbox/PsychHardware/EyelinkToolbox/Contents.m  Our In-House code EyeLink_Demo.m - With many thanks to Dr. Yali Pan</p> <ul> <li>Set the desired Calibration and Validation settings.<ul> <li>From the SET OPTIONS screen, choose the Calibration Type and Pacing Interval.The current Default is a 9-point grid and 1000msec (1sec) interval. 9-point calibration is standard, but Participants who find that difficult can be given an easier 5-point or 3-point calibration. Click on the relevant \"Calibration Type\" as necessary.</li> <li>It is recommended to perform the Calibration in a randomised order , so make sure the Randomize Order box is selected.</li> <li>Uncheck/disable Force Manual Accept to make the fixation point move automatically once the first calibration position is registered.Otherwise, the <code>spacebar</code> or <code>Enter</code> key will need to be pressed  on the Stim or Host PC to gather the next point once the Participant has fixated their eyes.</li> </ul> </li> </ul> <p>The following steps are echoed/replicated in the example code, EyeLink_Demo.m</p> <ul> <li>Start TRACK.EXE on the Stim PC (<code>Programs -&gt; SR Research \u2013&gt; EyeLink -&gt; Track</code>), or start relevant Stimulus paradigm code incorporating any/all of the example MATLAB code. The Stim PC ADMIN account password will be required to start \"TRACK\".<ul> <li>The Offline Screen should appear.</li> <li>Press <code>ENTER</code> to start camera setup, the Camera Setup screen should appear.</li> </ul> <p>Info</p> <p>USEFUL HOTKEYS  - ENTER - show camera image (e.g. Participant eye on Projector screen)   - Left/Right \u2013 switch between zoomed in/zoomed out camera image  - C - Calibration  - SPACE - start Calibration  - ENTER - accept Calibration  - V - Validation   - SPACE - start Validation  - ENTER - accept Validation  - D - to drift-correct  - ESC - to exit (use carefully!)</p> <ul> <li>Begin Calibration by pressing the \"C\" key, or the \"Calibrate\" button from the Camera Setup menu on the EyeLink Host PC.The first fixation point needs to be manually accepted by pressing the <code>spacebar/ENTER</code> keys. </li> <li>On the screen, the letter \"D\", in GREEN (left eye) and in BLUE (right eye) will appear, which moves when the Participant moves their eyes.   When the \"D's\" (pupils) appear stable on the fixation point, press \"Accept Fixation\", or the <code>ENTER</code> button or <code>spacebar</code> to accept the first fixation, then let the sequence run by itself (if Force Manual Accept was previously unchecked). </li> </ul> <p>The <code>spacebar</code> may need to be pressed to start the calibration.</p> <ul> <li>Whenever the Participants' gaze reaches a fixation/calibration point, a white cross will appear on the EyeLink Host PC \"Calibrate\" screen. For a 9-point calibration, these crosses need to form a perfect grid.<ul> <li>To achieve that, the Participant is asked to focus on the centre of the fixation points and not to change their gaze until the fixation point disappears.<ul> <li>\"Please don't move your head\"</li> <li>\"Please look at the middle of the dot\"</li> <li>\"Please don't move your eyes until the dot moves\"</li> </ul> </li> </ul> </li> </ul> <p>Even if eye tracking is not required (only pupil size is being monitored), it is still recommended to do at least a 3-point calibration.</p> <p>Info</p> <p>Use the <code>Backspace</code> key to undo recent calibration targets if they are proving problematic to collect.</p> <ul> <li>With each press, the data collected for the last point in the calibration sequence is erased and new calibration data can then be obtained.</li> <li>This can be used to improve calibration accuracy for one or few selected points without having to restart calibration, and is especially helpful for those Participants whose calibration data is hard to collect.</li> </ul> <ul> <li>When the last calibration target has been presented, the calibration will be evaluated. At the bottom of the Calibrate screen, each eye's calibration is graded and displayed as follows:<ul> <li> GOOD : No obvious problems found with the data.</li> <li> FAILED : Could not use data, calibration must be repeated.</li> <li>An example of a \"GOOD\" result is shown below.</li> </ul> </li> </ul> <p></p> <ul> <li>A \"GOOD\" calibration is also indicated by a regular pattern of parallel horizontal and vertical lines formed by the calibration fixation crosses, as shown below.</li> </ul> <p></p> <ul> <li>If the calibration was successful, press the \"Accept\" or <code>ENTER</code> button to accept the result. Press \"Restart\" or the <code>ESC</code> button to \"restart the calibration\".<ul> <li>Pressing <code>ESC</code> twice exits to the \"Camera Setup\" screen.</li> </ul> </li> </ul> <p>NOTE: NEVER press the <code>ESC</code> key at the calibration end, when the calibration grid is displayed, if the current calibration is wanted to be kept. Doing so will DISCARD the current calibration, and the software will revert to any existing cached calibration.A recalibration may then be required.</p>"},{"location":"meg/acquisition/eyelink_operations_guide/#validation","title":"Validation","text":"<ul> <li> <p>Begin Validation by pressing the \"V\" key, or the \"Validate\" button from the Camera Setup menu on the EyeLink Host PC.  A round, coloured, cursor will show the Participant's gaze position.</p> </li> <li> <p>Once the cursor appears stable and close to the target, press <code>ENTER</code> to manually accept the first fixation, then let the sequence run by itself, or manually accept each fixation by pressing <code>ENTER</code></p> </li> <li> <p>Every time the Participant\u2019s gaze reaches a validation point, a cross is displayed to mark its computed position relative to the target and a value (degrees of deviation) appears on screen next to it. All these values need to be below 1 degree of error.</p> </li> </ul> <p>Info</p> <p>As with the Calibration procedure, if necessary use the <code>Backspace</code> key in the middle of a Validation sequence to redo data collection for the last or last few Validation points collected.</p> <ul> <li> <p>After the final fixation is collected, the average and maximum errors are displayed at the bottom of the screen, and the accuracy is scored. Each eye is graded separately, using coloured messages similar to the calibration results:</p> <ul> <li> GOOD : Errors are generally acceptable.</li> <li> FAIR : Errors are moderate, calibration should be improved.</li> <li> POOR : Errors are too high for useful eye tracking.<ul> <li>View the pattern of errors for each target position. If only one target has a large error, the Participant may have simply mis-fixated that point, and the validation can be repeated to check this: press <code>ESC</code> to return to the Camera Setup screen, and press \"V\" to repeat the validation. If a systematic pattern of error is seen (i.e. all fixations on the left side are too low) there is probably a calibration or camera setup problem. In this case, press <code>ESC</code> to return to the Camera Setup screen, adjust the set-up as needed, and repeat the calibration.</li> </ul> </li> </ul> </li> <li> <p>Repeat the Calibration if Validation is poor (deviations of more than 1 degree are observed for each point).</p> </li> <li> <p>Press \"Accept\" or <code>ENTER</code> if the Validation results are acceptable.  </p> </li> <li> <p>Close \"TRACK.EXE\" if the Validation is good.  If using EyeLink PTB code, pressing <code>ESC</code> will exit (ending the calibration/validation routine) to the experimental paradigm, allowing it to continue.</p> </li> </ul>"},{"location":"meg/acquisition/eyelink_operations_guide/#run-experiment","title":"Run Experiment","text":"<p>Note</p> <p>If the EyeLink partition is almost full, then Tracker may fail to start.Copy off and then delete some of the older EDF files from the exe (/elcl/exe) directory via the File Manager.</p> <ul> <li>Start experiment.Make sure that the EDF filename/Participant Name to store the data does not exceed 8 characters otherwise the data may not properly transfer over at the end of the experiment (an error mesasge will pop up when copying the EDF file to the Stim PC is attempted). EDF data from a previously-saved session could also be potentially overwritten!</li> </ul> <p>Info</p> <p>This is an old DOS naming convention (older EyeLink trackers run on DOS).SR Research have kept to this file naming convention, even with newer Windows-based eye trackers, for consistency across software versions.</p> <ul> <li>When the experiment is finished, the EyeLink PTB code should exit from the Tracker application to the File Manager. If not, press <code>CTRL+ALT+Q</code> to exit the Tracker application, or select \"Offline\" then \"Exit EyeLink\".</li> </ul> <p>Note</p> <p>If the battery, or AC Power, is switched off BEFORE the Tracker appliaction is exited, the EyeLink Host PC will complain (loud beeping!).Repower the camera head/illuminator, and then exit the Tracker application back to the File Manager and then switch off the battery/AC Power.</p> <ul> <li> <p>If the last user of the day, switch off the EyeLink battery/AC Power, remove/tidy up the FO cable/power cable, and remove the battery from the MSR \u2013 putting it back on charge (if possible, otherwise leave a note for MEG Support/next Operator to put it on charge the following morning - attach a piece of Micropore tape to the battery front). Replace the lens cap on the FO camera head, and put the FO camera head/IR Illuminator back on a shelf in the MSR cabinet. </p> </li> <li> <p>Copy off any required EyeLink Data Files (EDF) from the Host PC (see September 2020 infomation below), or check that any relevant EDF files were copied automatically to the Stim PC (if experimental code is set up to do that) ...</p> </li> <li> <p>... and then shutdown the Host PC. </p> <ul> <li>From the File Manager interface, select the Power button (top right), or Shutdown Host from the EyeLink screen. Switch off the monitor, and then switch off the bar plug on the table. </li> </ul> </li> <li> <p>Sleep the PROPixx projector. (See relevant section in Tidying Up). </p> </li> </ul> <p>Info</p> <p>September 2020: The EyeLink Host PC software was updated from 5.14 to 5.15, to help troubleshoot a MEG Operator's stimuli.</p> <p>Most of the changes are under-the-hood, so should be transparent to usage. The only change that might impact usage, is that the default storage location of EDF files on the Host PC has been moved from the \"Data subfolder\" to the \"Exe subfolder\".</p> <p>Sam, from SR Research says ...\"The location of the EDF file on the Host PC should be irrelevant for most users as the EDF should always be transferred to the stimulus display PC at the end of the task - the copy on the Host PC is really just there as a back up in case people somehow lose or delete the copy on the display PC. But letting people know will hopefully prevent any panics if people go looking in the data subfolder and don't see any EDFs!\" </p>"},{"location":"meg/acquisition/eyelink_operations_guide/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Ensure the MSR is as dark as possible when trying to find the pupil and when undertaking the calibration e.g. close the door, or push the door to. Turn the lights down or off.</li> <li>If still having issues, ask Participant to close their eyes for a few seconds to reset the pupils.</li> <li>If Participant is tall, place the relevant-size TABLE RISERS under the table legs, so the camera is more in line with their pupils. Three heights are available.</li> <li>To check focusing, look at the eyelashes. When they are in sharp focus the image of the eye is usually good enough.</li> <li>To help with Calibration quality, ask Participant to look along the edges/four corners of the display after performing the camera setup. Be sure to instruct Participant to fixate within the bounds of the display, or loss of tracking may occur because they have looked too far outside of the trackable range of the eye tracker, not because of a poor set-up.  Watch for the warning signals on the tracker screen to make sure that the Pupil and Corneal Reflection (CR) signal are not lost when the Participant is doing so, and check the CR is not becoming distorted or \"smeared\" when the Participant looks at the top corners. Try adjusting the screen position to increase the viewing distance and raising the camera when CR smearing is seen (typically at the upper portion of the display). Table risers are available to help with this.</li> <li>Participants who have never been calibrated before may require some practice in stably and accurately fixating the calibration targets. Try to perform at least two calibrations per Participant before beginning to collect data.</li> <li>Always check the pattern of the calibration grid. For a 9-point calibration, the fixation crosses should form three parallel horizontal (or close-to-horizontal) lines and three parallel vertical (or close-to-vertical) lines.Redo the calibration or camera setup if this is not seen.</li> <li>If the current calibration looks good, press either the \"ENTER\" key to accept the calibration or press \"V\" to go to validation screen.Never press the ESC key - doing so will discard the current calibration and thus revert to the cached calibration results.</li> <li>Encourage Participants to sit still! A Participant who doesn't sit still is proably not paying proper attention to the experimental task. Try to give the Participant a short break in the middle of the experiment and (if possible) recalibrate before resuming the experiment.</li> <li>When writing stimulus paradigms, try matching the background color of the calibration and validation screen to that of the experimental displays.  Changes in pupil size caused by large changes in brightness between the calibration and the experimental displays will degrade the system accuracy. At the beginning of the experiment, let Participant adapt to the environment and the ambient light levels before performing calibration and data collection. If the illumination levels are altered (i.e. the lights are dimmed) shortly before the experiment begins, the calibration accuracy will be reduced as the Participant adapts to the new illumination level and the pupil dilates or constricts.</li> <li>If the validation is off, redo BOTH the calibration and the validation. Validation deviation needs to be less than 1 degree of error.</li> <li>Calibration improves when Participant is:<ul> <li>Asked to \"not move your head\".</li> <li>Asked to \"look at the middle of the dot\".</li> <li>Asked to \"not move your eyes until the dot moves\".</li> </ul> </li> <li>If the Eyelink Host PC starts to beep, either the battery has run down or the battery has been switched off BEFORE the EyeLink software has been exited first.</li> <li>CALIBRATION BEEPS: (Some Participants reported the beeps are too loud through our Natus audio system.)<ul> <li>If using Experiment Builder, click on the EL_CAMERA_SETUP node and turn the relevant properties from \"DEFAULT\" to \"OFF\".</li> <li>If using Psychtoolbox (MATLAB) or PsychoPy, some comands can be sent to the Host PC to turn the beeps off. E.g. in Psychtoolbox set these parameters to \"0\" instead of \"1\".</li> </ul> </li> </ul> <pre><code>% Set calibration beeps (0 = sound off, 1 = sound on)\nel.targetbeep = 1; % sound a beep when a target is presented\nel.feedbackbeep = 1; % sound a beep after calibration or drift check/correction\n</code></pre> <ul> <li>OLDER PARTICIPANTS: The biggest problem is likely to be Ptosis (\"droopy eyelids\"). The top eyelid can obscure the top of the pupil, making it difficult for the eye tracker to determine the pupil\u2019s centre.<ul> <li>Whilst monitoring the thumbnail images of the eye(s), it may help to issue verbal prompts to \"try and keep your eyes wide open\" as often as necessary.</li> <li>On the \"Camera Setup\" screen, changing the \"Pupil Tracking\" from \"Centroid\" to \"Ellipse\" can sometimes help. In Ellipse mode, the Host software draws a green circle around the pupil and tracks the centre of the circle. This sometimes helps the tracking cope a bit better if the top of the pupil is obscured by the eyelid.</li> <li>Rather than reduce the light levels, increase them or have the MSR lights on full. This will cause the pupil size to decrease, and smaller pupils are easier to track in this context. In low light conditions, the pupil will expand making it more likely to be obscured by the eyelid and harder to track.</li> <li>Moving the camera head/illuminator closer, rather than raising it, may also help, as looking up at the eye at a steeper angle may expose more of the smaller pupil.</li> <li>When recruiting older Participants, ask if they have had eye surgery (particularly cataract removal). This can cause corneal scarring and result in flat spots on the cornea, both of which can make tracking difficult or impossible and may discount them as a potential experimental subject if recording eye movement is vital.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/eyelink_settings/","title":"EyeLink Settings","text":"<p>Screen Dimensions:</p> <ul> <li>Width: 830mm - Width of the viewable portion of the projected Stim PC monitor image.</li> <li>Height: 470mm - Height of the viewable portion of the projected Stim PC monitor image.</li> </ul> <p>NOTE: These values may change, depending on the position of the projector screen relative to the projector mirror.Stimulus paradigm will also determine the screen position - use tape on the MSR floor to help with projector screen placement.</p> <p>Display Resolution of Stim PC monitor:</p> <ul> <li>Width: 1920 pixels</li> <li>Height: 1080 pixels</li> </ul> <p>This setting only needs to be changed, in FINAL.INI, if a different display resolution is used to the one above.</p> <p>Eye-to-Screen Distance:</p> <ul> <li>1000mm - Distance from the eye to the top of the viewable portion of the projected Stim PC monitor image.</li> <li>1050mm - Distance from the eye to the bottom of the viewable portion of the projected Stim PC monitor image).</li> </ul> <p>NOTE: These values may change, depending on the position of the projector screen relative to the gantry chair/participant. e.g. 1500mm.Some Operators also measure Distance from the eye to the center of the viewable portion of the projected Stim PC monitor image.</p> <p>EyeLink lens defualt setup:</p> <ul> <li>35mmm - Used by most Operators. 50mm lens is available on the MSR shelving if required.<ul> <li>Swap back to 35mm after use.</li> </ul> </li> <li>\"I put the eye tracker very close to the participant, so smaller lens will give me a wider angle to cover the whole visual fields\" Yali Pan.</li> </ul> <p>Camera-to-Screen Distance:</p> <ul> <li>150mm - Only applicable in \"Remote\" mode (which is not used), so can safely be ignored.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/","title":"MEG Data Acquisition Checklist","text":"<p>Guidelines to MEG Data Acquisition (Customer training, May 2020)  User Manual April 2017 Data Acquisition v6.0</p> <p>Click on the checklists to mark your progress through data collection.</p> <ul> <li> On arrival, sanitise your hands with the provided Anti-bac foam (dispenser on wall outside Control Room).</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#prepare-control-room-msr","title":"Prepare Control Room &amp; MSR","text":"<ul> <li> <p> Check functioning of stimulus and response equipment.</p> Select the stim PCSelect the parallel port <ul> <li>Select the correct Stim PC via KVM.<ul> <li>Press button 1 to connect to the OLD Stim PC.</li> <li>Press button 3 to connect to the NEW Stim PC.<ul> <li>LED Meanings.</li> <li>Green/Dark for connected PCs, but not active.</li> <li>Green/Red for connected PCs actively using the KVM.</li> <li>Dark/Dark for no connection.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Select the correct Parallel Port via the Parallel Port (PP) Switch Box.<ul> <li>PP Switch position A to connect STI101 to the OLD Stim PC (PP Base Memory Address: BFF8).</li> <li>PP Switch position B to connect STI101 to the NEW Stim PC (PP Base Memory Address: CFF8).</li> <li>PP Switch position C to connect STI101 to the LabJack U3-LV connected via USB to the NEW Stim PC.</li> </ul> </li> </ul> </li> <li> <p> Check Gantry position. Move from liquefaction (25) position to usage position.</p> <ul> <li>Moving the Gantry</li> </ul> </li> <li> <p> Check experimental paradigm.</p> Check the PROPixx projectorCheck Stimuli, Responses and Triggers <ul> <li>Check the PROPixx projector is \"awake\" (make sure lens cover is removed).<ul> <li>Start the VPutil program, from the Stim Desktop shortcut, and type...</li> <li>(ANY DEVICE) &gt; <code>ppx a</code> - should respond with \"PROPixx is in awake mode\"</li> <li>To \"sleep\" the projector ...</li> <li>(ANY DEVICE) &gt; <code>ppx s</code> - should respond with \"PROPixx is in sleep mode\"</li> </ul> <p>Please do not leave the PROPixx projector in awake mode when not in use e.g. overnight!</p> <p><code>ppx a / ppx s</code> didn't work on one occasion. PROPixx needed a full power off/on to reset.</p> </li> </ul> <ul> <li>Check that the stimuli and responses are as expected.</li> <li>Check arrival of triggers in MEG recording.</li> </ul> <p>New Stim PC PP card has a different Base Memory Address than the OLD Stim PC PP card.</p> <p>Change any, e.g. MATLAB, code on the NEW Stim PC, referencing the PP Base Memory Address to... CFF8 ... e.g. in <code>initialiseParallelPort.m</code></p> </li> <li> <p> Start participant preparation - items to have ready/available.</p> <p>Reusable and disposable electrodes are available for use as required.</p> <ul> <li>Label 4 electrodes for EOG, 2 electrodes for ECG and any other (i.e. EMG) electrodes as required. Have some additional electrodes ready in case you have to redo them.</li> <li>Electrode gel (in 20ml syringes - use the caulking gun to fill them.) We also have 12ml curved tip syringes available.</li> <li>Cut tape ready for attaching electrodes to skin (Tegaderm tape).</li> <li>Cut tape for securing electrodes (Micropore tape) and Blenderm tape for attaching cHPI coils.</li> <li>Small double-sided sticky discs used to secure reusable electrodes.</li> <li>If using an EEG cap, check it over for damaged electrodes. Makes sure it's clean and dry.</li> <li>Set up the Digitiser chair, away from any metal. Attach the transmitter cube to the back of the chair. The cable has to point downwards.</li> <li>See this page for our various consumable items - MEG Consumables.</li> </ul> </li> <li> <p> Check the MSR, yourself, and participant, for any unwanted items that could cause artefacts and remove them.</p> <ul> <li>See this PDF... Metal items Checklist</li> </ul> </li> <li> <p> Check that the participant monitoring camera and microphone are working correctly.</p> </li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#prepare-meg-system","title":"Prepare MEG system","text":"<ul> <li> Login to the Console, start MEG Acquisition program (megacq).</li> <li> Load latest Tuning file, check quality of channels. \"Heat Sensor\", \"Reset Channels\" as necessary.<ul> <li>See this flowchart Noisy Channels, or for a more detailed process see this walkthrough To fix noisy channels.</li> </ul> </li> <li> Exit Tuner and return to megacq. Adjust Settings<ul> <li>Select Project, or create new.</li> <li>Input pseudonymised participant details from Participant Logging Computer (PLC).</li> <li>Adjust Acquisition parameters or load settings... <code>File -&gt; Load settings</code> .</li> <li>Create or adjutst stimulus generation, on-line averaging (as necessary).</li> </ul> </li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#prepare-participant","title":"Prepare participant","text":"<ul> <li> Offer bathroom break.</li> <li> Explain preparation procedure.</li> <li> Explain experiment.</li> <li> Have participant read and sign ethics consent and screening questionaire.</li> <li> Have participant remove metal objects, and do a comprehensive check with both metal detectors. Participant to change into scrubs if necessary (show participant to Changing Room and show scrubs sizes that are available).</li> </ul> <p>We are trying to reduce our laundry bill so only use scrubs if necessary e.g. metal in clothing.</p>"},{"location":"meg/acquisition/meg-acquisition-checklist/#attach-electrodes","title":"Attach electrodes","text":"<p>Reusable and disposable electrodes available for use as required.</p> <ul> <li> Clean hands with provided Alcohol Gel Sanitiser.</li> <li> Ask participant to sit in Digitisation Chair.</li> </ul> <p>When ready to attach a reusable electrode:</p> <ul> <li> Carefully attach a sticky disc to the electrode, centering the hole over the grey Ag/AgCl. Remove the paper protective cover, exposing the disc adhesive.</li> <li> Using a gel-filled syringe and blunt needle, place a drop of gel in the electrode center and place the electrode on the prepared site.</li> <li> Do not pull on the cable when applying it or when attached. Apply Micropore tape as necessary to help secure it in place.</li> </ul> <p>If using the NeuroTab disposable electrodes.</p> <ul> <li> Remove the transparent backing from the electrode and place the electrode on the prepared site.</li> <li> To ensure good contact, apply pressure to the center of the electrode and move to the edges.</li> <li> Do not pull on the cable when applying it or when attached. Apply Micropore tape as necessary to help secure it in place.</li> </ul> <p>For either electrode type:</p> <ul> <li> Where necessary, remove makeup with the provided Micellar water and cotton pads.</li> <li> Rub skin with alcohol wipes where the electrodes and HPI coils will be attached (see Figure 1 below). </li> </ul> <p>Don't overdo it as the skin can become sensitive.</p> <ul> <li> Some Operators also like to then abrade the skin with NuPrep paste. <ul> <li>Using one of our small stainless steel bowls, squeeze out some NuPrep and rub it onto the skin using a cotton bud.</li> <li>Use tissues to gently wipe-off excess NuPrep as it is non-conducting (some Operators then like to re-rub the skin with an alcohol wipe).</li> </ul> </li> <li> hEOG: Attach an electrode on the outside of the subject's left eye (hEOG left) and on the outside of the subject's right eye (hEOG right). </li> <li> vEOG: Attach an electrode above subject's right eye (vEOG up) and below the subject's right eye (vEOG down). </li> </ul> <p>In both cases, make sure that the electrodes are in line with the eyes - horizonally &amp; vertically.</p> <ul> <li> ECG: Attach an electrode on the left collarbone (ECG left) and on the right collarbone (ECG right).</li> <li> GND: Attach an electrode on the back of the subject's neck (GND).</li> <li> REF: Attach an electrode on the subject's right cheekbone (REF).</li> </ul> <p> Figure 1: Standard locations of EOG and ECG electrodes</p> <p>Note</p> <p>REF may not be required for the bipolar EOG, ECG, but use as necessary if channels are noisy. For EMG, site REF electrode where required/as per your paradigm. Use Micropore tape over the electrodes to help hold them in place.</p> <p>Our Electrode input on the gantry is to the right of the subject, so we use the right eye for vEOG.</p>"},{"location":"meg/acquisition/meg-acquisition-checklist/#check-impedance-of-electrodes","title":"Check impedance of electrodes","text":"<p>Use the SIGGI II impedance meter</p> <ul> <li> Press the white button, labelled Enter/Esc, on the jog-shuttle to turn on.</li> <li> Press the white button again to enter Impedance Meter menu.</li> <li> On the top side of the SIGGI (\"Single-Ch-In\") plug GND electrode into \"N\".</li> <li> On the top side of the SIGGI plug REF electrode into \"-\".</li> <li> On the top side of the SIGGI plug the electrode of interest into \"+\".</li> </ul> <p>If measuring EEG cap impedance, use the provided adapter.</p> <ul> <li> Cycle through all electrodes, and make sure the impedance is &lt;10kOhm.</li> <li> Quit Impedance Meter by selecting Return symbol and press Enter/Esc. </li> <li> Select Power off via the jog-shuttle and press Enter/Esc.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#attach-hpi-coils","title":"Attach HPI coils","text":"<p>Why do we attach HPI coils?</p> <p>Our HPI coils are energised at different frequencies (now 25Hz separation) compared to the default  (HPI Coil Placement and Frequencies)</p> <ul> <li> If necessary test the HPI coils first, for continuity, uisng our HPI Coil Tester With many thanks to Gary Chandler &amp; David Hayes (MRC-CBU).</li> <li> Attach HPI coils with either Tegaderm tape, Blenderm tape, or Micropore tape, on the forehead below the hairline, and behind the ears (where there is exposed skin) as shown in Figure 2 below.</li> </ul> <p>Note</p> <ul> <li>If using Micropore, a good trick is then to mark the center of the tape-covered HPI coil with a pencil to aid digitisation/locate the stylus tip correctly.</li> <li>The coils must be covered by the MEG helmet/sensor array, so place them as high on the head as possible.</li> <li>The coils behind the ears as high up as possible, without being in the hair.</li> <li>The coils on the forehead well separated, but not in the hair.</li> <li>The coils should not be directly under the Internal Active Shielding (IAS) reference channels, i.e. they should not be in the middle of the forehead, on the inion or near peri-auricular points.</li> <li>The most precise HPI information is obtained when the coils are as far apart as possible but still within the sensor helmet.</li> <li>Try avoiding situations where coils form a nearly perfect square.</li> </ul> <ul> <li> If using only 4 coils, tape the 5th (YELLOW) coil to the shoulder. This one will not be used or digitised.</li> </ul> <p>Note</p> <ul> <li>If desired, The 5th coil can be placed in the upper parietal region, preferably somewhat off midline.</li> <li>Do not place the fifth coil directly on vertex as it may interfere with the Internal Active Shielding (IAS) if turned on. </li> <li>Avoid the locations of the zero detectors when placing the HPI coils in order to prevent this problem. Refer to the IAS User\u2019s Manual section found in the User's Manual for zero detector locations (middle shelf, right-hand white cupboard in Control Room).</li> </ul> <ul> <li> Place the Polhemus goggles carefully on your participant, or attach the small receiver firmly on the forehead using tape. Make sure the coils do not come unstuck.</li> </ul> <p> Figure 2: Standard locations of HPI coils </p> <p>Please don\u2019t rush the HPI coil attachment!</p> <ul> <li>The better the coils are attached, the less likely they will move during digitisation and when the participant is sitting in the gantry chair.<ul> <li>Less likely to produce a non-Acceptance when performing the megacq HPI check.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#digitise-head-coordinate-system","title":"Digitise head-coordinate system","text":"<p>Make sure that the goggles don't move when making the digitisation.</p> <p>The order in which the fiducial points are digitised does not matter.</p> <ul> <li> Turn on the Polhemus system (switch on the back right of the unit).</li> <li> Place the Transmitter cube in the grey bracket on the back of the Digitisation chair, with the cable pointing down.</li> <li> Place the Polhemus goggles on your Participant.</li> <li> Click Change next to HPI: not digitized! in the Acquisition control Settings panel.</li> <li> Click Coordinate frame alignment in the Head shape digitization window.</li> <li> Remove the black rubber tip cover from the stylus. Do not drop the stylus as the point is easily damaged!<ul> <li>Rest the tip of the stylus gently on the first fiducial point, e.g. nasion or a peri-auricular point (see green crosses in Figure 2 above), and press the stylus button.</li> <li>Repeat this procedure for the other two fiducial points. You should hear two beeps after the 3rd point, signfying completion.</li> </ul> </li> <li> If time allows, as a sanity-check, to make sure the measured location of the fiducial points are in still in alignment...<ul> <li>Click Coordinate frame alignment again, and select Check from the pop-up window.</li> <li>Digitise all three fiducial points (cardinal landmarks) again by pressing the stylus button after each beep. You should hear two beeps after the 3rd point, signifying completion.</li> <li>To abort digitise a point 75cm from the head origin/receiver, by pressing the stylus button at that distance.</li> <li>Deviations from the first digitisation will appear in another pop-up window after you have digitised all three fiducial points/landmarks.</li> <li>Deviations &lt; 5mm are considered to be \"OK\", no redo required.</li> </ul> </li> <li> If necessary (values &gt; 5mm), redo measurement by clicking Coordinate frame alignment again and selecting Redo.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#digitise-hpi-coils","title":"Digitise HPI coils","text":"<p>The coils must not move relative to the head during the measurement!</p> <p>The order in which the HPI coils are digitised does not matter.</p> <ul> <li> Click HPI coils in the Head shape digitization window.<ul> <li>Rest the tip of the stylus gently in the little hole in the centre of a coil and press the stylus button.</li> <li>Repeat this procedure for the other three coils, as shown in Figure 2 above.</li> </ul> </li> <li> Stop the digitisation after the 4th coil (if only using four coils) by digitising a point 30cm from the head origin.<ul> <li>Hold the stylus that distance away from the receiver on the Polhemus goggles, and press the stylus buttton once. You should hear two beeps.</li> <li>If you were digitising all five HPI coils, you should hear two beeps after the 5th coil, signifying completion.</li> </ul> </li> <li> If time allows, as a sanity-check, to make sure the measured locations of the HPI coils are in alignment.<ul> <li>Click HPI coils again, and select Check from the pop-up window.</li> <li>Digitise all four (or five) HPI coils again by pressing the stylus button after each beep.</li> <li>To abort, digitise a point 30cm from the head origin/receiver, by pressing the stylus button at that distance.</li> <li>Deviations from the first digitisation will appear in another pop-up window after you have digitised all four (or five) HPI coils.</li> <li>Deviations &lt; 5mm are considered to be \"OK\", no redo required.</li> </ul> </li> <li> If necessary (values &gt; 5mm), redo measurement by clicking HPI coils again and selecting Redo.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#digitise-head-shape","title":"Digitise head shape","text":"<ul> <li> Leave the Polhemus goggles in place on your participant, then ...</li> <li> Click Pen in the bottom right (Additional Data) window.<ul> <li>Gently stroke the tip of the stylus (usually with the black rubber tip cover in place) over several (especially bony) shapes of the head ... eyebrows, around the eyes, nose, and along the scalp, ...to capture the head shape, while pressing the button of the stylus.</li> <li>At least 200 extra points would be the minimum number to digitise.</li> </ul> </li> <li> Ideally select the cardinal landmark locations again as the last 3 points you collect.</li> <li> Stop when ready by digitising a point 30cm from the head origin. <ul> <li>Hold the stylus that distance away from the receiver on the Polhemus glasses and click the stylus button once. You should hear two beeps.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#prepare-the-participant-in-the-msr","title":"Prepare the participant in the MSR","text":"<p> At all times make sure your participant knows what is going to happen. Make him/her comfortable in expressing his/her opinions.</p> <ul> <li> Before escorting the participant into the MSR, secure any relevant cables to the body (i.e. shoulder) of the participant e.g. the unused (5th) yellow HPI coil, using Micropore tape.</li> <li> When the participant is seated in the gantry chair, plug in the EOG, ECG, EMG electrodes (as required) into the correct BIO sockets of the gantry side panel, as determined by your experimental setup.</li> <li> Attach the HPI coils (red plug) into the red \"HPI\" socket of the gantry side panel.</li> <li> If used, attach the Natus audio plug into the green \"Patient\" socket of the gantry side panel.</li> <li> Raise participant into the gantry helmet, using the chair foot pedal, until the top of the head almost touches the inside top of the helmet.</li> <li> Make participant comfortable with cushions/pillows and/or by raising the leg rests of the chair.</li> <li> If using, setup the EyeLink 1000 Plus Camerahead/Illuminitor on the small table, placed over the participant's legs. (See the Eyelink 1000 Plus section for more detailed usage).</li> <li> Position the back projection screen in front of the participant, with the glossy side facing them.</li> <li> Place NAtA button pad/s, response device/s - e.g., on the gantry chair waist tray.</li> <li> If necessary, run through the stimulus paradigm again to confirm they know what they need to do/what is required.</li> <li> Exit, then close MSR door.</li> <li> Check communication both ways using the intercom. Put the participant at ease.</li> <li> Check again that the participant is happy/knows what to do.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#if-using-the-eyelink-1000-plus","title":"If using the EyeLink 1000 Plus","text":"<p>See the EyeLink Operations Guide for more detailed usage.</p> <p>NOTE: STIM PC will need to be powered up to allow network communication to the EyeLink PC(both APC Back-UPS 1400s will need to be powered).</p> <ul> <li> Switch on 6-way bar plug on table alongside EyeLink Host PC (to power EyeLink camera (on desk), Host PC, and monitor).</li> <li> EyeLink Batteries: Use a fully charged battery where possible.<ul> <li>Press the TEST button to check the power level (batteries #1 and #2).</li> <li>Power on, and press the TEST button (new batteries #3 and #4).</li> </ul> </li> </ul> <p>\"A battery with 2-3 hours left should be fine for a short experiment. Do not risk using it for a 2-hour experiment\"(SR Research).</p> <ul> <li> Put any used battery on charge as required. <ul> <li>Make sure battery is switched OFF when charging.</li> <li>#1 and #2: AC Adapter Orange LED will extinguish when battery is charged.</li> <li>#3 and #4: AC Adapter Red LED will change to Yellow when battery is charged, eventually Green.</li> <li>Unplug battery once fully charged, switch off AC Adapter (at Mains socket).</li> <li>DO NOT leave a battery on charge overnight, or unsupervised!<ul> <li>Leave a strip of Micropore on battery to signify charging required the following day. <li> Swap to a new battery between Acquisition sessions. Put the used battery on charge.</li> <li> Take a battery into the MSR. Place in front left corner (as viewed from gantry chair).</li> <li> Arrange power cable around the edge of the MSR, avoiding any loops. Attach power cable to battery and to FO Camera Head/IR Illuminator. Switch on battery. </li> <p>NOTE: If you don\u2019t power the Camera Head/IR Illuminator first, the Host PC will complain when \"EyeLink\u201d starts up (ticking sound).</p> <ul> <li> Place FO Camera Head/IR Illuminator on small table. Position table as required, use provided table risers as necessary.</li> <li> Turn on EyeLink 1000 Plus Host PC and monitor.<ul> <li>Select \"EyeLink\" with the mouse, or just wait.</li> </ul> </li> <li> Set up EyeLink FO Camera Head/IR Illuminator as per normal usage ...<ul> <li>Adjust Camera Head position, remove lens cap, adjust focus/thresholds etc.</li> </ul> </li> </ul> <p>NOTE: You can view the EyeLink IR lamp via the MSR camera monitor on the wall in the Control Room - helps in checking lamp alignment on the participant.</p> <ul> <li> EyeLink 1000 Plus AC Adapter usage (if batteries have failed/none have enough charge). <p></p> <ul> <li>Unplug the battery cable from the EyeLink FO Camera Head/IR Illuminator, and attach the cable labelled \"AC Adapter\". </li> <li>Coil up the now-unused battery cable and leave it on the shelf.</li> <li>Turn on the EyeLink FO Camera Head/IR Illuminitor power (via switch labelled \"EYELINK\"), in the Stimulus Cabinet (see image right), and close the door.</li> <li>Set up EyeLink FO Camera Head/IR Illuminator as per normal usage.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#start-recording","title":"Start recording","text":"<ul> <li> Instruct participant to remain still and relaxed, and announce the start of the experiment.</li> <li> Start Acquisition by pressing \"GO!\".</li> <li> Tick Record raw.</li> <li> Tick Average (if required).</li> <li> Start experiment on Stim PC.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#finishing-recording-session","title":"Finishing recording session","text":"<ul> <li> When the experiment has finished, press Stop.</li> <li> Inform participant that the experiment is over, to remain seated, and that you will be in there shortly.</li> <li> Save data. If Average was ticked, the first file saved will be the averaged data and the second file will be the raw data.</li> <li> Name your files as per your usual file-naming scheme.</li> <li> Do not change the default path (ProjectName/SubjectID/Date). </li> <li> Enter MSR, disconnect electrode cables and HPI coils. As a help, ask participant to hold cabling.</li> <li> Lower chair by using foot pedal, and pull chair out from under the gantry.</li> <li> Help participant up out of the chair (if required), and escort them back to the Digitisation chair. When seated, gently remove all electrodes and tape.  If used to attach them, remove the Tegaderm tape from the HPI coils as soon as convenient - see Tidying Up page.</li> <li> Copy off Acquired data to RDS. Ideally now, but when Lab is next free if under time constraint - see Copying MEG data page.</li> </ul>"},{"location":"meg/acquisition/meg-acquisition-checklist/#tidying-up-separate-page","title":"Tidying Up (separate page)","text":"<ul> <li> <p> Some procedures only need to followed if End of Day, as indicated by Orange wording in the document.</p> </li> <li> <p>Most equipment can be left on during normal working hours.</p> </li> </ul>"},{"location":"meg/acquisition/meg-consumables/","title":"MEG Consumables","text":""},{"location":"meg/acquisition/meg-consumables/#location-of-consumablesuseful-items-in-meg-laboratory","title":"Location of Consumables/Useful Items in MEG Laboratory","text":"<p>The majority of the required items are now located in (''or on top of'') the IKEA cabinets on the wall in the Side Room alongside the MSR.</p> <ul> <li>Abralyt gel, Nuprep paste, alcohol swabs, blunt needles, tapes (Tegaderm, Micropore, and Blenderm).</li> <li>Spare electrodes (disposable and reusable), large &amp; small double-sided sticky discs, cotton buds, and cotton wool balls.<ul> <li>Spare disposable electrodes (NeuroTab) on the floor by cryocooler compressor.</li> </ul> </li> <li>Facial wipes, micellar water, round cotton pads.</li> <li>Microphones, 3D Accelerometers, spare L2V converter.</li> <li>Polystrene Heads (to support EEG caps after cleaning).</li> <li>User manuals, EEG caps (old and new) can be found in the right-hand white cabinet in the Control room.</li> <li>MEG-safe glasses/lenses are in the black suitcase on top of the right-hand white cabinet in the Control room.</li> <li>Phantom Phyllis &amp; the Cryo Kit can be found in the left-hand white cabinet in the Control room.</li> <li>Useful adapters (audio/BNC) can be found in a slim clear plastic box on the bottom shelf of the EEG trolley.</li> <li>Spare Isopropyl Alcohol in the red Flammables cabinet in the Changing Room.</li> <li>Towels are housed in the top drawer, located at the bottom left-hand side of the IKEA wardrobe in the Changing Room. </li> <li>Scrubs can be found, in their relevant sizes, on marked shelves on the right-hand side of the wardrobe.</li> <li>Spare green paper hand towels are on the floor by cryocooler compressor. MEG Support/Administrator both have keys to the paper towel holder cabinet in the Control room.</li> <li>Spare BNC cables can be found in a labeled clear plastic box in the IHR/Tank Room (G24).</li> <li>Polystrene heads for EyeLink testing (Phantom Phil) can be found in the IHR/Tank Room (G24).</li> <li>Anti-static pink foam, 20ml syringes, in clear plastic boxes in the IHR/Tank Room (G24).</li> </ul> <p>Please let MEG Support know in plenty of time if any consumables are running low, so a Requisition can be placed to restock.</p>"},{"location":"meg/acquisition/misc_channels/","title":"Miscellaneous Channels","text":"<p>12 analog inputs for miscellaneous analog signals are available (maximum +/- 10V). Connections are made via BNC connectors to a separate interface box similar to STI101 &amp; STI102.</p> <p> Current MISC connections <ol> <li>EyeLink 1000 Plus DAC0 - X - horizontal position</li> <li>EyeLink 1000 Plus DAC1 - Y - vertical position</li> <li>EyeLink 1000 Plus DAC2 - Pupil size</li> <li>Light-2-Voltage Converter (L2V) - #1</li> <li>Light-2-Voltage Converter (L2V) - #2</li> <li>Stereo Audio Output - Left - (from Stim PC, or DATAPixx) - see MEG Audio Connections</li> <li>Stereo Audio Output - Right - (from Stim PC, or DATAPixx)</li> <li>Microphone Input - Left - (response to Stereo Audio Left Output)</li> <li>Microphone Input - Right - (response to Stereo Audio Right Output)</li> <li>Accelerometer Output - X</li> <li>Accelerometer Output - Y</li> <li>Accelerometer Output - Z</li> </ol> <p></p>"},{"location":"meg/acquisition/moving-the-gantry/","title":"Moving the Gantry","text":"<p>Never change the gantry position whilst a particiant is seated under the gantry!</p> <p>For all \"in use\" positions (0, 60 &amp; 68), traffic light should show solid GREEN LED.  In the liquefaction position (25), traffic light should show flashing GREEN LED.</p> <p>After liquefaction has stopped (~9:0am), set the probe unit to the desired measurement position to be able to start a MEG measurement.</p>"},{"location":"meg/acquisition/moving-the-gantry/#moving-probe-unit-from-liquefaction-position-25-to-lower-seated-position-60","title":"Moving probe unit from liquefaction position (25) to lower seated position (60).","text":"<ul> <li> <p>Make sure that no one is underneath the gantry during the position change and that the gantry can move freely up to the lower seated position.</p> </li> <li> <p>Press the UP button on the back side of the probe unit for a few seconds.</p> <ul> <li>The amber Tension LED comes on to show that the probe unit is released from the latches.</li> </ul> </li> <li>Keep pressing the UP button until you hear the latches lock into the 60 (lower seated) position.</li> <li>Press the DOWN button until the pobe unit stops over the latches and the green OK LED comes on.<ul> <li>If any other LED remains lit, press the UP or DOWN buttons as necessary to adjust the gantry position.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/moving-the-gantry/#moving-probe-unit-from-liquefaction-position-25-to-upper-seated-position-68","title":"Moving probe unit from liquefaction position (25) to upper seated position (68).","text":"<ul> <li> <p>Make sure that no one is underneath the gantry during the position change and that the gantry can move freely to the upper seated position.</p> </li> <li> <p>Press the UP button on the back side of the probe unit for a few seconds.</p> <ul> <li>The amber Tension LED comes on to show that the gantry is released from the latches.</li> </ul> </li> <li>Pull down the latch release bar on the back of the probe unit, and keep it pulled down.   </li> <li>Keep pressing the UP button past the lower seated position (60) until the gantry reaches the upper seated position (68) and the movement stops.</li> <li>Press the DOWN button until the gantry stops over the latches and the green OK LED comes on.<ul> <li>If any other LED remains lit, press the UP or DOWN buttons as necessary to adjust the gantry position.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/moving-the-gantry/#moving-probe-unit-from-liquefaction-25-position-to-supine-position-0","title":"Moving probe unit from liquefaction (25) position to supine position (0).","text":"<ul> <li> <p>Make sure that no one is underneath the gantry during the position change and that the gantry can move freely to the supine position.</p> </li> <li> <p>Press the UP button on the back side of the probe unit for a few seconds.</p> <ul> <li>The amber Tension LED comes on to show that the gantry is released from the latches.</li> </ul> </li> <li>Pull down the latch release bar on the back of the probe unit and keep it pulled down.</li> <li>Press the DOWN button until the gantry passes the liquefaction position (25) and stops over the latches at the supine position (0) and the green OK LED comes on.<ul> <li>After the gantry has rotated downwards and passed the 25\u00b0 position, you can release your hand from the latch bar.</li> <li>If any other LED remains lit, press the UP or DOWN buttons as necessary to adjust the gantry position.</li> </ul> </li> </ul> <p>When MEG measurements have finished for the day, move the probe unit to the liquefaction position (25) to allow liquefaction to run efficiently.</p>"},{"location":"meg/acquisition/moving-the-gantry/#moving-probe-unit-from-supine-position-0-to-liquefaction-position-25","title":"Moving probe unit from supine position (0) to liquefaction position (25).","text":"<ul> <li>Remove the bed from the probe unit.</li> <li> <p>Make sure that no one is underneath the gantry during the position change and that the gantry can move freely to the liquefaction position.</p> </li> <li> <p>Press the UP button on the back side of the probe unit until you hear the latches lock into the liquefaction (25) position.</p> </li> <li>Press the DOWN button until the probe unit stops over the latches and the green OK LED starts flashing.<ul> <li>If any other LED remains lit, press the UP or DOWN buttons as necessary to adjust the gantry position.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/moving-the-gantry/#moving-probe-unit-from-upperlower-seated-position-6860-to-liquefaction-position-25","title":"Moving probe unit from upper/lower seated position (68/60) to liquefaction position (25).","text":"<ul> <li>Remove the chair from the probe unit.</li> <li> <p>Make sure that no one is underneath the gantry during the position change and that the gantry can move freely to the liquefaction position.</p> </li> <li> <p>Press the UP button on the back side of the probe unit for a few seconds.</p> <ul> <li>The amber Tension LED comes on to show that the gantry is released from the latches.</li> </ul> </li> <li>Pull down the latch release bar on the back of the probe unit.</li> <li>Keep the latch release bar down and press the DOWN button.</li> <li>Keep pressing the DOWN button. When the probe unit has passed the 60\u00b0 position latches, release the latch release bar without releasing the DOWN button.<ul> <li>If you started from the lower seated position, the probe unit passes the 60\u00b0 position latches in about 3 seconds of driving down.</li> <li>If you started from the upper seated position, the probe unit passes the 60\u00b0 position latches in about 6 seconds of driving down.</li> </ul> </li> <li>With the latch release bar released, keep pressing the DOWN button until you hear the latches lock into the liquefaction (25) position.</li> <li>Keep pressing the DOWN button until the gantry stops over the latches and the green OK LED starts flashing.<ul> <li>If any other LED remains lit, press the UP or DOWN buttons as necessary to adjust the gantry position.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/noisy_channels/","title":"Noisy Channels","text":"<ul> <li>Start the MEG Acquisition program.</li> <li>Load the latest Tuning File (\"He_90.tnp\").</li> <li>Measure Noise, and Heat Channel/s if necessary. Reset Channels is also a good first attempt at a fix.</li> <li>If heating/resetting doesn't help, exit Tuner, exit Acquisition, perform a RAP (Restart Acquisition Programs).</li> <li>Start the MEG Acquisition program again, load the latest Tuning file etc.</li> <li>If that doesn't help, exit Acquisition and Soft Boot the electronics.</li> <li>Run a RAP again, Start Acquisition, load Tuning file etc.</li> <li>If that doesn't help, powerdown/restart electronics - by MEG Support only!</li> <li>Run a RAP again, Start Acquisition, load Tuning file etc.</li> <li>If channels are still too noisy to acquire with, then MEG Support may need to Tune the channels.</li> <li>If still too noisy to acquire, a Help Request with MEGIN Support will be required.</li> </ul>"},{"location":"meg/acquisition/noisy_data/","title":"Noisy Data","text":"<p>If Acquired data is noisy during Acquisition, run a quick check to see if the artefacts can be easily removed using MaxFilter.Collect ~1min or so of data, save, and then \u2026</p> <ol> <li>Start MaxFilter.<ul> <li><code>Applications -&gt; Neuromag -&gt; MaxFilter.</code></li> <li>Dismiss the \"Welcome\" splash screen, click \"Hide\"</li> </ul> </li> <li><code>File -&gt; Working directory</code>.<ul> <li>Example settings files/.fif files, to try, are shown in blue.</li> </ul> </li> <li>In the Select a new working directory window, type the name of the folder location e.g.<ul> <li>/data/neuro-data/demo/221003/ - don\u2019t forget the \u201c/\u201d at the end!</li> </ul> </li> <li>Click \u201cOK\"</li> <li><code>File -&gt; Load data</code>.</li> <li>In the Files window, select the relevant .fif file e.g.<ul> <li>watch_on_chair_30_sec.fif</li> </ul> </li> <li>In the Maxwell filtering task window, select Spatiotemporal tSSS<ul> <li>\"to suppress nearby movement-related artefacts such as metal fillings/a magnetised tooth.\"</li> </ul> </li> <li>Click \u201cOK\u201d.</li> <li>Click \u201cExecute\u201d.</li> <li><code>File -&gt; Exit</code></li> <li>Click \u201cYes\u201d.</li> <li>A file should now have been written to the working directory location, with the addition of \u201c_tsss\u201d to the name of the .fif file chosen in Step 6 above e.g.<ul> <li>watch_on_chair_30_sec_tsss.fif</li> </ul> </li> </ol> <p>Info</p> <p>For more detailed information on usage, please read pages 21 \u2013 25 from Guidelines to MEG Data Analysis Software</p> <p>Compare the before and after MaxFilter files \u2026</p> <ol> <li>Start Graph.<ul> <li><code>Applications -&gt; Neuromag -&gt; Graph.</code></li> <li>Dismiss the \"Welcome\" splash screen, click \"OK\".</li> </ul> </li> <li><code>File -&gt; Load settings</code>.<ul> <li>Example settings files/.fif files, to try, are shown in blue.</li> </ul> </li> <li>In the Directories window, double-click on the settings required e.g.<ul> <li>/home/meguser/lisp/setup/local.</li> </ul> </li> <li>In the Files window, select compare.setup</li> <li>Click \u201cOK\u201d  - two synchronised Windows will appear.</li> <li>In the top Window, <code>File -&gt; Open Diskfile</code></li> <li>In the Directories window, double-click /neuro/data/sinuhe</li> <li>In the next Directories window (left-click on the RH window edge and drag to open the window wider if necessary), scroll down and double-click on the Project e.g.<ul> <li>/neuro/data/sinuhe/demo</li> </ul> </li> <li>In the next Directories window (left-click on the RH window edge and drag to open the window wider if necessary), scroll down and double-click on any relevant sub-directory e.g.<ul> <li>/neuro/data/sinuhe/demo/221003</li> </ul> </li> <li>In the Select disk file to open window, chose the unfiltered .fif file e.g.<ul> <li>watch_on_chair_30_sec.fif</li> </ul> </li> <li>Click \u201cOK\".</li> <li>In the top Window, <code>Displays -&gt; Control Panel</code></li> <li>Open the filtered .fif file by double-clicking the widget \"File2\" (usually to be found bottom left of the Control Panel window).</li> <li>Repeat from Step 7 to Step 10 to select the \"\u2026 _tsss.fif\" file e.g.<ul> <li>watch_on_chair_30_sec_tsss.fif</li> </ul> </li> <li>Click \u201cOK\"</li> <li>View the effect of MaxFilter on the original noisy .fif file (lower window/display2).</li> <li>In the top Window, \"Exit\", \"Exit\", \"Yes\", when finished.</li> </ol> <p>Info</p> <p>For more detailed information on usage, please read from page 57 onwards, as necessary, from Guidelines to MEG Data Analysis Software</p>"},{"location":"meg/acquisition/position_usage_eeg_caps/","title":"Correct Positioning &amp; Usage of EEG Caps","text":"<p>CHBH MEG uses 64 Channel EASYCAPs purchased from Brain Products UK, and have 6 caps available in 4 different sizes. The caps use the 10/20 system of electrode placement.</p> <ul> <li>1 x 54cm, 2 x 56cm, 2 x 58cm, 1 x 60cm</li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#the-international-1020-system","title":"The International 10/20-System","text":"<ul> <li>This system employs connecting lines of anatomical landmarks, with the length of these lines defined as 100%. </li> <li>Electrodes are placed at distances of 10% or 20% in either the longitudinal or the lateral lines, resulting in approximately equidistant points. </li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#cap-sizes","title":"Cap Sizes","text":"<ul> <li> <p>The cap size denotes the circumference of the head in centimeters, with the size labels found at the back of the cap.</p> </li> <li> <p>Measure the participant's head circumference at the \"hat line\" (10% higher than the Nasion, Inion, and ear openings), and choose a corresponding cap size (or one slightly larger).</p> </li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#correct-positioning-of-the-cap","title":"Correct Positioning of the Cap","text":"<ul> <li> <p>Caps are placed on the head in relation to the Nasion and Inion anatomical landmarks.</p> </li> <li> <p>Measure the distance from Nasion to Inion centrally over the head with a tape measure. </p> </li> </ul> <p></p> <ul> <li> <p>Then put the cap on the participant, making sure the Cz electrode position is centered/halfway between the Nasion and Inion.</p> </li> <li> <p>Make sure the cap is left-right symmetric and then close the chin strap.</p> </li> <li> <p>The cap is fitted on the participant correctly when Fp1/Fp2 - O1/O2 - T7/T8, viewed from the side, are all in the same plane (with Fp1/Fp2 close to the eyebrows). </p> </li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#achieving-good-signal-quality","title":"Achieving good signal quality","text":"<p>Good contact between the skin and the electrode, using an electrolyte gel or paste, is essential to maintain low impedance and ensure high signal quality.</p> <ul> <li>With the wooden end of a cotton swab, push aside the hair in the electrode opening until the skin is clearly visible.</li> <li>Clean the skin with 70% Isopropyl Alcohol. Decant some alcohol into the provided stainless steel pot. Rinse out/clean the pot after use. Dip the cotton end of the swab in the pot and then, by twirling the swab between thumb and index/forefinger, degrease the skin in the electrode opening by rotating on the spot. This should reduce the initial impedance to below 30 kOhm.</li> </ul> <p>If possible, ask participants to arrive with their hair washed, without using any conditioner.</p> <ul> <li>Abrade the skin with NuPrep paste. Squeeze some paste into the provided stainless steel pot. Rinse out/clean the pot after use. Dip another cotton swab into the paste and, again, rotate the swab on the spot in the electrode opening. This should further reduce the impedance to below 5 kOhm.</li> </ul> <p></p> <ul> <li>EasyCap EEG caps have large openings in their ring-shaped electrodes, enabling abrasion of the skin by means of a cotton swab.</li> <li>Best results are achieved when rotating the swab FAST (4-5 fast twirls) but with MINIMAL PRESSURE.</li> <li>Using more pressure will only result in reddening of the skin/possible bleeding.</li> <li>\"Quick, but gentle, is the order of the day!\".</li> <li>With low pressure, this procedure is painless and very effective. </li> </ul> <p> <ul> <li>After abrading using NuPrep (removing as much as paste as possible as it is non-conducting), apply electrode gel through each electrode opening, using the filled syringe and a blunt needle.</li> </ul> <p>Check needle is firmly luer-locked in place, and gel is being extruded, BEFORE using the syringe.</p> <ul> <li>Touch the skin with the blunt needle and start to press the plunger. This is to establish contact between the skin and the gel. Only after the gel starts to extrude is the syringe pulled back, filling the electrode opening with gel.</li> </ul> <p>DO NOT re-use the same needle on a second participant. Throw the needle away, in the provided yellow Sharps box, and open a new blunt needle.</p> <ul> <li>If more electrode gel is required, reverse fill a syringe using the provided caulking gun and the 300g gel cartridge.</li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#check-impedances","title":"Check impedances","text":"<ul> <li>As most electrolytes permeate the skin, impedances improve after a few minutes 'magically' by themselves. Thus it's best to fill all the electrodes first, starting with REF and GND, and check the impedances afterward.</li> <li>If needed, repeat the abrasive step by gently twirling with a cotton bud.<ul> <li>Most impedance problems result from insufficient contact between skin and gel or gel and electrode.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#siggi-ii-impedance-meter","title":"SIGGI-II Impedance Meter","text":"<ul> <li>Although the EEG impedances are checked by the Acquisition software, after plugging the cap into the side of the gantry, it is worth checking them whilst the participant is outside the MSR.</li> </ul> <p>SIGGI-II User Manual </p> <ul> <li>The SIGGI-II can measure either single electrodes (Single-Ch-In) or multiple electrodes (Multi-Channel-In).</li> </ul> <p></p> <p> <ul> <li> <p>A customised adaptor (Brain Products UK) allows 32 of the 64 EEG cap electrodes to be checked at the same time, with the Ground electrode plugged into the BLACK GND socket,   and the Reference electrode plugged into the BLUE REF socket.</p> </li> <li> <p>When testing a single electrode e.g. an EOG or ECG electrode ...</p> <ul> <li>Plug a Ground-Electrode into \"N\"</li> <li>Plug a Reference-Electrode into \"-\"</li> <li>Plug the to-be-measured electrode into \"+\"</li> </ul> </li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#switching-the-siggi-ii-on","title":"Switching the SIGGI II On","text":"<ul> <li>Press the white button named Enter/Esc on the jog-shuttle.</li> <li>After a short message the Main Menu will appear on the LCD-display.<ul> <li>SIGGI II starts with the settings stored last within the Setup Menu.</li> </ul> </li> </ul>"},{"location":"meg/acquisition/position_usage_eeg_caps/#impedance-measure","title":"Impedance Measure","text":"<ul> <li>Select Impedance Meter from the Main Menu (turn the jog-shuttle) and press Enter/Esc.</li> <li>The menu Impedance Measurement appears. The electrode impedances of the to-be-measured electrode, the reference- and the ground-electrode are displayed simultaneously.</li> <li>Impedance is shown as a bar graph as well as a numerical value. The range of the bar graph can be adjusted in the Setup menu, and also the Impedance measurement frequency if so desired.</li> <li>The electrode potential of the to-be-measured electrode compared to the reference electrode is shown beneath the selected input channel.<ul> <li>If all the electrodes are the same material =&gt; high potentials indicate faulty electrodes.</li> <li>If the electrode materials are different =&gt; some amplifiers may be unable to process the signal if the electrode potentials are high.</li> </ul> </li> <li>To select the channel for impedance measurement select CH menu and press Enter/Esc.  By turning the jog-shuttle, Single-Ch-In with its three safety sockets, or one of 32 channels of Multi-Channel-In, is selected. Single-Ch-In is depicted by III, whereas Multi-Channel-In is shown by the channel numbers 1\u201332.</li> <li>To quit channel selection press Enter/Esc.</li> <li>To quit Impedance Measurement select the \"up arrow\" (on top row) and press Enter/Esc.</li> <li>To switch off the SIGGI-II, select Power Off from the Main Menu and press Enter/Esc</li> </ul> <ul> <li>When checking EEG Cap electrodes 1-32 (yellow connector), SIGGI-II displays numbers 1-32 as the channels under test.</li> <li>When checking EEG Cap electrodes 33-64 (green connector), SIGGI-II STILL displays numbers 1-32, NOT 33-64 e.g.<ul> <li>Electrode #33 =&gt; SIGGI-II channel #1</li> <li>Electrode #64 =&gt; SIGGI-II channel #32</li> </ul> </li> </ul>"},{"location":"meg/acquisition/rap/","title":"Restart Acquisition Programs (\"RAP\")","text":"<ol> <li>Stop/Close the Acquisition program (megacq).</li> <li>Open the Maintenance folder under the Neuromag folder in the Desktop\u2019s Applications menu to see the available actions.</li> <li>Select the Restart Acquisition Programs icon (\"RAP\").</li> <li>Confirm that you really want to proceed by answering \"Y\" to the question appearing in the Restart Acquisition Programs terminal window.</li> <li>Observe the messages in the window during the restarting. </li> <li>Should the restart operation fail, verify all physical power and data connections, as well as network connections, are working. Then ...</li> </ol> <p> 7. Close the terminal window, and try from point #2 again. If successful, then... 8. Wait until the message...<code>Restart complete. Press &lt;Enter&gt; to close the window</code> ...appears and press Enter on the keyboard. 9. If you had collected data and megacq ceased to work after you pressed Stop, you can rescue your data by double-clicking the Rescue Data icon in the Maintenance folder. 10. If there is some data to be saved, you will first see a dialog to confirm that you would really like to proceed. Thereafter, a standard megacq saving dialog will appear. The rescued data will be  saved under the project directory called unknown if the real project name could not be retrieved. 11. Restart megacq by selecting the Acquisition icon in the Neuromag folder."},{"location":"meg/acquisition/restart_acquisition/","title":"Restart Acquisition","text":"<p> Problem:   - SQUID controller (SQC), Signal Acquisition Module (SAM), System Controller (SCC)      dropped out during acquisition.   - SQC, SAM, SCC previously disconnected. Solution:   - SCC reset (Main Electronics Cabinet, SCC card, Reset button).   - Restart Acquisition Programs (Neuromag applications, Maintenance folder).   - Download the latest Tuning file with Tuner (<code>Acquisition &gt; Tools &gt; Tuner</code>). If nothing else helps   - Switch off/on the power in the Main Electronics Cabinet (by MEG Support!).   - Restart Acquisition Programs (Neuromag applications, Maintenance folder).   - Download the latest Tuning file with Tuner (<code>Acquisition &gt; Tools &gt; Tuner</code>). </p>"},{"location":"meg/acquisition/restart_acquisition/#resetting-the-electronics","title":"Resetting the electronics","text":"<p>The MEGIN TRIUX has four different Digital Signal Processing (DSP) electronics boards:</p> <ul> <li>SQUID controller (SQC) board, used for MEG channels, HPI and Internal Active Shielding.</li> <li>Signal acquisition module (SAM) board, used for bioamplifiers, EEG, and analog signal input.</li> <li>System controller (SCC) board, a master board for the main electronics.</li> <li>Front end controller (FEC) board, used for controlling the preamplifiers.</li> </ul> <p>Each main electronics board has a recessed Reset button on its front panel.  If the board becomes locked up (e.g. showing a red Fail LED, or it is reported by the acquisition sofware (megacq) as been dropped from acquisition) press the Reset button.  Boot-up of the boards starts automatically.  Wait until the board shows a steady green Run LED and the Fail LED is off.  Boot-up takes about 30\u201460 seconds.  If the bootup fails, open the back door of the main electronics cabinet and check the indicator LEDs of individual power supplies. </p> <p>Note</p> <p>If several boards fail simultaneously, all boards can be reset simultaneously by pressing the Reset button of the System Controller Card [SCC] which, in our installation, is located 5th slot from the right in the middle rack in the electronics cabinet. Most MEG sites detail this slot with a label/arrow.</p> <p>After resetting the boards, run Restart Acquisition Programs by double-clicking its icon in the Maintenance toolbox on the acquisition workstation. See the specific RAP page for the full procedure. </p> <p>The SCC and FEC boards also have status LEDs for the optical links of the stimulus trigger interface units and MEG and Bio/EEG preamplifiers. The Link LEDs should be lit green after resetting the boards.</p> <p>Note</p> <p>Each time the MEG front-end electronics are reset, or powered off/on, they must be initialized by invoking the Restart Acquisition Programs, a RAP, and the correct/up-to-date Tuning File must be reloaded.</p>"},{"location":"meg/acquisition/restart_acquisition/#restarting-the-software","title":"Restarting the software","text":"<p>When to restart</p> <p>The data acquisition may under some circumstances either stop prematurely or freeze with the following symptoms:</p> <ul> <li>Megacq becomes non-responsive for a long time. When windows covering megacq are moved, the exposed areas are not repainted.</li> <li>When megacq is started it fails to contact the data server.</li> </ul> <p>The most common reasons for this are networking problems. Recover the system by restarting the acquisition software modules.</p> <p>If the front-end DSP boards hang up, a complete power cycle is not normally required. It is enough to ...</p> <ul> <li>Stop/Close the Acquisition program (megacq).</li> <li>Reset the DPS boards (See the Resetting the electronics section above).</li> <li>Perform a RAP</li> <li>Restart the Acquisition program again.</li> </ul> <p>The DSP boards are reset by pressing the Reset button on the SCC board panel in the electronics cabinet and waiting until all DSP boards boot-up to green Run-status.  See the Resetting the electronics section above.</p> <p>Procedure to restart the software (perform a RAP)</p> <ol> <li>Stop/Close the Acquisition program (megacq).</li> <li>Open the Maintenance folder under the Neuromag folder in the Desktop\u2019s Applications menu to see the available actions.</li> <li>Select the Restart Acquisition Programs icon (\"RAP\").</li> <li>Confirm that you really want to proceed by answering \"Y\" to the question appearing in the Restart Acquisition Programs terminal window.</li> <li>Observe the messages in the window during the restarting. <ul> <li>Should the restart operation fail, verify all physical power and data connections, as well as network connections, are working. Then ...</li> <li>Close the terminal window, and try from point #2 again. If successful, then...</li> </ul> </li> <li>Wait until the message... <code>Restart complete. Press &lt;Enter&gt; to close the window</code> ...appears and press Enter on the keyboard.</li> <li>If you had collected data and megacq ceased to work after you pressed Stop, you can rescue your data by double-clicking the Rescue Data icon in the Maintenance folder.<ul> <li>If there is some data to be saved, you will first see a dialog to confirm that you would really like to proceed. Thereafter, a standard megacq saving dialog will appear. The rescued data will be  saved under the project directory called unknown if the real project name could not be retrieved.</li> </ul> </li> <li>Restart megacq by selecting the Acquisition icon in the Neuromag folder.</li> </ol>"},{"location":"meg/acquisition/restart_acquisition/#loading-a-tuning-file","title":"Loading a Tuning File","text":"<p>Procedure to load a tuning file, to check sensor noise levels, and to make sure the correct file is loaded after a Console reboot/MEG front-end reset or power off/on.</p> <ol> <li>Start the Acquisition program (megacq) on the DACQ Console.</li> <li>Select <code>Tools &gt; Tuner</code> from the menu bar at the top of the Acquisition window.</li> <li>Select <code>File &gt; Load tunings</code> from the menu bar. A dialog window will pop up... <code>OK to load state file /neuro/dacq/tunings/tnp/He_90.tnp</code></li> <li>If this is the file wanted, click OK. Otherwise, click Load other to pop up an ordinary file selection box and browse for the file required.  Click OK once the required file to be loaded has been found.</li> <li>Click on the Measure noise button, to start a noise check.</li> <li>Look at the generated \"Manhatten Skyline\", warm any sensors that are reaching atypical levels...<ul> <li>CTRL + left click on the noisy sensor \"building\"</li> <li><code>Commands &gt; Heat sensor</code>, trace should reduce in height/noise level reduce</li> <li>CTRL + left click to return to the \"all sensor\" view</li> <li>Once happy, click <code>Stop measurement</code>, followed by <code>Stop Collector</code></li> </ul> </li> <li>To exit Tuner, select <code>File &gt; Exit</code>. A dialog window will pop up, select \"Yes\"</li> </ol> <p>Note</p> <p>He_90.tnp is the default filename expected by megacq when the software is started. After a completed tuning session, ensure that the new tuning file is saved under this name. A backup copy can then be made by selecting <code>File &gt; Save Tunings &gt; Save elsewhere</code> and chosing a different filename e.g. date of tuning/gantry position.</p>"},{"location":"meg/acquisition/tidying_up/","title":"Tidying Up","text":"<p><p>Tidying Up e.g. before next Operator</p> <p>End of day \u201cto do\u201d procedures shown in ORANGE - if you're the last Operator of the day (according to Calpendo).</p> <p>SUMMARY</p> <ul> <li>UPSs in place, to remain powered/protecting equipment. REO Isolation Transformer removed.</li> <li>EyeLink Host PC to be shut down after use, the 6-way Mains extension bar plug then switched off (to power off Camera).</li> <li>EyeLink batteries charged/used as normal. Don't leave switched on/charging overnight. Make sure the AC Adapter in the Stimulus Cabinet is switched off.</li> <li>PROPixx projector to remain powered, to be \"awakened\" or \"slept\" as necessary. Lens cover can be left off.</li> <li>STIM PC to remain powered, leave switched to NEW Stim via KVM at End of Day (a screensaver is set to protect monitor).</li> <li>NAtA Response Box Controller to remain powered up.</li> <li>All other Tiding Up as per our usual procedures...<ul> <li>L2V Converters switched off after use.</li> <li>HPI coils cleaned.</li> <li>Polhemus cabling left tidy, L2V FO cabling/NAtA Response Box FO cabling/EyeLink cabling, left tidy in MSR.</li> <li>Log out of the DACQ Console, switch off the DACQ Console monitor once login screen appears.</li> <li>Fill out a Maintenance Log report for your session (one report for each session, if you have consecutive sessions).</li> <li>Move the gantry to 25, if you're the last Operator of the day/End of Day, or more than ~1hr between daily booked slots (check Calpendo).</li> </ul> </li> </ul> <p>Remember to check Calpendo to see if another Operator has booked the next session after yours;in that case, you may be able to leave some equipment powered up.</p> <p>FULL PROCEDURE </p> <ul> <li> Stop Acquisition and Save Data. Copy off data to RDS - Copying MEG data.</li> <li> End session on Participant Logging Computer (PLC), click on \u201cSCAN END\u201d, turn off monitor.</li> <li> Inform participant (via intercom) that the experiment has finished, that they are to remain seated, and you\u2019ll be in to unplug/disconnect them shortly.</li> <li> Carefully disconnect EEG cap connectors (if used), NATUS audio (if used), BIO Electrodes, and HPI coils from the gantry side.</li> <li> Ask participant to remove NATUS ear tips (if used). Dispose of used ear tips in the provided flip-top bin (spare bin liners are available on the bottom shelf of the EEG trolley).</li> <li> Ask participant to remove SOUNDPixx ear tips (if used). Disconnect black SOUNDPixx participant tubing from the main tubing (if used). Dispose of used ear tips in the bin.</li> <li> If required, help participant up from gantry chair (they may be a little unsteady), and have them resit in the Digitisation chair in Control Room.</li> <li> Carefully remove EEG Cap (if used), and reusable EOG/ECG electrodes (if used) from the participant, DO NOT pull on the cables!</li> <li> Remove disposable electrodes carefully, to avoid any unnecessary pain to the participant.</li> <li> Remove HPI coils carefully from the participant, DO NOT pull on the cables!</li> <li> Inform participant that they can wash their hair, if necessary, before or after changing out of scrubs (if used).<ul> <li>Towel and hair dryer in IKEA wardrobe. </li> <li>Show participant to the Shower Room. Remember to take your swipe card! </li> <li>Leave the used towel on the drying rack in the Changing Room for MEG Support to deal with.</li> </ul> </li> <li> Participant changes out of scrubs (if used) in the Changing Room, and back into their street clothes. The used scrubs to then be put into the kitchen laundry basket by the participant or the Operator on their exit from the Lab.</li> <li> Check all necessary documentation has been signed by the participant. Thank your participant for their cooperation and show them out, making sure they have all their belongings with them when they leave.<ul> <li>Make sure used scrubs are put into the kitchen laundry basket.</li> </ul> </li> </ul> <p>Return to the Control Room, and ...</p> <ul> <li> Remove, and throw away, disposable response box covers (if used). If not, wipe down NAtA response boxes - with Alcohol wipes (not gel!). Be careful! Don't wipe too hard!</li> <li> Throw away disposable electrodes/used Micropore tape.</li> <li> If used, Clean EEG cap.</li> <li> Clean reusable electrodes.<ul> <li>Carefully remove the double-sided sticky disc, and any Micropore tape, and dispose of in the bin.</li> <li>Use a cotton bud dipped in Isopropyl Alcohol to remove any sticky disc residue from the white surround.</li> <li>Wash the electrode in warm water in the Shower Room sink, using a cotton bud/soft toothbrush to remove the gel.</li> <li>Dry the electrode using a green paper towel, and hang the cable over the handle of the EEG trolley. </li> </ul> </li> <li> Remove as much Teagderm as possible from each HPI coil - be gentle - DON'T PULL on coil or cable!.</li> </ul> <p>Use a piece of Blenderm tape to pull/pick off (\"stipple\") the remaining stubborn small bits of Teagderm tape from the coloured heatshrink sections of each HPI coil.</p> <ul> <li> Wash HPI coils in warm, soapy water - DON'T GET grey end connector wet!</li> <li> Dry coils with a green paper towel.</li> <li> Soak coils in Isoproply Alcohol (IA) (marked tub) for a few minutes, then wipe with a paper towel and leave to dry on a green paper towel.<ul> <li>If the coils still feel \"sticky\", put some Alcohol gel in the palm of your hand and rub each coil carefully. </li> <li>Resoak again in IA if necessary.</li> </ul> </li> <li> Leave the HPI lead coiled up on a green paper towel to dry off on the EEG trolley.</li> <li> Replace the internal cover on any open pot of Isopropyl Alcohol, then screw on the lid gently but firmly. Leave pot upright on EEG trolley.<ul> <li>If end of day, return Isopropyl Alcohol pots to red Flammables cabinet located in Changing Room.</li> </ul> </li> <li> Throw away used cotton buds/used paper towel/Tegaderm backing paper. </li> <li> Dispose of used blunt needles in the yellow \u201cSHARPS\u201d box. Throw away used syringes, when necessary, in the bin.</li> <li> We have a Dyson vacuum cleaner - please use it on the Control Room carpet/Changing Room floor, as necessary.</li> </ul> <p></p> <ul> <li> Leave EEG trolley tidy \u2013 (see image right).<ul> <li>Alcohol pots returned to Flammables cabinet - if end of day).</li> </ul> </li> </ul> <p> </p> <ul> <li> Wipe inside gantry helmet, chair tray, chair arms - with Alcohol gel on green paper towel.</li> <li> Turn off L2V Converters (in Stimulus Cabinet) - move switch to \u2018OFF\u2019 position - make sure  RED  LED is NOT lit.</li> </ul> <p></p> <ul> <li> Turn off Polhemus, tidy up cables \u2013 (see image right).<ul> <li>Polhemus power switch can be found back right of control box. Front panel GREEN LED should go out.</li> </ul> </li> </ul> <p> </p> <ul> <li> If end of day, or Eyelink not required by next Operator, shutdown EyeLink PC, switch off EyeLink monitor, switch off extension 6-way bar plug.</li> <li> Turn off/Remove EyeLink Battery from MSR.</li> <li> Put battery on charge, unplug once charged, don\u2019t leave on charge overnight.<ul> <li>See Charging EyeLink batteries for further information.</li> <li>If necessary leave a note for MEG Support, to put the battery on charge first thing in the morning.</li> </ul> </li> </ul> <p>A piece of Micropore tape on the front of the battery indicates charging required.</p> <p></p> <ul> <li> If end of day, or EyeLink not required by next Operator<ul> <li>Remove EyeLink Camera head/Illuminator from small table and replace on MSR shelving. Replace the lens cap on the Camera head.</li> <li>Tidy up EyeLink Camera head/Illuminator battery (or AC Adapter) power cables, and Orange FO cable, neatly and loosely, and place back on MSR shelving.</li> </ul> </li> </ul> <p></p> <ul> <li> Remove L2V Converter suction mounts (if used) carefully from projector screen, coil their FO cables neatly, and replace on MSR shelving. <ul> <li>Clean any marks on the screen with a Lens Cleaning Wipe.</li> </ul> </li> </ul> <p>DO NOT coil the FO cables tightly!</p> <ul> <li> Leave everything tidy \u2013 as per MSR Shelving image shown above.</li> <li> If the EyeLink \"AC Adapter\" has been used ... </li> </ul> <p></p> <ul> <li>Shutdown the EyeLink PC, switch off the EyeLink monitor, switch off the extension 6-way bar plug.</li> <li>Turn off the FO Camera Head/IR Lamp power (via switch labelled \"EYELINK\", in the Stimulus cabinet - see image right), and then close the cabinet door.</li> <li>Unplug the AC Adapter cable, coil it up, and leave it on the MSR shelving.</li> </ul> <p></p> <ul> <li> <p> If end of day, move projector screen to the side wall of MSR. Move small table, and any used table risers to the side wall of MSR.</p> </li> <li> <p> If end of day, replace the black cloth cover on projector mirror, and \"sleep\" projector, as described below...</p> <ul> <li>Start the VPutil program, from the Stim Desktop shortcut, and type...</li> <li>(ANY DEVICE) &gt; <code>ppx s</code> - should respond with \"PROPixx is in sleep mode\"</li> </ul> </li> <li> Open MSR and check projector is \"sleeping\".</li> </ul> <p><code>ppx a / ppx s</code> didn't work on one occasion. PROPixx needed a full power off/on to reset.</p> <p>Projector lens cover to remain off, so the projector state can easily be determined.</p> <ul> <li> If end of day, or no one booked in for the session following yours, move the gantry to the Liquefaction position (\"25\"). Make sure the gantry traffic light is FLASHING GREEN.</li> <li> NAtA Control Box in Stimulus Cabinet can remain switched on.</li> <li> If end of day, Stim PC to left switched on (no need to logoff/shutdown), then ...<ul> <li>Make sure KVM is switched to \"NEW\" (button #3), so the monitor is displaying the NEW Stim Desktop (a screensaver is set to protect the monitor).</li> <li>(Monitor can still be powered off as normal if necessary).</li> </ul> </li> <li> Copy off data from DACQ console, if not already done so.</li> <li> If end of day, switch off the MSR Participant Monitoring Intercom (press the \"X\" button).</li> <li> If end of day, or no one booked in for the session following yours, logout of DACQ console (\u201cSinuhe\u201d). <ul> <li>Click/select \"Application Launcher\" button (bottom left of screen).</li> <li>Hover mouse over \"Leave\u201d button.</li> <li>Move to, and click/select, \"Logout\" button.</li> <li>Move to, and click/select, \"Logout\" buton in center of screen - or just wait (30sec).</li> </ul> </li> <li> Once login screen appears, turn off monitor - switch bottom right of monitor.</li> </ul> <p>Don\u2019t shutdown the Console! Only logout and then switch the monitor off.</p> <ul> <li> Fill out a Maintenance Log report for your session (one report for each session, if you have consecutive sessions).</li> <li> If end of day, open MSR door for one last sanity check that gantry traffic light is FLASHING GREEN.<ul> <li>If not, de-metal and adjust gantry up/down buttons as necessary.</li> </ul> </li> <li> If end of day, Switch off Control Room light.</li> <li> If end of day, Lock MEG lab, return key to key safe. Make sure key safe is locked!</li> <li> On leaving, sanitise your hands with the provided Anti-bac foam (dispenser on wall outside Control Room).</li> <li> Put all relevant documentation in the black Postbox outside Reception as you exit the MEG corridor.</li> </ul>"},{"location":"meg/acquisition/to_fix_noisy_channels/","title":"Fixing Noisy Channels","text":"<p>If, on starting Acquisition, you encounter a noisy channel, after installing your participant in the gantry chair and your empty room check was fine beforehand ... </p> <p> </p> <ul> <li>Hopefully you would have confirmed your participant was clean of any metal (correct use of both metal detectors).</li> <li>Ask your participant to open/close their mouth (dental artefacts).</li> <li>Ask your participant to blink their eyes once per second (eye makeup artefact).</li> <li>Ask your participant to take 2 deep breaths (clothing arefefact).</li> </ul> <p>First thing to try would be a channel reset.</p> <ul> <li>From the Acquisition Menu Bar, choose ...<ul> <li><code>Tools -&gt; Reset Channels</code></li> </ul> </li> </ul> <p>The noisy channel may return to normal after the reset artefact has passed through.</p> <p>If not, try heating the sensor.</p> <ul> <li>Stop any ongoing Acquisition by pressing the <code>Stop</code> button.</li> <li>From the Menu Bar, choose <code>Tools -&gt; Tuner</code>.</li> <li>Load the latest Tuning file <code>File -&gt; Load Tunings -&gt;</code> Select OK (to load the default tuning file He_90.tnp).</li> <li>Select <code>Measure Noise.</code></li> <li>In the <code>View Channel</code> window, replace the word <code>ALL</code> with the noisy channel in question e.g. <code>MEG0923</code>, press <code>Enter</code>.</li> <li>From the Menu Bar, choose <code>Commands -&gt; Heat sensor</code>. Wait for the buffer to be reprocessed... noise level should hopefully show a reduction.</li> <li>Select <code>Stop measurement</code>, then <code>Stop Collector</code>.</li> <li>From the Menu Bar, choose <code>File -&gt; Exit -&gt;</code> Yes to close the Tuner window.</li> <li>Start Acquisition, check if channel is still noisy.</li> </ul> <p>If the sensor is still noisy, perform a RAP.</p> <ul> <li>Once done, then ...</li> <li>Restart Acquisition.</li> <li>From the Menu Bar, choose <code>Tools -&gt; Tuner</code>.</li> <li>Load the latest Tuning file <code>File -&gt; Load Tunings -&gt;</code> Select OK (to load the default tuning file He_90.tnp).</li> <li>Select <code>Measure Noise</code> to see if the RAP has reduced the channel noise level.</li> <li>If not, try another RAP and then repeat from \"Restart Acquisition\" above.</li> </ul> <p>If the sensor is still noisy, do a soft reboot/reset of the electronics, as per Restart Acquisition #resetting the electronics</p> <ul> <li>Exit Acquisition back to the Console login screen. </li> <li>Open the Electronics Cabinet.</li> <li>Press the Reset button on the System Controller Card, SCC, as shown by the arrow.</li> <li>Confirm all cards/boards are reset (all are showing GREEN LEDs) - takes 30-60sec.</li> <li>Close the Electronics cabinet door.</li> <li>Perform a RAP, then make sure the deafult tuning file is reloaded...<ul> <li>Acquisition -&gt; Tuner -&gt; Load Tunings -&gt; Measure Noise.</li> </ul> </li> </ul> <p>If the sensor is still noisy, contact MEG Support to attend to power down then restart the electronics.</p> <p>Dr. Chris Bailey, former MEG Lab Manager at Aarhus University, Denmark, had this to say re: \"noisy\" participants ...back in 2018.</p> <p>First, I\u2019d try to figure out whether the artefacts are body motion-related. Ask the participant to keep completely still, and hold their breath while you count slowly to ten.  At \u2019two\u2019, hit \u201cReset channels\u201d. If the sensors return to something sane (non-saturated) after the reset-artefact has passed, there\u2019s likely something magnetic on or in the participant. The Reset is needed if the source is very strong: the SQUID\u2019s operating points will be screwed in a very strong static field. You can also try without the Reset, just ask them to hold (Very) still. We routinely use Hospital scrubs, at least the blouse. Hair wash is probably less likely to help, but getting all pins and clips out is important. A recent MRI will be a problem if there\u2019s magnetic material inside the subject.  Finally, women with bras need to be asked whether they have a metal support, many do. Most artefacts will clearly be breathing-correlated, so that usually helps locating external sources.</p>"},{"location":"meg/analysis/mne/","title":"MNE Python","text":"<p>MNE-Python is a Python package for analysing electrophysiology (MEG, EEG, sEEG, ECoG, NIRS, etc) data.</p>"},{"location":"meg/analysis/mne/#mne-python-versions","title":"MNE-Python Versions","text":"<p>BEAR Apps has several versions of MNE-Python as modules.</p>"},{"location":"meg/analysis/mne/#bear-modules","title":"BEAR Modules","text":"<p>The following <code>bash</code> loads <code>mne</code> version 1.3.1 and its dependencies - an equivalent is availiable for JupyterLab.</p> <pre><code>module load bear-apps/2022a\nmodule load MNE-Python/1.3.1-foss-2022a\n</code></pre> <p>Note</p> <p>Note that MNE-Python depends on a number of other python applications that will be loaded automatically. The above code will also load <code>numpy</code>, <code>scipy</code>, <code>numba</code>, <code>matplotlib</code>, <code>sklearn</code> and many other packages that are needed by MNE into your environment.</p> <pre><code>import mne\nimport numpy as np\n</code></pre>"},{"location":"meg/analysis/mne/#mne-in-a-virtual-environment","title":"MNE in a virtual environment","text":"<p>If you want to use a specific version of MNE-Python that isn't supported by BEAR, you can install it into a virtual environment. This <code>bash</code> script provides an example. We load Python 3.9.5, create an environment and install MNE into the environment using <code>pip</code>.</p> <pre><code>#!/bin/bash\n\nmodule purge;\nmodule load bear-apps/2022a\nmodule load MNE-Python/1.3.1-foss-2022a\nmodule load IPython/7.25.0-GCCcore-10.3.0\n\nexport VENV_DIR=\"${HOME}/virtual-environments\"\nexport VENV_PATH=\"${VENV_DIR}/mne-example-${BB_CPU}\"\n\n# Create master dir if necessary\nmkdir -p ${VENV_DIR}\necho ${VENV_PATH}\n\n# Check if virtual environment exists and create it if not\nif [[ ! -d ${VENV_PATH} ]]; then\n    python3 -m venv --system-site-packages ${VENV_PATH}\nfi\n\n# Activate virtual environment\nsource ${VENV_PATH}/bin/activate\n\n# Any additional installations\npip install mne==1.1.0\n</code></pre> <p>As with other examples, this can be copied directly into the terminal or saved as an shell script that can be executed in a terminal.</p>"},{"location":"meg/analysis/mne/#evoked-response-example","title":"Evoked response example","text":"<p>The following code is adapted from the MNE-Python overvew of MEG/EEG analysis tutorial. It will download a small example file and run a quick analysis.</p> <p>You can run this code directly in a Python session on BEAR within an activated MNE environment. The file will be saved into your RDS home directory (eg <code>/rds/homes/q/quinna</code>) unless specified otherwise - please change the <code>sample_data_folder</code> variable if you'd like to save this file elsewhere.</p> <pre><code>import numpy as np\nimport mne\n\n# This will download example data into your RDS home directory by default -\n# change the folder path passed to mne.datasets.sample.data_path() if you want to save the file elsewhere!\nsample_data_folder = mne.datasets.sample.data_path('/rds/homes/q/quinna/mne-data/')\nsample_data_raw_file = (sample_data_folder / 'MEG' / 'sample' /\n                        'sample_audvis_filt-0-40_raw.fif')\nraw = mne.io.read_raw_fif(sample_data_raw_file)\n\nevents = mne.find_events(raw, stim_channel='STI 014')\n\nevent_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,\n              'visual/right': 4, 'smiley': 5, 'buttonpress': 32}\n\nreject_criteria = dict(mag=4000e-15,     # 4000 fT\n                       grad=4000e-13,    # 4000 fT/cm\n                       eeg=150e-6,       # 150 \u00b5V\n                       eog=250e-6)       # 250 \u00b5V\n\nepochs = mne.Epochs(raw, events, event_id=event_dict, tmin=-0.2, tmax=0.5,\n                    reject=reject_criteria, preload=True)\n\nconds_we_care_about = ['auditory/left', 'auditory/right',\n                       'visual/left', 'visual/right']\nepochs.equalize_event_counts(conds_we_care_about)  # this operates in-place\naud_epochs = epochs['auditory']\nvis_epochs = epochs['visual']\n\nvis_evoked = vis_epochs.average()\n\nfig = vis_evoked.plot_joint()\nfig[0].savefig('my-mne-evoked-example-grad.png')\nfig[1].savefig('my-mne-evoked-example-mag.png')\nfig[2].savefig('my-mne-evoked-example-eeg.png')\n</code></pre> <p>We can save this as <code>mne_python_example.py</code> as our core analysis script. This can be executed from a terminal session in which the appropriate python environment has been loaded. For example, we could open a 'BlueBEAR GUI' session, open a new terminal, change directory to the location of our script and run the following code:</p> <pre><code>module load bear-apps/2022a\nmodule load MNE-Python/1.3.1-foss-2022a\n\npython mne_python_example.py\n</code></pre> <p>At the end you should have some new figures created next to your script.</p> <p> </p>"},{"location":"meg/analysis/mne/#mne-on-the-cluster","title":"MNE on the cluster","text":"<p>Warning</p> <p>There is currently a bug with this example to do with the automatic file downloading when running on the cluster. Running a similar example on your own data from RDS should work fine.</p> <p>Alternatively, we can run our evoked responses analysis on the cluster. For this we'll need a job submission script. Let's use the following shell code to load the MNE module from BEAR and run our code.</p> <pre><code>#!/bin/bash\n#SBATCH --account quinna-example-project\n#SBATCH --qos bbdefault\n\nmodule purge; module load bluebear\n\nmodule load bear-apps/2022a\nmodule load MNE-Python/1.3.1-foss-2022a\n\npython mne_python_example.py\n</code></pre> <p>Note</p> <p>We could equally create or load a virtual environment with a customised Python set-up in our job script. Here we use the built in BEAR module as it is all we need for the case in hand.</p> <p>We can save the job script as <code>run_mne_python_example.sh</code> and submit it to the cluster using <code>sbatch</code>:</p> <pre><code>sbatch run_mne_python_example.sh\n</code></pre> <p>You can see the progress of the job using the 'Active Jobs' page on BEAR portal or by reading the log files.</p>"},{"location":"meg/hardware/contraindications/","title":"MEG Contraindications","text":"<p>The signal measured by a MEG system is extremely low (10<sup>-15</sup>T) ), and is susceptible to many potentially artifact-inducing elements.</p> <p>None of the contraindications listed below will cause the MEG system to harm the participant or harm the device: a MEG is a fully passive device.</p> <p>The contraindications will only impact the signal quality.</p> <p>If your population of participants is limited or rare, you may have to run Acquisition sessions with subjects that might induce noise/reduce signal quality.</p> <p>Depending on the artifact, it may well be possible to correct the Acquired data/remove the noise in postprocessing through the use of MaxFilter/Spatiotemporal SSS (tSSS) and/or MATLAB/FieldTrip.</p> <p>Note</p> <p>MRI compatibility is not equivalent to MEG compatibility. An MRI-compatible object might still contain some amount of ferromagnetic material which does not discount it from allowing an MRI scan but will induce artifacts that will show in the MEG signal.</p> <p>Info</p> <p>The majority of the contraindications, if not all, will have been mentioned in both our MRI and MEG screening forms. Remember to go over both screening forms when recruiting participants, to make sure you're able to obtain T1 scans (if you require them for your study).</p>"},{"location":"meg/hardware/contraindications/#known-contraindications","title":"Known contraindications","text":"<p>(not listed in any specific order of signal degradation)</p> <ul> <li>Pacemaker, or any kind of cardiac stimulator</li> <li>Insulin pump, bladder neurostimulator, deep-brain neurostimulator, or any kind of implanted device</li> <li>Cardiac valves, both mechanical or animal</li> <li>Hearing aid, hearing implant</li> <li>Joint prosthesis (hip, knee, shoulder, etc)<sup>[1]</sup></li> <li>Neurosurgical clip for brain aneurysm</li> <li>Orthodontic implants, dental prosthesis, dental retainer/bridge work<sup>[2]</sup></li> <li>Sutures with metal wires or staples</li> <li>Non-removable piercings, earings, etc</li> <li>Tattoos<sup>[1]</sup></li> <li>Permanent makeup and eye makeup<sup>[3]</sup></li> <li>Coloured contact lenses, \"Quick Attach\" false eyelashes</li> <li>Recently-dyed hair, or any kind of hair extension</li> <li>Dreadlocks (gantry helmet is quite narrow)<sup>[5]</sup></li> <li>Foreign object in the eye</li> <li>Shrapnel or metal object in the body</li> <li>Vena cava filter, to prevent pulmonary embolism</li> <li>Metal workers or construction workers who work with metal (welders, etc)<sup>[6]</sup></li> </ul>"},{"location":"meg/hardware/contraindications/#additionally-its-better-if-the-participant","title":"Additionally, it's better if the participant:","text":"<ul> <li>Arrives with clean hair and/or beard<sup>[4]</sup></li> <li>Has not had an MRI scan, or been close to an MRI field, in the previous 72 hours<sup>[6]</sup></li> <li>Has not had any recent surgery<sup>[6]</sup></li> </ul> <p>[1] May depend on the material and localisation.  It's safer to avoid including participants with this contraindication, but if your participant population is limited, bring her/him into the lab for a brief screening test before booking the actual MEG slot.  If the lab is free for ~10min or so, demetal your participant (where possible) and position them in the gantry chair. Start Acquisition, and look at the sensor noise.  Based on your prior usage, make an informed decision as to whether it's worth your while Acquirng from this participant.  If you're not sure, consult a colleague or ask MEG support.  Remember MaxFilter and/or FieldTrip may be able to clean up your data afterward. Tattoos below the elbow do not usually cause artifacts.</p> <p>[2] Any kind of dental work should be avoided, but some of the more modern dental work/dental retainers may be compatible.  If your participant population is limited, bring her/him into the lab for a brief screening test before booking the actual MEG slot.  If the lab is free for ~10min or so, demetal your participant (where possible) and position them in the gantry chair. Start Acquisition, and look at the sensor noise.  Based on your prior usage, make an informed decision as to whether it's worth your while Acquirng from this participant.  If you're not sure, consult a colleague or ask MEG support.  Remember MaxFilter and/or FieldTrip may be able to clean up your data afterward.</p> <p>[3] Makeup remover is available in the lab, but your setup will be quicker if the participant arrives without any makeup.</p> <p>[4] A sink with a showerhead and hairdryer/towels are available in the lab, but your setup will be quicker if the participant arrives with clean hair/beard.</p> <p>[5] We have a plastic helmet mimicing the gantry helmet. If the participant can wear the helmet comfortably, they will fit comfortably in the gantry helmet.</p> <p>[6] If you're in any doubt, and your participant population is limited, bring her/him into the lab for a brief screening test before booking the actual MEG slot.  If the lab is free for ~10min or so, demetal your participant (where possible) and position them in the gantry chair.  Start Acquisition, and look at the sensor noise.  Based on your prior usage, make an informed decision as to whether it's worth your while Acquirng from this participant.  If you're not sure, consult a colleague or ask MEG support.  Remember MaxFilter and/or FieldTrip may be able to clean up your data afterward.</p>"},{"location":"meg/hardware/dimensions/","title":"MSR Dimensions","text":""},{"location":"meg/hardware/dimensions/#dimensions-of-our-vacoshield-advanced-room","title":"Dimensions of our Vacoshield ADVANCED room","text":"Length Width Height Inside Mumetall surface 4.00m 3.00m 2.49m Inside decoration surface 3.93m 2.93m 2.41m Outside Mumetall surface 4.35m 3.35m 2.85m Outside decoration surface 4.51m 3.51m 2.87m Pit for standard door 4.55m (min) 3.55m (min) 115mm (max) Pit for level entry door 4.55m (min) 3.55m (min) 235mm (max)"},{"location":"meg/hardware/ihr/","title":"The IHR (Internal Helium Recycling) System","text":"<p>The technology that helps record the minute magnetic fields is a Superconducting QUantum Interference Detector (SQUID) which is like a highly sensitive magnetic field meter.  To maintain superconductors one needs to provide an extremely cold environment, which is achieved by using liquid Helium around the sensors.</p> <p>At the CHBH we use an integrated closed-loop Helium reliquefaction system which collects the Helium gas that boils off during testing. The boiling Helium gas is directed via the Helium gas line to the Helium recycler cabinet for compression, and from there for storage in pressurized Helium gas storage tanks. Reliquefying the collected Helium is only possible when the MEG is not in use. This poses limitations to the MEG user time. The system needs regular downtime in the evenings/weekends. The measurement and reliquefaction periods must be in balance. Prolonged measurement or measurements in the evening therefore possibly shortens the next day\u2019s measurement window.</p>"},{"location":"meg/hardware/ihr/#maximizing-available-measurement-time-budget-mtb","title":"Maximizing available Measurement Time Budget (MTB)","text":"<ul> <li>Use the liquefaction position (\"25\") when not in use.</li> </ul> <p>The liquefaction capacity depends on the tilt angle of the Dewar. The capacity is highest when the probe unit is in the liquefaction position and lowest in the upper seated position. Therefore please use the liquefaction position when not in use. Liquefaction position is not needed for short periods (e.g. in between sessions during the day).</p> <ul> <li>Avoid unnecessary position changes.</li> </ul> <p>Position changes increase helium boil-off, and, therefore, fill the helium gas storage tanks faster.</p> <ul> <li>Do not leave the probe unit in the upper seated position.</li> </ul> <p>The boil-off is highest in the upper seated position. Do not keep the probe unit in the upper seated position longer than necessary.</p> <ul> <li>Do not measure in the liquefaction position.</li> </ul> <p>The TRIUX is not designed to Acquire data in the 25<sup>o</sup> position.</p> <ul> <li>Remember to move the gantry to the liquefaction position (25) at End of Day.</li> </ul> <p>The liquefaction rate is optimal at the 25<sup>o</sup> position. If the gantry is left in a sub-optimal position (60 or 68) liquefying will be poor, and tank pressure may not reduce very much. This will potentially lead to a reduced Measurement Time Budget for the following day or days.</p>"},{"location":"meg/hardware/ihr/#helium-is-not-life-supporting","title":"Helium is not life supporting!","text":"<p>If released into the air it poses a danger of suffocation. If a significant Helium leakage is detected our Oxygen Depletion Alarms will sound, then :</p> <ul> <li>Immediately, calmly, evacuate MEG Control Room &amp; MSR, and inform Sleep Control Room &amp; Labs of their need to evacuate also, and instruct other staff/students not to enter the corridor.</li> <li>Arrange proper ventilation.<ul> <li>Open Fire Exit.</li> <li>Open MEG Corridor door.</li> <li>Open Sleep Lab doors and subsequently the windows (if possible).</li> </ul> </li> </ul>"},{"location":"meg/hardware/meg-labjack/","title":"Using LabJack to send MEG triggers","text":"<p>The following code can be used to send triggers to the MEG using a LabJack. The current setup uses a LabJack U3-LV, although the code can easily be modified for other versions.</p> <p>Note</p> <p>There is a small delay sending triggers via a LabJack compared to directly from the PC (see https://support.labjack.com/docs/3-1-command-response-u3-datasheet). For many, this delay (~0.6-1 ms) is probably negligible, but if super accurate timing is important for your experiment you may need to look on LabJack's website for more information and/or run your own timing tests.</p> <p>LabJack main website: https://labjack.com/</p> <p>LabJack U3-LV documentation: https://support.labjack.com/docs/u3-datasheet</p> <p>Example code for controlling LabJack U3: https://support.labjack.com/docs/ud-example-code-u3-u6-ue9</p>"},{"location":"meg/hardware/meg-labjack/#matlab-code-to-initialise-labjack","title":"Matlab code to initialise LabJack","text":"<p>Matlab-specific examples on LabJack support website: https://support.labjack.com/docs/matlab-for-ud-windows</p> <p>The following code uses digital I/O to set ports to high or low (i.e., on or off) to send triggers to the MEG via a parallel port.</p> <p>To connect to LabJack:</p> <pre><code>function [ljudObj, ljhandle] = initialiseLabJack()\n\n% Make the UD .NET assembly visible in MATLAB.\nljasm = NET.addAssembly('LJUDDotNet');\nljudObj = LabJack.LabJackUD.LJUD;\n\n% Read and display the UD version.\ndisp(['UD Driver Version = ' num2str(ljudObj.GetDriverVersion())])\n\n% Open the first found LabJack U3.\n[ljerror, ljhandle] = ljudObj.OpenLabJackS('LJ_dtU3', 'LJ_ctUSB', '0', true, 0);\n\n% Start by using the pin_configuration_reset IOType so that all pin\n% assignments are in the factory default condition.\nljudObj.ePutS(ljhandle, 'LJ_ioPIN_CONFIGURATION_RESET', 0, 0, 0);\n\nend\n</code></pre> <p>To send a trigger to the MEG:</p> <pre><code>trigger_code = 255;\nljudObj.AddRequestS(ljhandle, 'LJ_ioPUT_DIGITAL_PORT', 0, trigger_code, 8, 0); % assign code to 0-7 ports\nljudObj.GoOne(ljhandle); % send the code\n</code></pre> <p>The 'LJ_ioPUT_DIGITAL_PORT' command will convert the trigger_code from decimal to binary (e.g., \"87\" becomes \"01010111\" in binary) and set the corresponding ports as low or high (0 or 1). The trigger is then sent via the parallel port when goOne() is called. To reset the ports back to low (i.e., all 0s), do the same as above but set <code>trigger_code = 0</code>.</p> <p>For ease of use, you can wrap the code above in a function that quickly sends a trigger and resets to zero:</p> <pre><code>function triggerSpike(ljudObj, ljhandle, trigger_code)\n\nljudObj.AddRequestS(ljhandle, 'LJ_ioPUT_DIGITAL_PORT', 0, trigger_code, 8, 0); %assign code to 0-7 ports\nljudObj.GoOne(ljhandle); %send the code\nWaitSecs(0.002); % Psychtoolbox function. Should be more accurate, but can use pause(0.002) if not using psychtoolbox\nljudObj.AddRequestS(ljhandle, 'LJ_ioPUT_DIGITAL_PORT', 0, 0, 8, 0); %reset to zero\nljudObj.GoOne(ljhandle);\n\nend\n</code></pre> <p>Then just call <code>triggerSpike(ljudObj, ljhandle, trigger_code)</code> in your scripts to send a trigger to the MEG (make sure to initialise the LabJack first, otherwise the <code>ljudObj</code> and <code>ljhandle</code> variables won't exist).</p>"},{"location":"meg/hardware/meg/","title":"Basic Workings of MEG","text":"<p>Magnetoencephalography (MEG) measures the magnetic fields generated by electric currents in the brain.  When neurons are activated synchronously they generate electric currents and thus magnetic fields, which are then recorded by MEG outside the head.  Unlike electrical currents (like in EEG), magnetic fields pass through the head without any distortion. Since this is a passive measurement, MEG is non-invasive.</p> <p>Recording the minute magnetic fields of the brain creates two challenges. One is to create a superconducting detector and the other is to attenuate external magnetic noise.</p> <p>The technology that helps record the minute magnetic fields is a superconducting quantum interference detector (SQUID) which is like a highly sensitive magnetic field meter.  To maintain superconductors one needs to provide an extremely cold environment, which is achieved by using liquid Helium around the sensors.  At the CHBH we use an integrated closed-loop helium reliquefaction system which collects the Helium gas that boils off during testing and liquefies this back when the MEG is not in use.  The system, therefore, needs regular downtime in the evenings/weekends.</p> <p>Our MEG laboratory houses an Elekta Neuromag TRIUX system, reinstalled in January 2019.</p>"},{"location":"meg/hardware/meg/#elekta-neuromag-triux","title":"Elekta Neuromag TRIUX","text":"<p>The TRIUX system has 306 sensors distributed over the head:</p> <ul> <li>204 planar gradiometers.</li> <li>102 magnetometers.</li> </ul> <p>The MEG system is situated in a two-layer Magnetically Shielded Room (MSR), installed by VAC. The system allows for concurrent EEG recordings from 64 electrodes and continuous monitoring of the head position. A closed-loop Helium recycler eliminates refills.</p>"},{"location":"meg/hardware/msr/","title":"How to open the MSR","text":""},{"location":"meg/hardware/msr/#to-open-the-msr","title":"To open the MSR","text":"<ul> <li>Press the GREEN Open/Close Door button. Door will open about 5cm.<ul> <li>If Outside, Pull the door open.</li> <li>If Inside, Push the door open.</li> </ul> </li> </ul>"},{"location":"meg/hardware/msr/#emergency-msr-door-opening-instructions","title":"Emergency MSR Door Opening Instructions","text":"<p>To unlock the door:</p> <ul> <li>Press the RED Emergency Door Release button. Door will open about 2cm.<ul> <li>If Outside, Pull the door open.</li> <li>If Inside, Push the door open.</li> </ul> </li> </ul> <p>If the door is still stuck:</p> <ul> <li>Place the hexagonal key in the Emergency Unlock slot and turn in direction of the arrow.</li> <li>Repeat for the second slot.<ul> <li>If Outside, Pull the door open.</li> <li>If Inside, Push the door open.</li> </ul> </li> </ul> <p>PDFs instructions for emergency opening the MSR door from both Outside and Inside can be found below...</p> <p>OUTSIDE emergency door opening instructions INSIDE emergency door opening instructions</p> <p>Principles of MSR Door Operation</p> <p>The MSR door is locked by pressurized air, provided by the compressor in the plant room next door.  On pressing the Emergency Door Release button, the air pressure is released, allowing free movement of the two latches holding the door shut.  The door will open approximately 2cm and can be pulled/pushed open the rest of the way.  It is heavy so a reasonable amount of effort will be required.  If for any reason the two latches are still locked after releasing the air pressure, the Emergency Unlock mechanism releases a spring that pulls the latches away from the lock hinges, allowing the door to open. To reset the latches Open the door wide enough to gain access to them.  Insert the hex key into both slots and turn in the opposite direction of the arrow.  Pull the latches out of their unlocked positions, against the spring, until they lock.  The spring is powerful, so pull hard!</p>"},{"location":"meg/hardware/safety/","title":"Shielded Room","text":"<p>The usual amplitude of magnetic fields created by the brain are extremely small, they do not exceed a few hundred femto tesla (10<sup>\u221215</sup> T).  Compared with this the Earth's magnetic field is between 10<sup>\u22124</sup> and 10<sup>\u22125</sup> T and an MRI is usually 1.5-3.0 T.</p> <p>Ross Devlin, Senior Service Specialist, MEGIN, says ... The background earth\u2019s magnetic field is about 0.5 Gauss or 50micro T = 50x10<sup>-3</sup> T. This is 11 orders of magnitude higher than expected brain signals (10<sup>-14</sup>) If the sensors were able to function in that level of field without being completely saturated, which is the most likely scenario, then the background noise would be so high as to make the data unusable.</p> <p>To attenuate the external magnetic noise the MEG is housed inside a Magnetically Shielded Room (MSR).  An MSR is an enclosure with a shell comprising layers of high permeability metals that are also good electrical conductors.  This attenuates (absorbs) the spurious magnetic and electrical fields emanating from outside sources.  All objects within the room are non-metallic/non-magnetic. It is imperative that neither the MEG operator, nor the participants bring any metal or magnetic objects into the MSR.  This is important for two reasons:</p> <ul> <li> <p>Firstly, the sensors (SQUIDs) are ultrasensitive in the sense that they can pick up changes in magnetic field in the range of femtoteslas.  Bringing magnetic objects close to the gantry helmet can cause flux traps in the SQUIDs. This may lead to a long and expensive service break and delay the measurements.</p> </li> <li> <p>Secondly, bringing metal/magnetic objects into the MSR will distort your measurements.</p> </li> </ul> <p>Therefore, before entering the MSR, please remove any potentially magnetic objects that you may be carrying.  These include belts, keys, watches, coins, hairpins, eyeglasses and pieces of clothing with metallic parts.  Also bringing cameras, flashlights, mobile phones or any other electrical equipment inside the MSR is strictly forbidden.  If you want to use any untested equipment or objects (e.g. chairs, cushions, etc.) this has to be tested first, in the presence of an experienced MEG operator only.  In the test, somebody waves the study object inside the closed MSR and somebody else watches the raw data display.  Start from the door and then proceed towards the MEG little by little.  If your colleague sees artifacts on the raw data display, then the object is magnetic and you should avoid bringing it inside the MSR.</p> <p>Please check whether your participant has removed all of the following items before entering the MSR:</p> <ul> <li>Phones</li> <li>Keys</li> <li>Bra\u2019s containing metal (e.g. underwired bra\u2019s) @</li> <li>Eye make-up containing metals (e.g. eye shadow/ mascara)</li> <li>Hair clips/pins</li> <li>Earrings and piercings</li> <li>Rings</li> <li>Bracelets/ necklaces containing metal</li> <li>Clothing with metal zips &amp; metal buttons<ul> <li>@ Hospital scrubs available if dresses/jeans need to be changed out of.</li> </ul> </li> <li>Any other metal objects in pockets, on clothing, or in hair</li> </ul> <p>Ask your participant if they have a dental retainer/brace, amalgam(mercury/metal alloy) fillings, or are wearing coloured contact lenses, or \"Quick Attach\" eyelashes.</p> <p>Further information can be found on our more-detailed MEG Contraindications page.</p>"},{"location":"meg/hardware/x_rite_i1_display_pro/","title":"VPixx X-Rite i1Display Pro Colorimeter","text":"<p>Specifications Data Sheet User Manual</p> <p>Note</p> <p>The calibration information is now included as part of the ... Application Guide for VPixx Products ... and the relevant section has been printed and is kept with the i1Display Pro device in its storage box in the MEG Side Room.</p> <p>Info</p> <p>\"The i1Display Pro colorimeter features an advanced, high-end optical system with custom-designed filters. It provides a near-perfect match to the color perception of the human visual system, delivering superior color measurement results.  i1Display Pro supports all modern display technologies, including LED backlight and wide gamut displays. It is spectrally calibrated, making it fully field upgradeable to support future display technologies. - VPixx Technologies</p> <p>The Colorimeter can be used as a Standalone device or through MATLAB.</p>"},{"location":"meg/hardware/x_rite_i1_display_pro/#standalone","title":"Standalone","text":"<p>(e.g. usage on own laptop to investigate stimuli generated via Stim PC).</p> <ul> <li>Install VPixx Software Tools from the provided USB stick (already done for CHBH-ST-MEG-W02).</li> <li>Plug in the Colorimeter to an availabe USB port, attach it to the back projection screen where required (wider Micropore tape is available).</li> <li>Start the VPutil application by clicking on its Desktop shortcut. The VPutil menu will appear.</li> <li>Type \u201c3\u201d to initiate the Calibration commands.</li> <li>Type \"i1d\", and follow the instructions to take a measurement.</li> <li>Type \"q\" to quit.</li> </ul>"},{"location":"meg/hardware/x_rite_i1_display_pro/#through-matlab","title":"Through MATLAB","text":"<p>(below instructions already done for CHBH-ST-MEG-W02).</p> <ul> <li>Copy I1.mexw64 (15/06/2021 94KB, from the USB memory stick) to C:\\toolbox\\Psychtoolbox\\PsychBasic\\MatlabWindowsFilesR2007a.</li> <li>Copy the new Datapixx.mexw64 (from C:\\Program Files\\VPixx Technologies\\Software Tools\\DatapixxToolbox_trunk\\mexdev\\build\\matlab\\win64) to the following usage locations depending on which version of MATLAB used ...<ul> <li>C:\\toolbox\\DataPixx - for MATLAB R2017A.</li> <li>C:\\toolbox\\Psychtoolbox\\PsychBasic\\MatlabWindowsFilesR2007a - for MATLAB R2019B.</li> </ul> </li> </ul> <p>Previous versions of Datapixx MEX files have been renamed to \"Old_Datapixx...\" etc</p> <p>Starting MATLAB and typing \"I1\", <code>Enter</code>, lists the I1's functions... not all are usable as we have the i1Display Pro, not the i1Pro.</p> <p>&gt;&gt; I1</p> <p><pre><code>Usage:\n\n% All I1 (Pro, Pro3, Display) functions:\nisConnected = I1('IsConnected');\nI1('Calibrate');\nLxy = I1('GetTriStimulus');\n\n% I1Pro / I1Pro3 functions:\nI1('TriggerMeasurement');\nkeyPressed = I1('KeyPressed');\nspectrum = I1('GetSpectrum');\n\n% I1 Display ONLY functions:\nI1('SetIntegrationTime', time);\ntime = I1('GetIntegrationTime');\nI1('SetMeasurementMode', 'mode');\nmode = I1('GetMeasurementMode');\nSERVER MODE VERSION: 3.9 [05/APR/2021]\n</code></pre> </p> <p>&gt;&gt; I1('IsConnected?');</p> <pre><code>Usage:\n\nisConnected = I1('IsConnected', [device]);\n\nReturns non-0 if an X-Rite I1 has been detected.\nThe argument 'device' can be used to choose a device should 2 different i1ProDev\nbe connected to the computer.\nIt should be noted that only 1 device can be used at the same time.\nDevice is one of the following value:\n    - i1Pro\n    - i1Pro3\n    - i1Display\n</code></pre> <p>Note</p> <p>&gt;&gt; isConnected = I1('IsConnected'); produces the result for \u2018isConnected\u2019 as \"1\" if the \"I1\" is connected, \"0\" otherwise.</p> <p></p> <p>&gt;&gt; I1('SetMeasurementMode?');</p> <p><pre><code>Usage:\n\nI1('SetMeasurementMode', \u2018mode\u2019);\n\nSets the calibration file and the measurement mode for the i1Display.\nThe measurement mode is one of the following value:\n    - CCFL: Used for LCD monitors with CCFL backlight.\n    - WLED : Used for LCD monitors with White LED backlight monitors.\n    - RGBLED : Used for LCD monitors with RGB LED backlight monitors.\n    - Phosphor : Used for CRT monitors.\n    - Projector : Used for Projectors.\n    - VPixx : Used for VIEWPixx, VIEWPixx /3D and PROPixx.\n    - EEG : Used for VIEWPixx /EEG monitors.\n</code></pre> </p> <p>&gt;&gt; I1('GetMeasurementMode?');</p> <pre><code>Usage:\n\nmode = I1('GetMeasurementMode');\n\nGets the measurement mode currently used by the i1Display.\nThe calibration mode is one of the following value:\n    - CCFL: Used for LCD monitors with CCFL backlight.\n    - WLED : Used for LCD monitors with White LED backlight monitors.\n    - RGBLED : Used for LCD monitors with RGB LED backlight monitors.\n    - Phosphor : Used for CRT monitors.\n    - Projector : Used for Projectors.\n    - VPixx : Used for VIEWPixx, VIEWPixx /3D and PROPixx.\n    - EEG : Used for VIEWPixx /EEG monitors.\n</code></pre> <p>So to change ...(default vaule is 'VPixx' as a PROPixx is used in the CHBH MEG Lab)</p> <p><pre><code>mode = I1('GetMeasurementMode');\nmode\nmode = \n\n    'VPixx'\nI1('SetMeasurementMode', 'RGBLED');\nmode = I1('GetMeasurementMode');\nmode\nmode =\n\n    'RGBLED'\n</code></pre> </p> <p>&gt;&gt; I1('GetTriStimulus?');</p> <pre><code>Usage:\n\nLxy = I1('GetTriStimulus'); \n\nReturns CIE Lxy coordinates of last i1 measurement.\n</code></pre> <p>Taking a sample measurement with \u2018RGBLED' as the 'mode' ...</p> <pre><code>Lxy = I1('GetTriStimulus');\nLxy\nLxy =\n\n     94.3362, 0.3781, 0.3791\n</code></pre> <p>VPIxx say a second or so exposure is needed to collect a sample, so allow for this time in the code.</p> <p></p> <p>&gt;&gt;  I1('SetIntegrationTime?');</p> <p><pre><code>Usage:\n\nI1('SetIntegrationTime', time);\n\nSets the integration time used to take a measurement by the i1Display.\nIt represents the maximum time which could be taken by the i1Display to get a measurement.\nThe value must be &gt; 0.2 seconds. Default is 0.2 seconds.\n</code></pre> </p> <p>&gt;&gt; I1('GetIntegrationTime?');</p> <pre><code>Usage:\n\ntime = I1('GetIntegrationTime');\n\nGets the integration time used for measurements by the i1Display.\nIt represents the maximum time which could be taken by the i1Display to get a measurement.\n</code></pre> <p>So</p> <pre><code>time = I1('GetIntegrationTime');\ntime\ntime =\n\n    0.2000\n</code></pre> <p>So to set the integration time to 1 second ...</p> <pre><code>I1('SetIntegrationTime', 1);\n</code></pre> <p>And to check it\u2019s changed \u2026</p> <pre><code>time = I1('GetIntegrationTime');\ntime\ntime =\n\n    1\n</code></pre>"},{"location":"meg/labsafety/documentation/","title":"Useful documents, COSHH etc","text":""},{"location":"meg/labsafety/documentation/#meg-operator-checklist-v4-0c","title":"MEG Operator Checklist v4-0c","text":""},{"location":"meg/labsafety/documentation/#meg-measurement-log-v1_2c","title":"MEG Measurement Log v1_2c","text":""},{"location":"meg/labsafety/documentation/#handling-compressed-gas-cylinders-regulators","title":"Handling Compressed Gas Cylinders &amp; Regulators","text":""},{"location":"meg/labsafety/documentation/#meg-msr-air-compressor-jun-air-12-25","title":"MEG MSR Air Compressor (Jun-Air 12-25)","text":""},{"location":"meg/labsafety/documentation/#isopropyl-alcohol-70","title":"Isopropyl Alcohol 70%","text":""},{"location":"meg/labsafety/documentation/#perfektan-tb-disinfectant","title":"Perfektan TB Disinfectant","text":""},{"location":"meg/labsafety/labsafety/","title":"Procedures to follow in an emergency","text":""},{"location":"meg/labsafety/labsafety/#helium-is-not-life-supporting","title":"Helium is not life supporting!","text":"<p>If released into the air it poses a danger of suffocation. If a significant Helium leakage is detected our Oxygen Depletion Alarm (ODA) will sound, then :</p> <ul> <li>Immediately, calmly, evacuate MEG Control Room &amp; MSR, and inform Sleep Control Room &amp; Labs of their need to evacuate also, and instruct other staff/students not to enter the corridor.</li> <li>Arrange proper ventilation.<ul> <li>Open Fire Exit.</li> <li>Open MEG Corridor door.</li> <li>Open Sleep Lab doors and subsequently the windows (if possible).</li> </ul> </li> <li>Beacon will flash/Alarm will sound - until Oxygen level is back above threshold.</li> </ul> <p>Our ODA is not connected to the building Fire Alarm system</p> <p>Swipe access will not be disabled/corridor door will remain locked. Use of the green \"no touch\" button will be required to exit the corridor towards Reception.</p> <p>If \"no touch\" button doesn\u2019t work to exit corridor, lift clear plastic flap, press green emergency button.Lock will lose power/switch off, and door will pull/push open.  Button Reset key in MEG Key Safe \u2013 to be used by Ops. Comm. staff and trained MEG Operators as necessary.</p> <p>The IHR tank room and MSR are protected by Oxygen Depletion sensors, with both a flashing Beacon and an 85dB Sounder.</p> <p></p> <ul> <li>Default/Normal reading: 20.8/20.9%VOL for both sensors.</li> <li>Below 19.5%VOL, Beacon flashes.</li> <li>Below 18.5%VOL, Beacon flashes, Sounder activates.</li> </ul>"},{"location":"meg/labsafety/labsafety/#first-aid-help","title":"First Aid help:","text":"<ul> <li>Notices for CHBH First Aiders can be found at each floor teapoint (by the central atrium staircase), the ground floor kitchen (G29), and in the MRI and MEG Suites.<ul> <li>If in doubt, contact Security (once phoned they can be on-site within a matter of minutes):<ul> <li>Security:<ul> <li>Emergency: 0121 414 4444</li> <li>Non-emergency: 0121 414 3000</li> </ul> </li> </ul> </li> </ul> </li> <li>First Aid Kits can be found at:<ul> <li>Each floor teapoint (by the central atrium staircase)</li> <li>Ground floor kitchen (G29)</li> <li>In the MRI and MEG Suites - NOT MRI SAFE.</li> </ul> </li> <li>Burns Aid Kit is at ground floor teapoint.</li> <li>Defibrillator (AED).<ul> <li>CHBH ground floor adjacent to the lift, in bright orange case.</li> <li>Edgbaston Park Hotel - behind the Reception Desk in the Lobby.</li> </ul> </li> <li>Emergency Box, on the CHBH ground floor adjacent to the lift.</li> </ul> <p>To call an ambulance, telephone \"999\" or \"112\" (mobile only) followed by Security on \"44444\" to let them know one is on the way.</p> <ul> <li>If unable to contact a First Aider, call Security on 44444.</li> </ul>"},{"location":"meg/labsafety/labsafety/#in-case-of-fire","title":"In case of Fire:","text":"<ul> <li>Operate the nearest Fire Alarm Call Point.</li> <li>All swipe access will be switched to failsafe mode, allowing corridor access.</li> <li>Fire Exits are at the end of MRI and MEG corridors.</li> <li>Link Corridor can be used as Fire Exit, as well as Main CHBH Entrance.</li> <li>Emergency Fire Escape Staircase leads to the MEG Fire Exit on Ground Floor. Access is via:-<ul> <li>1st Floor - opposite breakout room #135.</li> <li>2nd Floor - adjacent to cubicle #222 and 224 (Lab 12).</li> </ul> </li> <li>CHBH Fire Assembly Point - up the path/grass verge alongside the Hotel.</li> <li>Chrome Carbon Dioxide and Foam Fire Extinguishers can be found on each floor:<ul> <li>Ground Floor - adjacent to the lift, G09 (Lab 4), and end of MR/MEG corridors.</li> <li>1st Floor - adjacent to 109 (Hippocampus), 122 (Hot Desks), and 103 (Thalamus).</li> <li>2nd Floor - adjacent to 202 (Researchers Room), 207 (Amygdala), and 224 (Lab 12).</li> </ul> </li> </ul>"},{"location":"meg/labsafety/labsafety/#meep","title":"MEEP","text":"<p>The MEG Emergency Evacuation Plan can be found on the MEG Control Room wall, and the on door of the MSR. A PDF copy can be viewed from the link below ...</p> <p>MEEP</p>"},{"location":"meg/labsafety/labsafety/#chbh-geep","title":"CHBH GEEP","text":"<p>The CHBH General Emergency Evacuation Plan can be found on the MEG Control Room wall, and is also on the notice board adjacent to the MRI corridor. A PDF copy can be viewed from the link below ...</p> <p>GEEP</p>"},{"location":"meg/labsafety/metal_detectors/","title":"Metal Detectors","text":"<p>It is imperative that neither the MEG Operator, nor the Participant bring any metal or magnetic objects with them into the MSR.  This is important for two reasons:</p> <ul> <li> <p>Firstly, the sensors (SQUIDs) are ultrasensitive in the sense that they can pick up changes in magnetic field in the range of femtoteslas.  Bringing magnetic objects close to the gantry helmet can cause flux traps in the SQUIDs. This may lead to a long and expensive service break and delay the measurements.</p> </li> <li> <p>Secondly, bringing metal/magnetic objects into the MSR will distort collected measurements.</p> </li> </ul> <p>Therefore, before entering the MSR, it is very important to remove any potentially magnetic or metal objects.  To help in checking this, two versions of metal detector are available to screen any person wanting to enter the MSR. Please use as instructed in their respective User Manuals.</p> <p>Poor usage/incorrect detection of metal may allow ferrous objects into the MSR potentially distorting acquired data subsequently collected. DON'T RUSH THE SCREENING!</p>"},{"location":"meg/labsafety/metal_detectors/#garret-superwand","title":"Garret SuperWand","text":"<ul> <li>User Manual</li> <li>Specification</li> </ul>"},{"location":"meg/labsafety/metal_detectors/#wardray-mr103","title":"Wardray MR103","text":"<ul> <li>User Manual</li> <li>Specification</li> </ul>"},{"location":"meg/stimulus/propixx/","title":"VPixx","text":"<p>We use a VPixx PROPixx projector (1440Hz refresh rate).</p> <p>Our PROPixx Controller, now rebranded as a DATAPixx, was updated from 'Lite' to 'Full' in 2023, and is now able to output audio stimuli.</p>"},{"location":"meg/troubleshooting/shutdown_restart/","title":"MEG Power Shutdown / Restart","text":""},{"location":"meg/troubleshooting/shutdown_restart/#problem","title":"Problem","text":"<p>CHBH was informed by Estates of a whole building shutdown on Saturday 15th January 2022, for High Voltage maintenance. The shutdown was to last at least 6 hours.  A Measurement Window was set to start ~30min/60min before shutdown, to make sure liquefaction wasn't taking place.</p>"},{"location":"meg/troubleshooting/shutdown_restart/#solution","title":"Solution","text":"<p>After liasing with MEGIN, the shutdown/startup procedure was agreed as follows...</p> <p> To shutdown beforehand, say ~30min before the agreed time...</p> <ul> <li>Power down the Stim PC/s, Participant Logging Computer, EyeLink Host Computer (as necessary). Turn off the monitors. Power down the two UPS on the Control Room floor (make sure they don't restart!).<ul> <li>Press and hold the Power button for approximately 0.5 to 1 second. The unit should beep, indicating it is turning off. Front panel LED should go out.</li> <li>Switch off the Mains at the wall socket.</li> </ul> </li> <li>May be prudent to power off above equipment the day before, to reduce workload on the day.</li> <li>Set the Internal Helium Recycler (IHR) to Maintenance Mode using the Service GUI.</li> <li>Close valve BV4 on the pressure regulator panel in the Internal Helium Recycler cabinet.</li> <li>Open valve BV13 (Refill Bypass Valve - on the wall behind the MSR) to let any excess Helium exit outside via Helium exhaust pipe.</li> <li>Make sure that the Main Power Switch on the cryocooler compressor is set to OFF (the cryocooler shouldn't be running, but stop liquefaction first if it is).</li> <li>Turn off the Electronics cabinet components... in order (left to right).<ul> <li>1st - Preamps.</li> <li>2nd - SQC Cards.</li> <li>3rd - Mains.</li> </ul> </li> <li>Turn off the IHR cabinet (press the UPS Power button for a few seconds).<ul> <li>Turn off the IHR Mains power (large red switch on the wall to the right of the cabinet).</li> </ul> </li> <li>Turn off any Stimulus cabinet devices, power off the bar plug.</li> <li>Turn off the gantry lifting motor/traffic lights (Mains plug on the back wall, behind the MSR).</li> <li>Shutdown the DACQ console &amp; monitor.</li> <li>Switch off the Watchguard Firewall and Network Switch, in the Side Room Comms cabinet.</li> <li>Switch off the MSR lighting UPS...<ul> <li>Press the Power button on the front panel for 2 seconds, release at first beep.</li> <li>Switch off the Mains at the wall socket.</li> </ul> </li> <li>Switch off the MSR Jun-Air air compressor (in the IHR Tank room, found behind the tanks).</li> <li>Power down the two Eaton UPS located at the back of the IHR Tank room...<ul> <li>Press the Power button on the front panel for 3 seconds.</li> <li>The UPS should start to beep and show a status of \"UPS off pending...\". The UPS then transfers to Standby mode, and the Mains indicator turns off.</li> <li>Switch off the Mains for each UPS (Sockets on back wall, to the right of both UPS).</li> </ul> </li> </ul> <p>To startup, after confirmation that Mains power is fully restored...</p> <ul> <li>Switch on the Mains sockets for the two Eaton UPS.<ul> <li>Both UPS front panel displays illuminate and show a status of \"UPS initializing...\".</li> <li>...both should then transfer to Standby mode (\"UPS on standby\").</li> </ul> </li> <li>Press the Power buttons on both front panels for at least 1 second.<ul> <li>The UPS front panel displays change status to \"UPS starting...\".</li> <li>Confirm the Power On indicator are lit and showing solid green, indicating that both UPS are operating normally and any loads are powered (or will be once they are turned on).</li> <li>The UPS should now be in Normal mode.</li> <li>Press the ESC button until the start screen appears.</li> </ul> </li> <li>Switch on the MSR Jun-Air air compressor (in the IHR tank room, found behind the tanks).</li> <li>Switch on the MSR lighting UPS...<ul> <li>Switch on the Mains socket.</li> <li>Press the Power button on the front panel.</li> <li>The green \"On Line\" indicator flashes.</li> <li>The yellow \"On Battery\" indicator lights while the Self-test is being performed.</li> <li>When Self-Test has successfully completed, only the green \"On Line\" indicator will be lit.</li> <li>Check the MSR lights come on when the light switch is depressed.</li> </ul> </li> <li>Switch on the Watchguard Firewall and Network Switch, in the Side Room Comms cabinet.</li> <li>Turn on the gantry lifting motor/traffic lights (Mains plug on the back wall, behind the MSR).</li> <li>Turn on the Electronics cabinet components... in order (right to left).<ul> <li>1st - Mains.</li> </ul> </li> <li>Power up the DACQ console and monitor, wait until login splash screen appears on the monitor.<ul> <li>2nd - SQC Cards.</li> <li>3rd - preamps.</li> </ul> </li> <li>Run a RAP (Restart Acquisition Programs) on the DACQ.</li> <li>Turn on the IHR Mains power (large red switch on the wall to the right of the cabinet).</li> <li>Turn on the IHR cabinet (press the UPS Power button for a few seconds).</li> <li>Turn on the Main Power Switch on the cryocooler compressor.</li> <li>Turn on the bar plug in the Stimulus cabinet, power on any devices.</li> <li>Open valve BV4 on the pressure regulator panel in the Internal Helium Recycler cabinet.<ul> <li>Wait for 1 minute.</li> </ul> </li> <li>Close valve BV13 (Refill Bypass Valve - on the wall behind the MSR).</li> <li>Set the IHR to Normal Mode/Cooldown Mode (as necessary) using the Service GUI.<ul> <li>Check the correct LED combination is showing on the IHR cabinet door.</li> </ul> </li> <li>Turn on the two UPS on the Control Room floor; power on Stim PC, Participant Logging Computer, EyeLink Host Computer (as necessary).</li> <li>Phew, Well done! Have a well-deserved cup of coffee!</li> </ul>"},{"location":"mri/","title":"MRI at CHBH","text":"<p>Guides and documentation for MRI analysis and data collection at the CHBH.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> <ul> <li>The MRI</li> <li>Recording data</li> <li>Troubleshooting</li> </ul> </li> <li> <p>Data analysis</p> <p>Analysis and data quality procedures</p> <ul> <li>fMRIPrep</li> <li>Freesurfer</li> <li>FSL</li> <li>SPM</li> <li>spant</li> </ul> </li> <li> <p>Mock MRI</p> <p>Equipment and Procedures</p> <ul> <li>Mock MRI</li> </ul> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"mri/analysis/fmriprep/","title":"fMRIPrep","text":"<p>fMRIPrep is an open-source tool for preprocessing functional MRI (fMRI) data. It automates the early stages of MRI data preprocessing, including motion correction, susceptibility distortion correction, and slice-timing correction, providing a standardised and reproducible analysis pipeline. Unlike other preprocessing pipelines, fMRIPrep utilizes functions from many popular neuroimaging tools, including FSL, FreeSurfer, and AFNI, ensuring that each step in the pipeline uses the most reliable and validated methods available, resulting in higher-quality outputs.</p>"},{"location":"mri/analysis/fmriprep/#downloading-fmriprep","title":"Downloading fMRIPrep","text":"<p>The simplest way of running fMRIPrep is using a container. Instructions for downloading the fMRIPrep container are detailed here.</p>"},{"location":"mri/analysis/fmriprep/#running-fmriprep","title":"Running fMRIPrep","text":"<p>In order to run fMRIPrep, your data must first be organised according the Brain Imaging Data Structure BIDS guidelines. Once organised into BIDS, the default fMRIPrep container can be run using the following script:</p> <pre><code>#!/bin/bash\n\n#SBATCH --account example-project\n#SBATCH --qos bbdefault\n#SBATCH --time 1440\n#SBATCH --ntasks 4\n#SBATCH --mem 18G\n\nbids_directory=camcan_bids/\noutput_directory=camcan_fmriprep/\n\napptainer run fmriprep_24_1_1.sif ${bids_directory} ${output_directory} participant -w work/ --participant-label 01 --fs-license-file ~/license.txt \n</code></pre> <p>This script can then be submitted using the following command:</p> <pre><code>sbatch fmriprep.sh\n</code></pre> <p>Descriptions of the variables and arguments:</p> Variables / Arguments Description <code>bids_dir</code> First positional argument. Path to the BIDS-formatted dataset. <code>analysis_level</code> Second positional argument. Should be set to \"participant\" (required). <code>output_dir</code> Third positional argument. Sets the output directory. <code>-w</code> Specifies the working directory to store intermediate files during preprocessing. <code>--participant-label</code> Specifies the BIDS subject ID, enabling fMRIPrep to run on a single subject or a subset of subjects. <code>--fs-license-file</code> Path to the FreeSurfer license file (see FreeSurfer). By default, fMRIPrep uses FreeSurfer for anatomical co-registration. <code>--nprocs</code> Number of CPU cores to use for processing. <code>--mem</code> Amount of memory available in GB. <p>These arguments represent only a selection of the available options.</p>"},{"location":"mri/analysis/fmriprep/#running-fmriprep-across-all-subjects","title":"Running fMRIPrep Across all Subjects","text":"<p>It is also possible to run all subjects within a BIDS directory by using the following modified script:</p> <pre><code>#!/bin/bash\n\n#SBATCH --account example-project\n#SBATCH --qos bbdefault\n#SBATCH --time 1440\n#SBATCH --ntasks 4\n#SBATCH --mem 18G\n#SBATCH --array=0-20 # Number of subjects in the BIDS directory.\n\nSUBJECTS=($(find camcan_bids -maxdepth 1 -type d -name 'sub-*' | sort | xargs -n 1 basename))\nSUBJECT_ID=${SUBJECTS[$SLURM_ARRAY_TASK_ID]}\nbids_directory=camcan_bids/\noutput_directory=camcan_fmriprep/\n\napptainer run fmriprep_24_1_1.sif ${bids_directory} ${output_directory} participant -w work/ --participant-label ${SUBJECT_ID} --fs-license-file ~/license.txt \n</code></pre> <p>Note</p> <p>The number at the end fo the <code>#SBATCH --array=0-20</code> should be replaced with the number of subjects within the BIDS directory.</p>"},{"location":"mri/analysis/freesurfer/","title":"FreeSurfer","text":"<p>FreeSurfer is an open-source package for the analysis and visualization of structural, functional, and diffusion neuroimaging data from cross-sectional and longitudinal studies.</p>"},{"location":"mri/analysis/freesurfer/#freesurfer-license","title":"FreeSurfer License","text":"<p>FreeSurfer requires a license registration key in order to be used. This can be obtained from here. Once downloaded, the file should be uploaded to your home directory on Bear. This can be done using \"Files\" tab on the BlueBEAR portal, or using file transfer software, such as WinSCP, or FileZilla. </p>"},{"location":"mri/analysis/freesurfer/#running-recon-all","title":"Running recon-all","text":"<p>The <code>recon-all</code> command performs all, or any part of, the FreeSurfer cortical reconstruction process. The outputs of <code>recon-all</code> can be used to define the surfaces required for the boundary estimate model (BEM) required when performing source reconstruction on M/EEG data. The function can be run via BlueBEAR using the example script (recon_all.sh) below:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --qos bbdefault\n#SBATCH --time 1440\n#SBATCH --ntasks 4\n#SBATCH --mem-per-cpu 2\n\nmodule purge\nmodule load bear-apps/2019a/live\nmodule load FreeSurfer/6.0.1-centos6_x86_64\n\nexport FS_LICENSE=${HOME}/license.txt\nexport SUBJECTS_DIR=/rds/projects/b/bagshaap-eeg-fmri-hmm/fs_outputs\n\nrecon-all -s sub-01 -i /rds/projects/b/bagshaap-eeg-fmri-hmm/T1_vol_v1_5.nii.gz \\\n-all \\ \n-log logfile \\ \n-all \\\n-parallel -openmp 4\n</code></pre> <p>This script can then be submitted using the following command:</p> <pre><code>sbatch recon_all.sh\n</code></pre> <p>Descriptions of the variables and arguments:</p> Variables / Arguments Description <code>FS_LICENSE</code> Sets the path to the FreeSurfer license file. <code>SUBJECTS_DIR</code> Sets the output directory for the analysis. <code>-s</code> Sets the name of the output folder. <code>-i</code> Specifies the full path to the T1-weighted MRI image. <code>-all</code> Instructs FreeSurfer to run all processing steps. <code>-log</code> Creates a log file named \"logfile\" upon completion of the processing. <code>-parallel</code> Enables parallel processing in FreeSurfer. <code>-openmp</code> Defines the number of CPU cores available for parallel processing. <p>For the above script to work for you, several of the variables and arguments need to be changed to match your filenames and directories. Specifically, the <code>SUBJECT_DIR</code> variable needs to be changed to the path where you want the outputs to be saved, the <code>-s</code> argument needs to be changed to the desired name of the output folder, and the <code>-i</code> argument needs to be changed to a path to your T1 file. </p>"},{"location":"mri/analysis/freesurfer/#running-recon-all-on-multiple-subjects","title":"Running recon-all on Multiple Subjects","text":"<p>Alternatively, if you need to run recon-all for multiple subjects at once, for example, on an entire BIDS dataset, it is possible to submit all jobs using the below script (recon_all_bids.sh):</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --qos bbdefault\n#SBATCH --time 1440\n#SBATCH --ntasks 4\n#SBATCH --mem-per-cpu 2\n#SBATCH --array=1-20 # 20 represents the total number of subjects\n\nmodule purge\nmodule load bear-apps/2019a/live\nmodule load FreeSurfer/6.0.1-centos6_x86_64\n\nexport FS_LICENSE=${HOME}/license.txt\nexport SUBJECTS_DIR=/rds/projects/b/bagshaap-eeg-fmri-hmm/fs_outputs\n\nsubject_id_number=$(printf \"%02d\" ${SLURM_ARRAY_TASK_ID})\n\nrecon-all -s sub-${subject_id_number} \\\n-i /rds/projects/b/bagshaap-eeg-fmri-hmm/bids_dataset/sub-${}/anat/sub-${subject_id_number}_T1w.nii.gz  \\\n-all \\ \n-log logfile \\ \n-all \\\n-parallel -openmp 4\n</code></pre>"},{"location":"mri/analysis/freesurfer/#running-freesurfer-in-a-container","title":"Running FreeSurfer in a Container","text":"<p>Running FreeSurfer within a container allows for greater control over the software versions and improves the reproducibility of the analysis. FreeSurfer containers are available on Dockerhub, or can be created using NeuroDocker (see the Containers page for details on downloading containers). </p> <p>In the example below we assume a container named <code>freesurfer.sif</code> has been downloaded:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --qos bbdefault\n#SBATCH --time 1440\n#SBATCH --ntasks 4\n#SBATCH --mem-per-cpu 2\n\nFS_LICENSE=${HOME}/license.txt\nSUBJECTS_DIR=/rds/projects/b/bagshaap-eeg-fmri-hmm/Projects/Visual_Response_Variability/fs_outputs\n\napptainer exec --env FS_LICENSE=${FS_LICENSE} --env SUBJECTS_DIR=${SUBJECTS_DIR} \\\nfreesurfer.sif \\\nrecon-all -s sub-01 -i /rds/projects/b/bagshaap-eeg-fmri-hmm/T1_vol_v1_5.nii.gz \\\n-log logfile \\ \n-all \\\n-parallel -openmp 4\n</code></pre>"},{"location":"mri/analysis/fsl/","title":"FSL","text":"<p>FSL is a comprehensive library of analysis tools for FMRI, MRI and DTI brain imaging data.</p>"},{"location":"mri/analysis/fsl/#fsl-modules","title":"FSL Modules","text":"<p>A range of installed FSL versions are available as modules on Bear Apps.</p>"},{"location":"mri/analysis/fsl/#bear-portal-gui","title":"BEAR Portal GUI","text":"<p>The following code snippet can be executed in a terminal from within the Bear Portal GUI. It will load a pre-installed FSL version into the terminal where is can be used as normal.</p> <pre><code>module load bluebear\nmodule load FSL/6.0.5.1-foss-2021a\n</code></pre> <p>We can then use FSL command line functions as normal:</p> <pre><code>fsl_anat --help\n</code></pre> <p>or open the FSL GUI:</p> <pre><code>fsl\n</code></pre>"},{"location":"mri/analysis/fsl/#fsleyes-on-bear-portal-gui","title":"FSLEyes on BEAR Portal GUI","text":"<p>FSLEyes is the MRI volume visualisation tool provided and maintained by the FSL team. This runs well in BEAR GUI and can be added to the local environment by adding the following module. (See the FSLEyes page on BEAR Apps for all available versions). </p> <pre><code>module load FSLeyes/1.3.3-foss-2021a\n</code></pre> <p>Once the module has loaded you can run FSLEyes from the terminal as normal.</p> <pre><code>fsleyes\n</code></pre> <p>Info</p> <p>Note that it is currently not possible to have both FSL and FSLEyes in the environment in the same terminal. Until this is fixed, please use two separate terminal sessions, one for FSL and one for FSLEyes.</p>"},{"location":"mri/analysis/fsl/#fsl-on-the-cluster","title":"FSL on the cluster","text":"<p>We can also run FSL jobs on the cluster using job scripts. The following can be saved as <code>run_fsl_bet.sh</code> and submitted to the cluster using <code>sbatch</code>. This will run a brain extraction on a single datafile.</p> <pre><code>#!/bin/bash\n\n#SBATCH --account quinna-camcan\n#SBATCH --qos bbdefault\n#SBATCH --time 60\n#SBATCH --nodes 1 # ensure the job runs on a single node\n#SBATCH --ntasks 5 # this will give you circa 40G RAM and will ensure faster conversion to the .sif format\n\nmodule purge\nmodule load bluebear\nmodule load FSL/6.0.5.1-foss-2021a\n\nset -e\n\nbet subject1.nii.gz subject1_brain.nii.gz\n</code></pre> <p>If we have many datafiles to run BET on, we can extend our script into an array job. This is a <code>slurm</code> script that actually creates many jobs that can be run in parallel. Here we add the <code>#SBATCH --array=1-48</code> line to our script to tell it that we want to parallelise our script across the range 1 to 48. This creates 48 separate jobs each with a value between 1 and 48 stored in the variable <code>${SLURM_ARRAY_TASK_ID}</code>. Our <code>BET</code> call changes the subject number with this variable for each job.</p> <pre><code>#!/bin/bash\n#SBATCH --account quinna-camcan\n#SBATCH --qos bbdefault\n#SBATCH --time 60\n#SBATCH --nodes 1 # ensure the job runs on a single node\n#SBATCH --ntasks 5 # this will give you circa 40G RAM and will ensure faster conversion to the .sif format\n#SBATCH --array=1-48\n\nmodule purge\nmodule load bluebear\nmodule load FSL/6.0.5.1-foss-2021a\n\nset -e\n\nbet subject${SLURM_ARRAY_TASK_ID}.nii.gz subject${SLURM_ARRAY_TASK_ID}_brain.nii.gz\n</code></pre> <p>Submitting this script to the cluster will run BET 48 times on each input from <code>subject1.nii.gz</code> to <code>subject48.nii.gz</code>.</p>"},{"location":"mri/analysis/fsl/#fsl-in-a-container","title":"FSL in a container","text":"<p>Sometime we may want more control over software versions that are supported by pre-compiled BEAR App. We can install FSL within a controlled container using the following job script. This creates a container file <code>FSL.sif</code> from the NeuroDesk container specification.</p> <pre><code>#!/bin/bash\n\n#SBATCH --account quinna-example-project\n#SBATCH --qos bbdefault\n#SBATCH --time 60\n#SBATCH --nodes 1 # ensure the job runs on a single node\n#SBATCH --ntasks 10 # this will give you circa 40G RAM and will ensure faster conversion to the .sif format\n#SBATCH --constraint icelake\n\nset -e\n\napptainer pull --name FSL.sif docker://vnmd/fsl_6.0.4\n</code></pre> <p>We can submit this job to the cluster using <code>sbatch</code> as normal. Once the <code>FSL.sif</code> has been created we can run future cluster jobs through it.</p> <p>For example, this job script runs <code>fsl_anat</code> on a single dataset using our FSL container.</p> <pre><code>#!/bin/bash\n\n#SBATCH --account quinna-camcan\n#SBATCH --qos bbdefault\n#SBATCH --time 60\n#SBATCH --nodes 1 # ensure the job runs on a single node\n#SBATCH --ntasks 5 # this will give you circa 40G RAM and will ensure faster conversion to the .sif format\n\nmodule purge\nmodule load bluebear\n\nset -e\n\napptainer exec FSL.sif  fsl_anat -i subject1.nii.gz -o subject1\n</code></pre> <p>This can be combined with array jobs from the example above to run many container-based analyses together in parallel.</p>"},{"location":"mri/analysis/spant/","title":"Using spant on BEAR","text":""},{"location":"mri/analysis/spant/#interactive-use","title":"Interactive use","text":"<ul> <li>Navigate to : https://portal.bear.bham.ac.uk</li> <li>Navigate to the \"Interactive Apps\" tab and select \"RStudio Server\".</li> <li>Set \"Number of hours\" to the duration of the session.</li> <li>Set \"Number of cores\" to 4 to allocate 16 GB of memory.</li> <li>Press \"Launch\".</li> </ul>"},{"location":"mri/analysis/spant/#installing-spant-for-the-first-time","title":"Installing spant for the first time","text":"<p>Type the following in the Console (lower left panel) to install the latest stable version of spant:</p> <pre><code>install.packages(\"spant\", dependencies = TRUE)\n</code></pre> <p>Or the development version from GitHub (requires the devtools package):</p> <pre><code>install.packages(\"remotes\")\nremotes::install_github(\"martin3141/spant\", ref = \"devel\", dependencies = TRUE)\n</code></pre> <p>Note, installing for the first time will require compilation of various packages and will take some time.</p>"},{"location":"mri/analysis/spant/#batch-use","title":"Batch use","text":"<p>The use of Apptainer containers are recommended for batch analyses using spant to ensure consistency. A guide to building and using these containers on BlueBEAR may be found on github : https://github.com/martin3141/mrs_apps_containers</p>"},{"location":"mri/analysis/spm/","title":"SPM12","text":""},{"location":"mri/analysis/spm/#running-first-level-analyses-with-parfor","title":"Running first-level analyses with parfor","text":"<p>Info</p> <p>Example contributed by Arkady Konovalov</p> <p>Simple parallelisation of a for-loop can be performed using parfor. This functionality is provided by MATLAB and enables faster processing of <code>for</code> loops simply by changing the syntax at the start to say <code>parfor</code> rather than <code>for</code>.</p> <p>Here is an example function which makes use of <code>parfor</code> whilst computing GLMs using SPM.</p> <pre><code>function glm_level1(model)\n% This function takes a model structure as input and performs first-level\n% estimations in a General Linear Model (GLM) analysis for a set of subjects.\n\nsubjects = model.Subj;\n\n% FIRST LEVEL (individual) estimations\n% Get the number of subjects to be processed.\nN = size(subjects,2);\n\n% Iterate over each subject in \"subjects\" using parallel processing\nparfor i = 1:N\n\n        % Get the current subject ID from \"subjects\"\n        id = subjects(i);\n\n        % Get the corresponding BIDS (Brain Imaging Data Structure) ID and\n        % session information for the current subject.\n        BIDS_id = model.ids{id};\n        BIDS_sess = model.sess{id};\n\n        % Construct the path to the GLM folder for the current subject.\n        path = [model.glmfolder BIDS_id];\n\n        % Construct the path to the SPM.mat file for the current subject.\n        modelfile = [path '/SPM.mat'];\n\n        % Delete the existing SPM.mat file for the current subject (clean\n        % up previously done models)\n        delete(modelfile);\n\n        % Create a job structure for the current subject.\n        job = analysis_job_func(BIDS_id, BIDS_sess, model);\n\n        % Create an empty cell array to be used as inputs for the \"spm_jobman\" function.\n        inputs = cell(0,1);\n\n        % Set the SPM defaults to 'FMRI'.\n        spm('defaults', 'FMRI');\n\n        % Run the current job using the \"spm_jobman\" function.\n        spm_jobman('run', job, inputs{:});\n\nend\n\nend\n</code></pre> <p>Note</p> <p>Make sure you specify the appropriate number of cores when starting the MATLAB GUI App, you may not notice a substantial speed-up if you run MATLAB using the default of 4 cores. Do try to avoid asking for substantially more than you might need however - BlueBEAR is a shared resource!</p>"},{"location":"mri/hardware/scanner/","title":"MRI Specifications and Equipment","text":"<p>Magnetic Resonance Imaging (MRI) is a medical imaging technique that uses strong magnetic fields and radio waves to generate detailed images of organs and tissues inside the body. The CHBH houses a SIEMENS MAGNETOM PRISMA 3T installed in January 2019. </p> <p>The scanner can be used to assess brain activity and function through several techniques:</p> <ul> <li> <p>Structural MRI is used to produce high-resolution anatomical images</p> </li> <li> <p>Functional MRI (fMRI) measures brain activity by detecting changes in blood oxygen levels</p> </li> <li> <p>Diffusion Tensor Imaging (DTI) maps brain connectivity through white matter tracts</p> </li> <li> <p>Magnetic Resonance Spectroscopy (MRS) measures levels of molecules including metabolites and neurotransmitters</p> </li> </ul> <p>Info</p> <p>The CHBH houses 20-channel, 32-channel and 64-channel head coils.</p> <p>The CHBH also has equipment for combining MR with simultaneous behavioural and physiological assessment. </p> <ul> <li> <p>Eyetracking - SR Eyelink 1000 tracker</p> </li> <li> <p>Respiratory belt, electromyography and pulse monitoring - SIEMENS Healthineers</p> </li> <li> <p>Grip force transducer - BIOPAC MP160 with AcqKnowledge software</p> </li> <li> <p>Button box - fMRI Button Pad (2-Hand) System (NATA Technologies)</p> </li> </ul>"},{"location":"mri/hardware/stimulus_equipment/","title":"Stimulus Equipment","text":""},{"location":"mri/hardware/stimulus_equipment/#stimulus-pcs","title":"Stimulus PCs","text":"<p>The CHBH has a rack of Stimulus PCs in the Console Room. The individual PCs are addressed by a single keyboard mouse &amp; local screen via the KVM Switch (Keyboard/Video/Mouse Switch) mounted at the top of the rack.</p> <p>Choose which Stimulus PC you want to run your experiment on and select that via the KVM Switch. KVM1 for Windows 10, KVM 2 for NeuroDebian. you can freely switch between the two, though MATLAB may need to be relaunched if it was active during switching.</p> <p>What is seen on the local screen in the console room, is seen on the projector screen (when the wake command has been issued to the projector). Both local terminal screen and VPixx Projector are 1920x1080@120Hz for Ubuntu, and 1920x1080@100Hz for Windows 10 (not the 100Hz for Windows, 120Hz is not stable and will cause flickering). Note that only the central element of the Console Screen will be visible on the in bore projection screen. The Projector overfills the rear projection screen and the useful resolution is closer to ~4:3 ~1440x1080 visible. Always verify your paradigm's visual elements are not only visible on the projector screen and stimulus machine monitor, but remain so via the participant's superior mirror.</p> <p>The KVM is not configured to route Audio, therefore to choose a specific Stimulus PC, as audio source, employ the plugs on the Audio Patch Panel.</p> <p>Available Stimulus PCs are;</p> <ul> <li> <p>KVM 1 - Windows 10 - PsychoPy, MATLAB 2018B with the PTB, Presentation, EPrime and NIDAQ Hardware [[6]]</p> </li> <li> <p>KVM 2 - Ubuntu 18.04.1 LTS with Neurodebian - PsychoPy, MATLAB 2018B with the PTB [[7]]</p> </li> </ul> <p>These have near identical hardware, INTEL i7, AMD WX7100. The Windows 10 machine has an additional National Instruments DAQ and BNC breakout attached. If one machine fails, the other can boot to Windows 10 / Ubuntu with intervention of the Technician. Identical Common Experimental Platform PCs are also installed in other modalities, several cubicles and the Mock Scanner room. You are invited to test your paradigms there.</p> <p>There are also legacy Stimulus PCs at the foot of the rack.</p> <ul> <li> <p>KVM 3 - Windows 7 - this is a former BUIC STIM PC and should function as before, except a difference in screen resolution* {Currently disabled and soon to be retired}</p> </li> <li> <p>KVM 4 - Windows XP - QUALISYS, ROBOT, other legacy.</p> </li> </ul> <p>When any CHBH Stimulus PC is selected via the KVM it will receive reports from the Keyboard, Mouse at the local screen, and from the NATA Response Interface and the LABJACK U3. Other devices may be plugged directly into the fascia of the desired Stimulus PC.</p>"},{"location":"mri/hardware/stimulus_equipment/#vpixx-projector","title":"vPixx Projector","text":"<p>The commands needed to enable the projector are as follows;</p> <ul> <li> <p>launch the VPUtil command line interface (click the desktop icon in Windows / under Linux; click to open the desktop VPUtil folder, and in the folder pane that opens rightclick on the white space and Launch A Terminal From That Location, then type ./vputil and press enter).</p> </li> <li> <p>In that VPUtil interface type ppx a and return to awaken the projector.</p> </li> <li> <p>In that VPUtil interface type ppx s and return to deactivate.</p> </li> <li> <p>Do not leave the projector awakened.</p> </li> <li> <p>If you get the error 'VPixx Device FPGA device appears unprogrammed' this means the USB connection to the Projector has failed. Switch the KVM to 2 or and then back to 1, or vice versa, for 10 seconds to restore connection. You can switch between Windows 10 and the NeuroDebian CEP using the KVM, whilst the projector is live, and the projector will display the selected desktop.</p> </li> </ul> <p>These should be all you need for basic use of the VPixx. Instructions with detailed trouble shooting steps are found here. UPDATED SEPT 2021 - if the projector / console screen is flickering for more than a minute after booting you may need to reboot.</p> <p>The projector should be set at 16:9 1920x1080@120Hz. The Projector overfills the rear projection screen and the useful resolution is closer to 4:3 1440x1080 visible. Always verify your paradigm's visual elements are; not only visible on the projector screen and stimulus machine monitor, but also remain so via the participant superior mirror.</p>"},{"location":"mri/hardware/stimulus_equipment/#recovering-responsestriggers-via-nata-interface","title":"Recovering responses/triggers via NATA Interface","text":""},{"location":"mri/hardware/stimulus_equipment/#recovering-triggers","title":"Recovering Triggers","text":"<p>Scanner volume timing is delivered to the CEP Stimulus machines by the detection of the letter 't' (as if from a USB keyboard, spoofed by the NAtA interface box). This will echo into any command windows you use for running stimulus. Consider using the 'commandwindow' command at the beginning of MATLAB scripts to direct key presses away from the script editor! Alternatively switch off the NAtA interface box when troubleshooting, or open a notepad window to redirect these.</p> <p>When a Stim PC is selected via the KVM [[9]] and the 2x5 NATA Response Interface is on, [[10]], then scanner volume triggers will echo as 't' keypress (at ~7ms after the volume begins). Consider using the suggested trigger code snippet on github, linked below, to recover this timing. If you are recovering other keypresses (e.g. 0-9) make sure you ignore ensuing 't's. Beware also, that if CAPSLOCK is on any keyboard attached to the current Stim PC, the NAtA will report 'T'. So always check CAPS LOCK is off, or program defensively to respond to 't' or 'T'.</p> <p>KbCheck on Windows, and KbCheck(-3) on Linux should suffice to recover the 't' press. When you want to ignore successive 't' during recovery of Response Box keypresses use DisableKeysForKbCheck.</p> <p>Example code using the more complex KbQueue is provided here.</p> <p>The SIEMENS Prisma produces a 1us impulse which is delivered fibre-optically to the SIEMENS Interface Box behind the console PC. This has two settings, TOGGLE and IMPULSE, and requires USB power. Ensure IMPULSE is selected. The BNC output of this SIEMENS Interface Box is relayed to the NATA Response Interface, with potential breakout for other devices. </p> <p>The NAtA is connected directly to the KVM and reports a 't' via USB connection, which also reports 1,2,3,4,5 &amp; ,6,7,8,9.0 for NATA response peripheral. The NATA Interface Box also passes the signal via a DB25 breakout, and &lt;1ms delay. This is DB25 breakout is normally connected to the legacy Windows 7 BUIC Stimulus PC. This enables legacy BUIC experiments to be run without alteration on the legacy Stimulus PC (besides screen size considerations). The DB25 breakout may also be connected to the LABJACK U3, the National Instruments DAQ or the BlackBoxToolKit.</p>"},{"location":"mri/hardware/stimulus_equipment/#recovering-participant-responses-in-linux","title":"Recovering Participant Responses in Linux","text":"<p>The NAtA Response Pads are installed in the scanner chamber in two configurations. 2x2 which report 12 34 and 2x5 which report 12345 67890 as if they were cut down USB keyboards. (NB Responding as US keyboards in PTB, not UK configuration.)</p> <p>The 2x2 Interface and 2x5 are always on and connected. Both are connected via the KVM. if you switch between Windows and Linux whilst MATLAB is open, you may need to re-open MATLAB for to detect the NAtA.</p> <p>Under Neurodebian use the following device names when setting up your KbQueue in PTB MATLAB;</p> <pre><code>DeviceName = 'NAtA Technologies LxPAD PK080219 v6.11'  % 2x5 and trigger 't'\n\nDeviceName = 'NAtA Technologies LxNK Keypad' % 2x2 only\n\nDeviceName = 'Dell Dell QuietKey Keyboard'  % Experimenter Keyboard\n</code></pre> <p>Here is example code that demonstrates gathering Experimenter Keyboard Responses and Participant 2x5 / Scanner volume triggers from the NAtA 2x5.</p> <p>Always ensure the NAtA boxes respond before placing your participant in the scanner. They will illuminate the red LEDs on the front of the NATA Interface Box, so observe these. If they illuminate and there is no response from the stimulus PC then reset the PC as the USB hub has been sent to sleep and not awoke with the PC.</p>"},{"location":"mri/hardware/stimulus_equipment/#participant-audio-siemens-soundpixx","title":"Participant audio - Siemens / SoundPIXX","text":"<p>For Operator/Participant contact we rely on the inbuilt Siemens audio console. This broadcasts into the Room, and optionally via the mono pneumatic in-ear headphones that can be attached to the base of the participant bed.</p> <p>For experimental audio, routed from the CEP stimulus machines the Siemens Room Audio / In-Ear Headphones may be suitable. However if you require Stereo reproductions or and higher fidelity audio reproduction there is the SoundPIXX system. This requires the use of a second set of headphones, stored to the left hand side of the head of the scanner bed.</p> <p>As noted above, the KVM is not configured to route Audio, therefore to choose a specific Stimulus PC, as audio source, employ the plugs on the Audio Patch Panel.To switch between the two audio systems there is a patch panel (bank of ports for large audio cables) below the CEP Stimulus machines on the main rack. These allow audio to be routed from the CEP Stimulus Machines to the two available audio outputs. Sources are the Windows and the Neurodebian CEP Stim, outputs are the Siemens (Room + Participant Headphones), or the SoundPIXX (Participant Headphones only).</p> <p>When utilising the SoundPIXX Audio the Siemens Room audio may suffice for participant communication still, but there is a secondary black desktop Microphone that you can use to speak directly into the SoundPIXX headphones.</p> <p>Warning</p> <p>The SoundPIXX headphones have a much higher range of available volume than the Siemens in-Ear headphones and participants may be overwhelmed. Before any experiment involving their use check the settings are suitable, and that they have not been changed since your last scan. Additionally check the volume setting on our CEP Stimulus machine has not changed as the interaction of these two can produce surprisingly high volumes of noise which will be delivered directly into the SoundPIXX in ear headphones.</p>"},{"location":"mri/hardware/stimulus_equipment/#troubleshooting","title":"Troubleshooting","text":"<p>When the Siemens Room audio is all that is required the patch panel should be left in the standard position to avoid a ground loops developing - which delivers a rumbling bassy noise. Should you experience this noise switch the Audio patch from 23-24 or vice versa.</p>"},{"location":"mri/hardware/troubleshooting/","title":"Troubleshooting","text":""},{"location":"mri/hardware/troubleshooting/#vpixx-device-fpga-device-appears-unprogrammed","title":"VPixx Device FPGA device appears unprogrammed","text":"<p>Problem</p> <p>If you get the error 'VPixx Device FPGA device appears unprogrammed' this means the USB connection to the Projector has failed.</p> <p>Solution</p> <p>Switch the KVM to 2 or and then back to 1, or vice versa, for 10 seconds to restore the connection. You can switch between Windows 10 and the NeuroDebian CEP using the KVM, whilst the projector is live, and the projector will display the selected desktop.</p> <p>Instructions with detailed trouble shooting steps are found HERE. UPDATED SEPT 2021 - if the projector / console screen is flickering for more than a minute after booting you may need to reboot.</p>"},{"location":"mri/hardware/troubleshooting/#siemens-room-audio","title":"Siemens Room audio","text":"<p>Problem</p> <p>When the Siemens Room audio is all that is required the patch panel should be left in the standard position to avoid a ground loops developing - which delivers a rumbling bassy noise.</p> <p>Solution</p> <p>Should you experience this noise switch the Audio patch from 23-24 or vice versa.</p>"},{"location":"mri/hardware/troubleshooting/#amplifier-out-of-synch-barker-words-missing","title":"Amplifier Out of synch, Barker words missing!","text":"<p>Problem</p> <p>This error was encountered when using the Brain Products MR EEG caps and amplifiers in the PTL (G08). The user was having issues keeping the impedance low as well as the software cutting out with the error \"Amplifier out of sync, Barker words missing!\"</p> <p>Possible Solution</p> <p>The so-called 'Barker words' are part of a watchdog mechanism that assures the integrity of the communication between the amp and PC interface. The error message likely originates from the BrainAmp driver. The error message suggests that the optical path is impaired. Check the following ...</p> <p>Correct connection between fiber optic and amp/USB-adapter. Clean optical plugs/slots. If cleaning doesn't help, use another fiber optic cable for testing Clean ribbon cables, plugs, and sockets. Make sure the cut ends of the ribbon cable are cleaned of any dried gel. Update your BrainVision Recorder .</p> <p>NOTE: For a combined EEG-fMRI measurement only: If the \"Barker words missing!\" error coincides with the start of an fMRI sequence, it can also be a sign of an RF overload. An amp experiencing RF overload can produce arbitrary error messages in Recorder.</p>"},{"location":"mri/hardware/troubleshooting/#the-participant-logging-computer-plc-isnt-working","title":"The Participant Logging Computer (PLC) isn't working","text":"<p>If the Participant Logging Computer (PLC) is faulty, or if there is some other Service/Network issue, but our intranet is working, you should be able to use the logging software via a browser.</p> <p>Links are shown below. The second log screen should automatically show after participant details are entered into the first screen, but the second link is provided below if needed.</p> <p>NOTE: The links will only work on the MRI Stim PCs.</p> <p>https://www.chbh.bham.ac.uk/log/log-screen1.html</p> <p>https://www.chbh.bham.ac.uk/log/log-screen2.html</p>"},{"location":"mri/hardware/troubleshooting/#in-bore-projector-screen-out-of-focus","title":"In bore projector screen out of focus","text":"<p>Problem</p> <p>On occasion, the in bore projector screen is out of focus.</p> <p>Solution</p> <p>Most commonly the projector screen has been moved in the bore and not replaced in the correct locale. You can remedy this by ensuring the red stabilisers (pictured below) are aligned with the black circles inscribed in the scanner bore. General users and operators are free to move the screen to recover focus themselves. Deploy caution as the screen has a deformable membrane, and costs \u00a3ks to replace. Move it only via the solid base.</p> <p>Much more rarely the Projector in the Equipment room has been moved. Resetting the focus in that room should be the province of the CHBH technical staff.</p>"},{"location":"sleep/","title":"Sleep Research at CHBH","text":"<p>Guides and documentation for sleep data collection at the CHBH.</p> <ul> <li> <p>Technical Information</p> <p>Essential hardware and infrastructure details</p> </li> <li> <p>Data Acquisition</p> <p>Equipment and setup for data collection</p> </li> <li> <p>Stimulus Delivery</p> <p>Software and methods for stimulus presentation</p> </li> <li> <p>Quality Control</p> <p>Analysis and data quality procedures</p> </li> </ul> <p>CHBH Sharepoint Pages</p> <p>These pages contain user lead and public facing information at CHBH. For full details on CHBH facilities, processes, project codes, approvals, ethics, finances, bookings and administration please see the CHBH Sharepoint pages (UoB SSO login required).</p>"},{"location":"software/","title":"Overview","text":"<p>This section collects tutorials and examples to run software on BlueBEAR. This is intended to extend the main BEAR Technical Documentation pages.</p> <p>Click on the links below to see the examples.</p> <ul> <li>Conda</li> <li>Containers</li> <li>MATLAB</li> <li>Python</li> <li>R</li> </ul>"},{"location":"software/R/","title":"R for statistical computing","text":"<p>The R project is a free software environment for statistical computing and graphics.</p>"},{"location":"software/R/#r-versions","title":"R Versions","text":"<p>BEAR Apps has several versions of <code>R</code> as loadable modules.</p>"},{"location":"software/R/#r-studio-gui-app","title":"R-Studio GUI App","text":"<p>RStudio is an integrated development environment (IDE) for <code>R</code>. It includes a console, syntax-highlighting editor that supports direct code execution, and tools for plotting, history, debugging, and workspace management.</p> <p>You can open an interactive RStudio session through the BEAR Portal. The pre-installed <code>R</code> versions can be loaded.</p>"},{"location":"software/R/#neuroimaging-specific-r-packages","title":"Neuroimaging specific R packages","text":"<p>Here is a list of <code>R</code> packages commonly used for neuroimaging analysis.</p>"},{"location":"software/R/#fslr","title":"FSLR","text":"<p>Wrapper functions that interface with 'FSL', a powerful and commonly-used 'neuroimaging' software, using system commands.</p>"},{"location":"software/R/#r-example-for-bear","title":"R Example for BEAR","text":"<pre><code>knitr::opts_chunk$set(echo = TRUE)\nlibrary(ggplot2)\n\n# Simulate some data\ntime     &lt;- 0:99\nset.seed(1)\nnoise    &lt;- rnorm(100)\ndisorder &lt;- time * 4 + 100 + noise * 20\ndis_df   &lt;- data.frame(time, disorder)\n\n# Create a plot\nggplot(dis_df, aes(x = time, y = disorder)) + geom_point() +\n  geom_smooth(method = \"lm\")\n\n# Fit model\nlm_fit &lt;- lm(disorder ~ time, dis_df)\nsummary(lm_fit)\n</code></pre>"},{"location":"software/conda/","title":"Using Conda to manage Python environments","text":"<p>Managing software dependencies can be one of the most annoying things in scientific computing, especially when dealing with complex systems with multiple packages and libraries.</p> <p>This is where <code>conda</code> comes in - a package management system that simplifies the task of installing, configuring, and managing software packages and their dependencies.</p> <p>BEAR systems offer a default Python environment, but it must be loaded beforehand, and it does not allow you to install additional packages that are not already provided. After creating your own Conda environment, you don't have to load them every time. Submitting cluster jobs becomes straightforward with simple scripts, as demonstrated in this example:</p> <pre><code>#!/bin/bash\nset -e\n#SBATCH settings\npython your_script.py\n</code></pre> <p>Note</p> <p>BEAR do not currently recommend using conda for installing Python packages. This is due to possible performance issues when installing packages with conda. BEAR recommend that you get in touch with them prior via an IT-ticket to performing intensive analyses using <code>conda</code> environments.</p> <p>If this seems interesting to you, or you need to use a custom environment, let's get started!</p>"},{"location":"software/conda/#what-is-conda","title":"What is <code>conda</code>","text":"<p>Conda is a platform-agnostic package management system that can be used to install and manage software packages and their dependencies. It is designed to work with multiple programming languages, including Python, R, and others.</p> <p>Advantages of using <code>conda</code>:</p> <ul> <li>Build your own Python env when you don't have <code>sudo</code> access</li> <li>Conda simplifies managing software packages and dependencies</li> <li>Conda allows for isolated environments for different projects or applications</li> <li>Conda facilitates switching between different package versions</li> <li>Conda provides access to a vast range of pre-built packages and libraries.</li> </ul>"},{"location":"software/conda/#how-to-install-conda","title":"How to install <code>conda</code>","text":"<p>First, go to your home directory and type:</p> <pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n# start installation\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre> <p>Follow the instructions on the screen to complete the installation (You can just leave everything as default, it should be fine most of the time). After the installation is complete, you need to restart your kernel to load it, type:</p> <pre><code>exec bash\n</code></pre> <p>And you should see your terminal changed, for example from <code>[&lt;usr&gt;@bb-pg-login04 ~]$</code> to <code>(base) [&lt;usr&gt;@bb-pg-login04 ~]$</code>. This means you have a Python environment called <code>base</code> that is now active. Now you can start using conda to manage your own Python environments!</p>"},{"location":"software/conda/#use-base-environment","title":"Use <code>base</code> environment","text":"<p>If you accepted the default setting when installing, the <code>base</code> environment is the default environment, Every time you logged in to BEAR this environment will be loaded automatically.</p> <p>You can install any packages you need in the <code>base</code> environment with <code>pip</code> or <code>conda</code> command.</p> <p>For example, to install <code>matplotlib</code> and <code>scipy</code>:</p> <pre><code>conda install -c conda-forge matplotlib=3.5.2 scipy\n# or\npip install matplotlib==3.5.2 scipy\n</code></pre> <p>If you have the <code>requirements.txt</code> from the projects you are working with:</p> <pre><code>pip install -r requirements.txt\n# or \nconda install --file requirements.txt\n</code></pre> <p>After installing the packages, you can check the list of packages installed in the <code>base</code> environment with:</p> <pre><code>conda list\n# or \npip list\n</code></pre> <p>Congratulations! Now you can start using your own environment to do anything you like! Simply type:</p> <pre><code>(base) [&lt;usr&gt;@bb-pg-login04 ~]$ python your_script.py\n# or \n(base) [&lt;usr&gt;@bb-pg-login04 ~]$ python # to start a python shell\n# or \n(base) [&lt;usr&gt;@bb-pg-login04 ~]$ ipython # to start a ipython shell\n</code></pre>"},{"location":"software/conda/#create-virtual-environments-with-conda","title":"Create virtual environments with <code>conda</code>","text":"<p>In most cases, the <code>base</code> environment should be enough. But if you are working on multiple projects, especially when you have deep learning projects or developing a toolbox that might be sensitive to specific environmental conditions, it is important to take measures to ensure consistency and prevent any problems that could arise from changes in the environment.</p> <p>Type the following command to create and enter a new environment:</p> <pre><code>(base) [&lt;usr&gt;@bb-pg-login04 ~]$ conda create -n &lt;name&gt; python=3.10 ipykernel\n(base) [&lt;usr&gt;@bb-pg-login04 ~]$ conda activate &lt;name&gt;\n# Now you will see your terminal became:\n(&lt;name&gt;) [&lt;usr&gt;@bb-pg-login04 ~]$\n# install the packages using the commands provided above\n(&lt;name&gt;) [&lt;usr&gt;@bb-pg-login04 ~]$ pip install -r requirements.txt\n# run your Python scripts\n(&lt;name&gt;) [&lt;usr&gt;@bb-pg-login04 ~]$ python your_script.py\n\n# Go back to the base environment\n(&lt;name&gt;) [&lt;usr&gt;@bb-pg-login04 ~]$ conda deactivate\n(base) [&lt;usr&gt;@bb-pg-login04 ~]$ \n</code></pre>"},{"location":"software/conda/#run-your-job-on-the-cluster","title":"Run your job on the cluster","text":"<p>As indicated before, your <code>bash</code> script is very simple:</p> <pre><code>#!/bin/bash\n# run_python.sh\nset -e\n#SBATCH --account &lt;your account&gt;\n#other settings\n\npython your_script.py\n</code></pre> <p>Then choose your preferred environment, let's say an environment called <code>neuroimaging</code>, and type the following command:</p> <pre><code>(base) [&lt;usr&gt;@bb-pg-login04 ~]$ conda activate neuroimaging\n(neuroimaging) [&lt;usr&gt;@bb-pg-login04 ~]$ sbatch run_python.sh\n# check your output:\n(neuroimaging) [&lt;usr&gt;@bb-pg-login04 ~]$ tail -f slurm-&lt;id&gt;.out \nProcessing subj_id: CC222555:  24%|\u2588\u2588\u258e       | 153/651 [08:42&lt;28:37,  3.45\n</code></pre>"},{"location":"software/containers/","title":"Containers","text":"<p>A container is a lightweight software package that contains both the software, and all of the required dependencies to run the contained software.</p> <p>BlueBEAR supports running analyses on containers using Apptainer. The BEAR Technical docs contain extensive tutorals.</p> <p>Note</p> <p>BlueBEAR does not directly support Docker as it requires administrator privileges to run. Apptainer is able to read and execute Docker images without admin rights. Apptainer is the successor to the Singularty project - please see this article for more information on the transition.</p>"},{"location":"software/containers/#downloading-a-container","title":"Downloading a Container","text":"<p>Docker has a wide selection of containers available to download. BEAR Technical docs contains some examples on how to download and execute a simple python container.</p> <p>The following <code>bash</code> code provides an example of how to download the fMRIPrep container, which includes a variety of neuroimaging software, including freesurfer, FSL, and ANTS. This can be executed on an interactive or batch job.</p> <pre><code>apptainer pull --name fMRIPrep.sif docker://nipreps/fmriprep:latest\n</code></pre> <p>and this version can be submitted as a cluster script.</p> <pre><code>#!/bin/bash\n\n#SBATCH --account bagshaap-example-project\n#SBATCH --qos bbdefault\n#SBATCH --time 60\n#SBATCH --nodes 1 # ensure the job runs on a single node\n#SBATCH --ntasks 10 # this will give you circa 40G RAM and will ensure faster conversion to the .sif format\n#SBATCH --constraint icelake\n\nset -e\n\napptainer pull --name fMRIPrep.sif docker://nipreps/fmriprep:latest\n</code></pre> <p>Save the code above into a bash script called <code>create-container_fmriprep.sh</code> (make sure you update the <code>account</code> name on line 3 to a project that you have access to!) inside the directory where you would like to save the container file. This can then be submitted to the cluster by running <code>sbatch create-container_fmriprep.sh</code> in a terminal, or creating a job in the 'job composer'. This will take several minutes to run to completion with the <code>fmriprep</code> image.</p> <p>Once the job has completed, you should be able to find a file called <code>fMRIPrep.sif</code> in your working directory (alongside the cluster log files). This is the container file.</p>"},{"location":"software/containers/#running-software-using-a-container","title":"Running Software using a Container","text":"<p>The <code>apptainer exec</code> command is used to run the contained software. The following bash codes demonstrates how to run the FSL command <code>fslroi</code> contained within the fMRIPrep container.</p> <pre><code>#!/bin/bash\n#SBATCH --account bagshaap-example-project\n#SBATCH --qos bbdefault\n\nmodule purge; module load bluebear\n\napptainer exec fMRIPrep.sif fslroi --help\n</code></pre> <p>This code can be saved into a <code>bash</code> script called <code>check-container_fmriprep.sh</code> inside the same directory used above. You can run the job as above and check the cluster logfiles to see that the help text for the <code>fslroi</code> function was printed from within the container. This is a very simple example but can be adapted to run any command using the software inside the container.</p> <p>Let's break this down so we can build a more complex command. There are four parts to running a command with Apptainer. This is the core line:</p> <pre><code>apptainer exec fMRIPrep.sif fslroi --help\n</code></pre> <p>We could visualise this as</p> <pre><code>&lt;apptainer call&gt; &lt;apptainer command&gt; &lt;container image&gt; &lt;user command&gt;\n</code></pre> <p>where</p> <ul> <li><code>&lt;apptainer call&gt;</code> is simply <code>apptainer</code>. This specifies that we're using apptainer.</li> <li><code>&lt;apptainer command&gt;</code> is <code>exec</code>. This tells apptainer that we want to run a command.</li> <li><code>&lt;container image&gt;</code> is <code>fMRIPrep.sif</code>. This should point to an existing <code>.sif</code> file containing our container.</li> <li><code>&lt;user command&gt;</code> is <code>fslroi --help</code>. This is the command we actually want to run and the part that we'll most frequently be changing.</li> </ul> <p>So, to run a more complex command we'd simply need to update our <code>&lt;user command&gt;</code> to the function that we need to compute. You'll need to be sure that the appropriate command is included in the container with all its dependencies. The command can point to files and directories within RDS as usual. You can combine array jobs and container commands to run many parallel analyses all within equivalent containers.</p> <p>For a practical tutorial on running a container, please see the fMRIPrep example.</p>"},{"location":"software/matlab/","title":"MATLAB","text":"<p>Interactive MATLAB sessions run as a GUI App accessible from the BEAR Portal. Please follow the information on the BEAR Technical Docs to start up an interactive MATLAB session.</p> <p>Some parallelisation is available through parfor loops within single MATLAB but users looking for to run many individual MATLAB scripts in parallel are likely to want to use the Slurm job submissions. Examples of both are included below.</p>"},{"location":"software/matlab/#neuroimaging-toolboxes","title":"Neuroimaging toolboxes","text":"<p>Neuroimaging toolboxes can be added to the MATLAB path on BlueBEAR in the normal way. Toolboxes can be downloaded from the developer and stored on an RDS space. These folders can be added to the path within a MATLAB session using <code>addpath</code>.</p> <pre><code>addpath(genpath('/rds/q/quinna-example-project/code/fieldtrip'))\n</code></pre> <p>These pages include some specific examples using popular MATLAB toolboxes:</p> <ul> <li>Fieldtrip</li> <li>SPM</li> </ul>"},{"location":"software/matlab/#parallel-for-loop","title":"Parallel for-loop","text":"<p>Info</p> <p>Example contributed by Dagmar Fraser</p> <p>Simple parallelisation of a for-loop can be performed using parfor. This functionality is provided by MATLAB and enables faster processing of <code>for</code> loops simply by changing the syntax at the start to say <code>parfor</code> rather than <code>for</code>.</p> <p>The following MATLAB code performs some matrix calculations on simulated data. The inclusion of a <code>parfor</code> loop means that the code can take advantage of computers with multiple CPUs to accelerate processing.</p> <pre><code>tic\nn = 200;\nA= 500;\na = zeros(1,n);\nparfor i = 1:n\n    a(i) = max(abs(eig(rand(A))));\nend\ntoc\n</code></pre> <p>Run this a few times replacing <code>parfor</code> with <code>for</code> to get an idea of the time difference.</p> <p>Note</p> <p>Make sure you specify the appropriate number of cores when starting the MATLAB GUI App, you may not notice a substantial speed-up if you run MATLAB using the default of 4 cores. Do try to avoid asking for substantially more than you might need however - BlueBEAR is a shared resource!</p>"},{"location":"software/matlab/#submitting-matlab-jobs-with-parfor-to-bear","title":"Submitting MATLAB jobs with parfor to Bear","text":"<p>You can run this code in an interactive MATLAB session, or save it as a script that can be executed on the big cluster. If we save the code in the previous example as <code>parforDemo.m</code>, we can write a second 'submission' script to execute it on the cluster.</p> <pre><code>#!/bin/bash\n#SBATCH --ntasks 8\n#SBATCH --time 5:0\n#SBATCH --qos bbshort\n#SBATCH --mail-type ALL\n\nset -e\n\nmodule purge\nmodule load bluebear\nmodule load MATLAB/2020a\n\nMATLAB -nodisplay -r parforDemo\n</code></pre> <p>If we save that second script as <code>RunMyCode.sh</code> it can be run using <code>sbatch RunMyCode.sh</code> on a terminal to send the job to the cluster. We can monitor the progress of the job using the 'Active Jobs' tab in BlueBEAR portal.</p> <p>The <code>ntasks</code> line specifies we are looking to use 8 cores. The last line contains the filename we are sending to MATLAB to execute.</p>"},{"location":"software/matlab/#submitting-multiple-matlab-jobs","title":"Submitting multiple MATLAB jobs","text":"<p>Info</p> <p>Example contributed by Katharina Deucker</p> <p>The previous example submits a single MATLAB job that uses <code>parfor</code> BlueBEAR, for larger analyses we may want to parallelise jobs across entire MATLAB instances. This can be done by submitting MATLAB jobs to BEAR using Slurm. The BEAR Technical Docs contain a simple example on submitting a MATLAB job to BEAR.</p> <p>For neuroimaging analyses, you'll generally need to organise your scripts so that each part that you want to parallelise runs from a single function that takes a single ID as an argument. Here is a specific example that runs a function <code>e1_fun_ICA</code> on each of 48 datasets.</p> <pre><code>#!/bin/bash\n#SBATCH --ntasks 1\n#SBATCH --time 30:0\n#SBATCH --mem 50G\n#SBATCH --qos bbdefault\n#SBATCH --array=1-48\n\nset -eu\n\nmodule purge; module load bluebear\n\n# load the MATLAB version you need\nmodule load MATLAB/2019b\n\n# apply MATLAB script to each index in the array\n# (the MATLAB script is programmed such that the input ID is used as the subject ID)\nMATLAB -nodisplay -r \"run /rds/homes/d/dueckerk/startup.m, e1_fun_ICA(${SLURM_ARRAY_TASK_ID}), quit\"\n</code></pre>"},{"location":"software/python/","title":"Python","text":"<p>Python is a interactive programming language known for being flexible and (relatively) simple to use. A vast range of scientific applications have be built in and around Python.</p> <p>Some of the most common are:</p> <ul> <li>numpy: fundamental array computing in python</li> <li>scipy: fundamental algorithms in python</li> <li>pandas: manipulation and analysis of data tables</li> <li>scikit-learn: efficient tools for machine learning</li> </ul> <p>and many, many more. Many Python packages are distributed on PyPI.org</p>"},{"location":"software/python/#python-versions-on-bear","title":"Python versions on BEAR","text":"<p>Many versions are supported as loadable modules on BEAR Apps. These can be loaded into a terminal session ready for use, for example:</p> <pre><code>module load bear-apps/2022a\nmodule load Python/3.10.4-GCCcore-11.3.0\n</code></pre> <p>This will be sufficient to run a pure Python script inside that terminal session. Frequently we'll want to load a wider range of modules to use in the script. There are several ways to do this.</p> <p>We could load these modules one at a time, ensuring that any versions relating to Python, FOSS or GCCCore all match each other:</p> <pre><code>module load bear-apps/2022a\nmodule load scikit-learn/1.1.2-foss-2022a\n</code></pre> <p>Note</p> <p>Modules will load any relevant dependencies at the same time, so loading <code>scikit-learn</code> will also load the relevant Python version into the session. It is best to trust the dependencies built into the <code>module load</code> system and only define the minimum necessary modules in your session.</p> <p>Or we can load a bundle of applications. The <code>SciPy-bundle</code> includes the <code>numpy</code>, <code>scipy</code> and <code>pandas</code> packages among many others.</p> <pre><code>module load bear-apps/2022a\nmodule load SciPy-bundle/2022.05-foss-2022a\n</code></pre>"},{"location":"software/python/#ipython","title":"iPython","text":"<p>iPython is a powerful Python console that you can use for interactive sessions in the terminal.</p> <pre><code>module load bear-apps/2022a\nmodule load SciPy-bundle/2022.05-foss-2022a\nmodule load matplotlib/3.5.2-foss-2022a\nmodule load IPython/8.5.0-GCCcore-11.3.0\n</code></pre> <p>You can then start an iPython session from a terminal:</p> <pre><code>ipython --pylab=tk\n</code></pre> <p>and start running some Python code using your loaded libraries:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.random.randn(10,)/2 + x\n\nplt.figure()\nplt.plot(x, y, 'o')\nplt.show()\n</code></pre> <p>You can also save some Python code into a file and run it on the command line (this is very useful for running jobs on the cluster later...). If we save the code above into a file called <code>my_plot.py</code> - we can run it in the terminal using:</p> <pre><code>python my_plot.py\n</code></pre>"},{"location":"software/python/#submitting-python-jobs-to-the-cluster","title":"Submitting Python jobs to the cluster","text":"<p>We need to prepare two things to run Python jobs on the BlueBEAR cluster:</p> <ol> <li>Python script to run the analysis</li> <li>bash script to prepare an environment and actually run our code</li> </ol> <p>Let's make a simple example. The following script creates and saves a simple scatter plot of some random data.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.random.randn(10,)/2 + x\n\nplt.figure()\nplt.plot(x, y, 'o')\nplt.title('This ran on the cluster!')\nplt.xlabel('Variable 1')\nplt.ylabel('Variable 2')\nfor tag in ['top', 'right']:\n    plt.gca().spines[tag].set_visible(False)\nplt.grid(True)\nplt.savefig('my_cluster_figure.png')\n</code></pre> <p>We can save this script as <code>quick_python_plot.py</code>. </p> <p>Next, we need a <code>bash/slurm</code> script to submit and run our Python code.</p> <pre><code>#!/bin/bash\n#SBATCH --account quinna-example-project\n#SBATCH --qos bbdefault\n\nmodule purge; module load bluebear\n\nmodule load bear-apps/2022a\nmodule load SciPy-bundle/2022.05-foss-2022a\nmodule load matplotlib/3.5.2-foss-2022a\n\npython quick_python_plot.py\n</code></pre> <p>We can save this as <code>submit_quick_python_plot.sh</code> in a directory next to our Python code (Remember to update the project on line 2 to a BEAR project that you can access!).</p> <pre><code>sbatch submit_quick_python_plot.sh\n</code></pre> <p>You can monitor the progress of your job in the active jobs tracker on BEAR portal. Once it has finished you should find a nice figure saved in your directory.</p> <p></p>"},{"location":"software/python/#jupyterlab","title":"JupyterLab","text":"<p>Interactive python notebooks are available to run as a JupyterLab GUI App through the BEAR Portal. The pre-installed Python modules can be loaded as modules in the notebook session.</p> <p>Only the pre-installed modules available in BEAR Apps are installable in the JupyterLab GUI App.</p>"},{"location":"software/python/#virtual-environments","title":"Virtual environments","text":"<p>More involved analyses may required dependencies or package versions that aren't available on BEAR Apps. The next option for these analysis is to use virtual environments as described on the BEAR Technical Docs.</p> <p>The following <code>bash</code> script (adapted from the main docs) loads the standard BEAR modules for MNE-Python, creates a virtual environment and then installs the EMD package with <code>pip</code>:</p> <pre><code>#!/bin/bash\nset -e\n\n# Load our core modules from BEAR\nmodule purge; module load bluebear\nmodule load bear-apps/2021b\nmodule load Python/3.9.6-GCCcore-11.2.0\n\n# Prepare path locations and name for virtual environment\nexport VENV_DIR=\"${HOME}/virtual-environments\"\nexport VENV_PATH=\"${VENV_DIR}/my-virtual-env-${BB_CPU}\"\n\n# Create a master venv directory if necessary\nmkdir -p ${VENV_DIR}\n\n# Check if virtual environment exists and create it if not\nif [[ ! -d ${VENV_PATH} ]]; then\n    python3 -m venv --system-site-packages ${VENV_PATH}\nfi\n\n# Activate the virtual environment\nsource ${VENV_PATH}/bin/activate\n\n# Perform any required pip installations. For reasons of consistency we would recommend\n# that you define the version of the Python module \u2013 this will also ensure that if the\n# module is already installed in the virtual environment it won't be modified.\npip install emd==0.5.4\n</code></pre> <p>You can save this into a shell script such as <code>init_myenv.sh</code> and run it using <code>source init_myenv.sh</code> to create the environment. You can now run <code>init_myenv.sh</code> when opening a new terminal to initialise an environment before running scripts or interactive sessions. The code above is all you need for this option, you can add or change the dependencies in the script as you need.</p>"},{"location":"software/python/#python-on-the-cluster","title":"Python on the cluster","text":"<p>You can also adapt the script to submit jobs to the cluster. For this, we'll need to add the appropriate <code>slurm</code> commands to the start of the script and add a line running our analysis to the end. That might look something like this:</p> <pre><code>#!/bin/bash\n#SBATCH --account quinna-example-project\n#SBATCH --qos bbdefault\n\nset -e\n\n# Load our core modules from BEAR\nmodule purge; module load bluebear\nmodule load bear-apps/2021b\nmodule load Python/3.9.6-GCCcore-11.2.0\n\n# Prepare path locations and name for virtual environment\nexport VENV_DIR=\"${HOME}/virtual-environments\"\nexport VENV_PATH=\"${VENV_DIR}/my-virtual-env-${BB_CPU}\"\n\n# Create a master venv directory if necessary\nmkdir -p ${VENV_DIR}\n\n# Check if virtual environment exists and create it if not\nif [[ ! -d ${VENV_PATH} ]]; then\n    python3 -m venv --system-site-packages ${VENV_PATH}\nfi\n\n# Activate the virtual environment\nsource ${VENV_PATH}/bin/activate\n\n# Perform any required pip installations. For reasons of consistency we would recommend\n# that you define the version of the Python module \u2013 this will also ensure that if the\n# module is already installed in the virtual environment it won't be modified.\npip install emd==0.5.4\n\n# Python script to be run.\npython emd_example.py\n</code></pre> <p>Note the additional <code>SBATCH</code> options at the start and the <code>python emd_example.py</code> at the end. We can save this script as 'submit_emd_example.sh`.</p> <p>We'll need a Python script for this example. Let's save the following script as <code>emd_example.py</code> on RDS.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport emd\n\n# Define and simulate a simple signal\npeak_freq = 15\nsample_rate = 256\nseconds = 10\nnoise_std = .4\nx = emd.simulate.ar_oscillator(peak_freq, sample_rate, seconds,\n                               noise_std=noise_std, random_seed=42, r=.96)[:, 0]\nx = x*1e-4\nt = np.linspace(0, seconds, seconds*sample_rate)\n\n# Run a mask sift\nimf = emd.sift.mask_sift(x, max_imfs=5)\n\nfig = plt.figure()\nemd.plotting.plot_imfs(imf[:sample_rate*3, :], fig=fig)\nfig.savefig('my-emd-example.png')\n</code></pre> <p>Now, we can submit our job to the cluster.</p> <pre><code>sbatch submit_emd_example.sh\n</code></pre> <p>You can monitor the progress of your job in the active jobs tracker on BEAR portal. Once it has finished you should find a nice new figure saved in your working directory.</p> <p></p>"},{"location":"software/python/#using-uv-to-manage-dependencies-and-environments","title":"Using uv to manage dependencies and environments","text":"<p>uv is a python package and project management tool that helps with consistency and reproducibility. It makes it easier for others (and yourself) to setup and run your code without worrying about differences between versions and dependency issues. </p> <p>Instead of using <code>pip</code> and a <code>requirements.txt</code>, uv creates a <code>uv.lock</code> and <code>pyproject.toml</code> file to keep track and manage package versions. These files can be version controlled using git.</p> <p>uv is compatible with <code>pip</code> but is 10x-100x faster. It aims to replace similar dependency management tools (<code>pip</code>, <code>pyenv</code>, <code>poetry</code>, <code>virtualenv</code>, etc.) </p>"},{"location":"software/python/#installing-uv","title":"Installing uv","text":"<p>If you are running things on BEAR, you can install uv to your home folder.</p> <p>For example, go to your home folder (<code>cd ~/</code> in the terminal) and then run:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh` \n</code></pre> <p>Further installation instructions, e.g., for Mac or Windows, can be found on the uv website.</p>"},{"location":"software/python/#initial-setup","title":"Initial setup","text":"<p>Once you have uv installed, you need to setup a project in your project's folder. </p> <p>In the terminal run:</p> <pre><code>uv init\n</code></pre> <p>This will create a universal lock file <code>uv.lock</code> and a <code>pyproject.toml</code> file to help manage the packages and dependencies used.</p> <p>The <code>pyproject.toml</code> contains metadata about your project, such as the packages required, project name and description, development tools used (e.g., formatters), etc.</p> <p>The <code>uv.lock</code> file keeps a record of all the packages used and their specific versions and dependencies.</p> <p>uv.lock is a cross-platform lockfile that contains exact information about your project's dependencies. Unlike the pyproject.toml which is used to specify the broad requirements of your project, the lockfile contains the exact resolved versions that are installed in the project environment. This file should be checked into version control, allowing for consistent and reproducible installations across machines.</p> <p>These files can be version controlled using git, so you can keep track of when you changed versions, added packages, etc.</p>"},{"location":"software/python/#installing-packages","title":"Installing packages","text":"<p>To install packages, use <code>uv add &lt;package-name&gt;</code>, for example <code>uv add numpy</code>. This will automatically install the package and any dependencies, and make sure that it does not conflict with other packages installed.</p>"},{"location":"software/python/#syncingcreating-virtual-environments","title":"Syncing/creating virtual environments","text":"<p>To create a virtual environment based on the uv.lock and pyproject.toml files, run in the terminal:</p> <pre><code>uv sync\n</code></pre> <p>This will create a virutal environment and install the required packages (defaults to <code>.venv</code>) .</p> <p>If a <code>.venv</code> folder already exists, it will sync/update the packages to match the versions required.</p> <p>To activate the virtual environment, run <code>source .venv/bin/activate</code>.</p> <p>Note</p> <p>A virtual environment created on Linux will not work on Mac or Windows. In this case, delete the .venv folder and use <code>uv sync</code> to rebuild it on your local machine.</p>"},{"location":"software/python/#running-a-python-file","title":"Running a python file","text":"<p>To run a python file, use <code>uv run &lt;python-file&gt;.py</code> where \"python-file\" is the name of the file you want to run (e.g., <code>main.py</code>).</p> <p>Using uv to run the file, rather than <code>python &lt;python-file&gt;.py</code>, will check that all the correct packages are installed and the correct version. It will even create and setup the virtual environment if it doesn't exist!</p>"},{"location":"software/python/#running-files-on-bear","title":"Running files on BEAR","text":"<p>When running scripts on BEAR, you will first need to load any modules you will be using. For example, in the terminal:</p> <pre><code>module purge\nmodule load bluebear\nmodule load bear-apps/2024a\nmodule load Python/3.12.3-GCCcore-13.3.0\n</code></pre> <p>You can put this into a script, for example called <code>setup_bear.sh</code>:</p> <pre><code>#!/bin/bash\n\n# set up bluebear\nset -e\nmodule purge\nmodule load bluebear\nmodule load bear-apps/2024a\nmodule load Python/3.12.3-GCCcore-13.3.0\n</code></pre> <p>You can then run <code>source setup_bear.sh</code> in the terminal and it will setup setup the modules for you.</p> <pre><code>[vogelt@bear-pg0201u17a example-project]$ source setup_project_bear.sh \nDetected OS: RedHatEnterprise 8.10\nGCCcore/13.3.0\nzlib/1.3.1-GCCcore-13.3.0\nbinutils/2.42-GCCcore-13.3.0\nbzip2/1.0.8-GCCcore-13.3.0\nncurses/6.5-GCCcore-13.3.0\nlibreadline/8.2-GCCcore-13.3.0\nTcl/8.6.14-GCCcore-13.3.0\nSQLite/3.45.3-GCCcore-13.3.0\nXZ/5.4.5-GCCcore-13.3.0\nlibffi/3.4.5-GCCcore-13.3.0\nOpenSSL/3\nPython/3.12.3-GCCcore-13.3.0\n</code></pre> <p>Once the modules are loaded, you can activate the virtual environment and edit/run your code, e.g., in an interactive session.</p> <p>More commonly, you will want to submit a job using to the cluster and run it through a sbatch script. An example may look like:</p> <pre><code>#!/bin/bash\n#SBATCH --account vogelt-example-project\n#SBATCH --qos bbdefault\n\n# set up bluebear\nset -e\nmodule purge\nmodule load bluebear\nmodule load bear-apps/2024a\nmodule load Python/3.12.3-GCCcore-13.3.0\n\nuv run main.py\n</code></pre> <p><code>uv run</code> will automatially activate the virtual environment, install/sync any packages if necessary (matching the versions listed in the pyproject.toml and uv.lock files), and run the python script.</p>"}]}